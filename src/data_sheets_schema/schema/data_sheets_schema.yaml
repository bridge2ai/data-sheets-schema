---
id: https://w3id.org/bridge2ai/data-sheets-schema
name: data-sheets-schema
title: data-sheets-schema
description: |-
  A LinkML schema for Datasheets for Datasets.
license: MIT
see_also:
  - https://bridge2ai.github.io/data-sheets-schema

prefixes:
  biolink: https://w3id.org/biolink/vocab/
  csvw: http://www.w3.org/ns/csvw#
  data_sheets_schema: https://w3id.org/bridge2ai/data-sheets-schema/
  datasets: https://w3id.org/linkml/report
  dcat: http://www.w3.org/ns/dcat#
  example: https://example.org/
  formats: http://www.w3.org/ns/formats/
  frictionless: https://specs.frictionlessdata.io/
  linkml: https://w3id.org/linkml/
  mediatypes: https://www.iana.org/assignments/media-types/
  pav: http://purl.org/pav/
  schema: http://schema.org/
  sh: https://w3id.org/shacl/
  skos: http://www.w3.org/2004/02/skos/core#
  void: http://rdfs.org/ns/void#
  B2AI_TOPIC: https://w3id.org/bridge2ai/b2ai-standards-registry/
  B2AI_STANDARD: https://w3id.org/bridge2ai/b2ai-standards-registry/
  B2AI_SUBSTRATE: https://w3id.org/bridge2ai/b2ai-standards-registry/
default_prefix: data_sheets_schema
default_range: string

imports:
  - linkml:types
  - standards_schema
  - standards_organization_schema
  # Base classes module
  - modules/D4D_Base
  # D4D Modules in original paper order
  - modules/D4D_Motivation
  - modules/D4D_Composition
  - modules/D4D_Collection
  - modules/D4D_Preprocessing
  - modules/D4D_Uses
  - modules/D4D_Distribution
  - modules/D4D_Maintenance
  # Additional extended modules
  - modules/D4D_Ethics
  - modules/D4D_Human

## TYPES ##


## SUBSETS ##
subsets:
  Motivation:
    description: >-
      The questions in this section are primarily intended to encourage dataset
      creators to clearly articulate their reasons for creating the dataset and
      to promote transparency about funding interests. The latter may be
      particularly relevant for datasets created for research purposes.
  Composition:
    description: >-
      The questions in this section are intended to provide dataset consumers
      with the information they need to make informed decisions about using the
      dataset for their chosen tasks. Some of the questions are designed to
      elicit information about compliance with the EU's General Data Protection
      Regulation (GDPR) or comparable regulations in other jurisdictions.
  Collection:
    description: >-
      The questions in this section are designed to elicit information that may
      help researchers and practitioners to create alternative datasets with
      similar characteristics.
  Preprocessing-Cleaning-Labeling:
    description: >-
      The questions in this section are intended to provide dataset consumers
      with the information they need to determine whether the "raw" data has
      been processed in ways that are compatible with their chosen tasks.
  Uses:
    description: >-
      The questions in this section are intended to encourage dataset creators
      to reflect on the tasks for which the dataset should and should not be
      used.
  Distribution:
    description: >-
      The questions in this section pertain to dataset distribution.
  Maintenance:
    description: >-
      The questions in this section are intended to encourage dataset creators
      to plan for dataset maintenance and communicate this plan to dataset
      consumers.
  Ethics:
    description: >-
      The questions in this section address ethical and data-protection concerns,
      including review by institutional bodies, consent and notification to data
      subjects, and potential impacts on data-protection rights.
  DataGovernance:
    description: >-
      The questions in this section relate to how the dataset is governed:
      how it is distributed, licensed, and maintained over time, plus
      third-party restrictions and update policies.

## CLASSES ##
classes:

  # NamedThing is imported from Bridge2AI standards schema

  # Information class is imported from modules/D4D_Base
  # Adapted from linkml Datasets schema - see
  # https://github.com/linkml/linkml-model/blob/main/linkml_model/model/schema/datasets.yaml

  # From linkml Datasets schema - see
  # https://github.com/linkml/linkml-model/blob/main/linkml_model/model/schema/datasets.yaml
  FormatDialect:
    description: Additional format information for a file
    attributes:
      comment_prefix:
      delimiter:
      double_quote:
      header:
      quote_char:
    slots:
      - id

  # Person, DatasetProperty, Software are imported from modules/D4D_Base

  DatasetCollection:
    aliases:
      - file collection
      - dataset collection
      - data resource collection
    tree_root: true
    description: >-
      A collection of related datasets, likely containing multiple files
      of multiple potential purposes and properties.
    exact_mappings:
      - dcat:Dataset
    close_mappings:
      - dcat:Catalog
    is_a: Information
    attributes:
      resources:
        range: Dataset
        multivalued: true

  # TODO: consider how to distinguish between metadata only vs
  # instances where data file is present (and we can extract metadata)
  Dataset:
    aliases:
      - data resource
      - data file
      - data package
    class_uri: dcat:Distribution
    exact_mappings:
      - schema:DataDownload
    see_also:
      - https://specs.frictionlessdata.io/data-resource
    description: >-
      A single component of related observations and/or information that can be
      read, manipulated, transformed, and otherwise interpreted.
    is_a: Information
    slots:
      - bytes
      - dialect
      - encoding
      - format
      - hash
      - md5
      - media_type
      - path
      - sha256
    attributes:
      # Motivation module classes
      purposes:
        range: Purpose
        multivalued: true
      tasks:
        range: Task
        multivalued: true
      addressing_gaps:
        range: AddressingGap
        multivalued: true
      creators:
        range: Creator
        multivalued: true
      funders:
        range: FundingMechanism
        multivalued: true
      # Composition module classes
      subsets:
        range: DataSubset
        multivalued: true
        slot_uri: dcat:distribution
        exact_mappings:
          - schema:distribution
      instances:
        range: Instance
        multivalued: true
      anomalies:
        range: DataAnomaly
        multivalued: true
      external_resources:
        range: ExternalResource
        multivalued: true
      confidential_elements:
        range: Confidentiality
        multivalued: true
      content_warnings:
        range: ContentWarning
        multivalued: true
      subpopulations:
        range: Subpopulation
        multivalued: true
      sensitive_elements:
        range: SensitiveElement
        multivalued: true
      # Collection module classes
      acquisition_methods:
        range: InstanceAcquisition
        multivalued: true
      collection_mechanisms:
        range: CollectionMechanism
        multivalued: true
      sampling_strategies:
        range: SamplingStrategy
        multivalued: true
      data_collectors:
        range: DataCollector
        multivalued: true
      collection_timeframes:
        range: CollectionTimeframe
        multivalued: true
      # Ethics module classes
      ethical_reviews:
        range: EthicalReview
        multivalued: true
      data_protection_impacts:
        range: DataProtectionImpact
        multivalued: true
      # Preprocessing module classes
      preprocessing_strategies:
        range: PreprocessingStrategy
        multivalued: true
      cleaning_strategies:
        range: CleaningStrategy
        multivalued: true
      labeling_strategies:
        range: LabelingStrategy
        multivalued: true
      raw_sources:
        range: RawData
        multivalued: true
      # Uses module classes
      existing_uses:
        range: ExistingUse
        multivalued: true
      use_repository:
        range: UseRepository
        multivalued: true
      other_tasks:
        range: OtherTask
        multivalued: true
      future_use_impacts:
        range: FutureUseImpact
        multivalued: true
      discouraged_uses:
        range: DiscouragedUse
        multivalued: true
      # Distribution module classes
      distribution_formats:
        range: DistributionFormat
        multivalued: true
      distribution_dates:
        range: DistributionDate
        multivalued: true
      # Data Governance module classes
      license_and_use_terms:
        range: LicenseAndUseTerms
      ip_restrictions:
        range: IPRestrictions
      regulatory_restrictions:
        range: ExportControlRegulatoryRestrictions
      # Maintenance module classes
      maintainers:
        range: Maintainer
        multivalued: true
      errata:
        range: Erratum
        multivalued: true
      updates:
        range: UpdatePlan
      retention_limit:
        range: RetentionLimits
      version_access:
        range: VersionAccess
      extension_mechanism:
        range: ExtensionMechanism
      # Other attributes
      is_deidentified:
        range: Deidentification
      is_tabular:
        range: boolean

  DataSubset:
    description: >-
      A subset of a dataset, likely containing multiple files
      of multiple potential purposes and properties.
    is_a: Dataset
    attributes:
      is_data_split:
        description: >-
          Is this subset a split of the larger dataset,
          e.g., is it a set for model training, testing,
          or validation?
        range: boolean
      is_subpopulation:
        description: >-
          Is this subset a subpopulation of the larger dataset,
          e.g., is it a set of data for a specific demographic?
        range: boolean

  # All D4D-specific classes are now imported from their respective modules
  # Motivation: Purpose, Task, AddressingGap, Creator, FundingMechanism, Grantor, Grant
  # Composition: Instance, SamplingStrategy, MissingInfo, Relationships, Splits, DataAnomaly, ExternalResource, Confidentiality, ContentWarning, Subpopulation, Deidentification, SensitiveElement
  # Collection: InstanceAcquisition, CollectionMechanism, DataCollector, CollectionTimeframe, DirectCollection, CollectionNotification, CollectionConsent, ConsentRevocation
  # Ethics: EthicalReview, DataProtectionImpact
  # Preprocessing: PreprocessingStrategy, CleaningStrategy, LabelingStrategy, RawData
  # Uses: ExistingUse, UseRepository, OtherTask, FutureUseImpact, DiscouragedUse
  # Distribution: ThirdPartySharing, DistributionFormat, DistributionDate
  # Data Governance: LicenseAndUseTerms, IPRestrictions, ExportControlRegulatoryRestrictions
  # Maintenance: Maintainer, Erratum, UpdatePlan, RetentionLimits, VersionAccess, ExtensionMechanism

## SLOTS ##
slots:

  # The majority of these slots are adapted from
  # the linkml Datasets schema - see
  # https://github.com/linkml/linkml-model/blob/main/linkml_model/model/schema/datasets.yaml

  # id is imported from Bridge2AI standards schema
  # name is imported from Bridge2AI standards schema
  # description is imported from Bridge2AI standards schema

  title:
    description: the official title of the element
    slot_uri: dcterms:title

  language:
    description: language in which the information is expressed

  publisher:
    slot_uri: dcterms:publisher
    range: uriorcurie

  issued:
    slot_uri: dcterms:issued
    range: datetime

  page:
    slot_uri: dcat:landingPage

  dialect:
    slot_uri: csvw:dialect

  bytes:
    description: Size of the data in bytes.
    range: integer
    slot_uri: dcat:byteSize

  path:
    close_mappings:
      - frictionless:path

  download_url:
    description: >-
      URL from which the data can be downloaded. This is not the same as the
      landing page, which is a page that describes the dataset. Rather, this
      URL points directly to the data itself.
    range: uri
    slot_uri: dcat:downloadURL
    exact_mappings:
      - schema:url
    close_mappings:
      - frictionless:path

  format:
    description: >-
      The format of the data. This is not the same as the media type.
      Rather, this is the format of the data in a more specific sense,
      e.g., CSV, JSON, etc.
    range: FormatEnum
    slot_uri: dcterms:format

  compression:
    description: >-
      The compression format of the data. This is not the same as the media
      type. Rather, this is the compression format of the data in a more
      specific sense, e.g., zip, gzip, etc.
    range: CompressionEnum

  encoding:
    description: >-
      The encoding of the data. This is not the same as the media type.
      Rather, this is the encoding of the data in a more specific sense,
      e.g., UTF-8, ASCII, etc.
    range: EncodingEnum

  hash:
    description: >-
      The hash representation of the data, e.g., sha256, md5, etc.
      Subtypes have their own slots.
    range: string
  sha256:
    description: >-
      The sha256 hash representation of the data.
    is_a: hash
  md5:
    description: >-
      The md5 hash representation of the data.
    is_a: hash

  media_type:
    description: >-
      The media type of the data. This is not the same as the format.
      Rather, this is the media type of the data in a more general sense,
      e.g., text/csv, application/json, etc., though as it is defined here
      the media type can be any string.
    range: string
    examples:
      - value: text/csv
      - value: application/json
    slot_uri: dcat:mediaType
    exact_mappings:
      - frictionless:mediatype
      - schema:encodingFormat

  conforms_to:
    description: >-
      The standard to which the data conforms. This is not the same as the
      media type. Rather, this is the standard to which the data conforms
      in a more specific sense, e.g., frictionless, schema.org, etc.
      This should be a standard from the Bridge2AI standards registry.
    slot_uri: dcterms:conformsTo
    range: uriorcurie
    values_from:
      - B2AI_STANDARD

  conforms_to_schema:
    description: >-
      The schema to which the data conforms. This is not the same as the
      media type. Rather, this is the schema to which the data conforms
      in a more specific sense, and even more specific than the general
      set of standards it conforms to.
    is_a: conforms_to
    exact_mappings:
      - frictionless:schema

  conforms_to_class:
    description: >-
      The class in the schema to which the data object instantiates.
    is_a: conforms_to

  doi:
    description: >-
      The Digital Object Identifier of the data, with the doi prefix.
    range: uriorcurie
    examples:
      - value: "doi:10.48550/arXiv.2310.03666"

  profile:
    description: >-
      The frictionless data profile to which the data conforms.
    range: uriorcurie
    exact_mappings:
      - frictionless:profiles

  keywords:
    description: >-
      Keywords associated with the data. These may be provided by
      the data creator or assigned later in a manual or automated
      manner.
    singular_name: keyword
    multivalued: true
    range: string
    slot_uri: dcat:keyword
    exact_mappings:
      - schema:keywords

  themes:
    description: >-
      Themes associated with the data. These may be provided by
      the data creator or assigned later in a manual or automated
      manner.
    singular_name: theme
    multivalued: true
    range: uriorcurie
    slot_uri: dcat:theme

  created_by:
    range: CreatorOrMaintainerEnum
    description: Agent that created the element
    slot_uri: pav:createdBy
    multivalued: true

  created_on:
    range: datetime
    description: Date and Time at which the element was created
    slot_uri: pav:createdOn

  last_updated_on:
    range: datetime
    description: Date and Time at which the element was last updated
    slot_uri: pav:lastUpdatedOn

  modified_by:
    range: CreatorOrMaintainerEnum
    description: agent that modified the element
    slot_uri: oslc:modifiedBy

  status:
    range: uriorcurie
    description: Status of the element in terms of its maturity or life cycle
    slot_uri: bibo:status
    examples:
      - value: "bibo:draft"

  license:
    description: license for the data
    slot_uri: dcterms:license
    exact_mappings:
      - frictionless:licenses

  version:
    description: particular version of schema
    slot_uri: pav:version
    exact_mappings:
      - schema:version
      - dcterms:hasVersion

  was_derived_from:
    slot_uri: prov:wasDerivedFrom
    description: >-
      A derivation is a transformation of an entity into another, an update
      of an entity resulting in a new one, or the construction of a new entity
      based on a pre-existing entity.@en

## ENUMS ##
enums:

  # CreatorOrMaintainerEnum is imported from modules/D4D_Base


  # These enums are adapted from
  # the linkml Datasets schema - see
  # https://github.com/linkml/linkml-model/blob/main/linkml_model/model/schema/datasets.yaml

  MediaTypeEnum:
    exact_mappings:
      - dcterms:MediaType
    permissible_values:
      csv:
        meaning: mediatypes:text/csv
      rdf-xml:
        meaning: mediatypes:application/rdf+xml

  FormatEnum:
    permissible_values:
      JSON-LD:
        meaning: formats:JSON-LD
      N3:
        meaning: formats:N3
      N-Triples:
        meaning: formats:N-Triples
      N-Quads:
        meaning: formats:N-Quads
      LD Patch:
        meaning: formats:LD_Patch
      Microdata:
        meaning: formats:microdata
      OWL XML Serialization:
        meaning: formats:OWL_XML
      OWL Functional Syntax:
        meaning: formats:OWL_Functional
      OWL Manchester Syntax:
        meaning: formats:OWL_Manchester
      POWDER:
        meaning: formats:POWDER
      POWDER-S:
        meaning: formats:POWDER-S
      PROV-N:
        meaning: formats:PROV-N
      PROV-XML:
        meaning: formats:PROV-XML
      RDFa:
        meaning: formats:RDFa
      RDF/JSON:
        meaning: formats:RDF_JSON
      RDF/XML:
        meaning: formats:RDF_XML
      RIF XML Syntax:
        meaning: formats:RIF_XML
      SPARQL Results in XML:
        meaning: formats:SPARQL_Results_XML
      SPARQL Results in JSON:
        meaning: formats:SPARQL_Results_JSON
      SPARQL Results in CSV:
        meaning: formats:SPARQL_Results_CSV
      SPARQL Results in TSV:
        meaning: formats:SPARQL_Results_TSV
      Turtle:
        meaning: formats:Turtle
      TriG:
        meaning: formats:TriG
      YAML:
      JSON:

  CompressionEnum:
    permissible_values:
      GZIP:
      TAR:
      TARGZIP:
      ZIP:

  EncodingEnum:
    permissible_values:
      ASCII:
      Big5:
      EUC-JP:
      EUC-KR:
      EUC-TW:
      GB2312:
      HZ-GB-2312:
      ISO-2022-CN-EXT:
      ISO-2022-CN:
      ISO-2022-JP-2:
      ISO-2022-JP:
      ISO-2022-KR:
      ISO-8859-10:
      ISO-8859-11:
      ISO-8859-13:
      ISO-8859-14:
      ISO-8859-15:
      ISO-8859-16:
      ISO-8859-1:
      ISO-8859-2:
      ISO-8859-3:
      ISO-8859-4:
      ISO-8859-5:
      ISO-8859-6:
      ISO-8859-7:
      ISO-8859-8:
      ISO-8859-9:
      KOI8-R:
      KOI8-U:
      Shift_JIS:
      UTF-16:
      UTF-32:
      UTF-7:
      UTF-8:
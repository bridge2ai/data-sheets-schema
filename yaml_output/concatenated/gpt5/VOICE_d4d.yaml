resources:
  - id: https://doi.org/10.13026/249v-w155
    name: Bridge2AI-Voice v1.1 (PhysioNet)
    title: Bridge2AI-Voice – An ethically-sourced, diverse voice dataset linked to health information (v1.1)
    description: >-
      A comprehensive collection of derived representations from voice recordings
      linked to demographic, clinical, and validated questionnaire data, enabling
      ethically sourced AI research on voice as a biomarker of health. Version 1.1
      provides 12,523 recordings from 306 adult participants collected across five
      North American sites. Only de-identified derived data (e.g., spectrograms,
      MFCCs, static acoustic features) are released; raw audio and free-speech
      transcripts are withheld to reduce re-identification risk.
    same_as:
      - https://docs.b2ai-voice.org
    citation: "Johnson, A., Bélisle-Pipon, J., Dorr, D., Ghosh, S., Payne, P., Powell, M., Rameau, A., Ravitsky, V., Sigaras, A., Elemento, O., & Bensoussan, Y. (2025). Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information (version 1.1). PhysioNet. RRID:SCR_007345. https://doi.org/10.13026/249v-w155"
    creators:
      - name: Alistair Johnson
      - name: Jean-Christophe Bélisle-Pipon
      - name: David Dorr
      - name: Satrajit Ghosh
      - name: Philip Payne
      - name: Maria Powell
      - name: Anais Rameau
      - name: Vardit Ravitsky
      - name: Alexandros Sigaras
      - name: Olivier Elemento
      - name: Yael Bensoussan
    funders:
      - grant:
          award_number: 3OT2OD032720-01S1
          title: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
        grantor:
          name: National Institutes of Health
      - grant:
          award_number: R01EB030362
          title: PhysioNet infrastructure support
        grantor:
          name: National Institute of Biomedical Imaging and Bioengineering
    purposes:
      - description: Enable ethically sourced, large-scale AI research on voice as a biomarker of health by linking derived voice representations to phenotype and clinical information.
    tasks:
      - name: Voice biomarker discovery
        description: Identify associations between voice-derived features and health conditions.
      - name: Health condition modeling from voice
        description: Develop and benchmark models using derived acoustic features and linked phenotypes.
    addressing_gaps:
      - description: Provides a large, ethically sourced, clinically linked voice dataset with privacy-preserving derived representations (no raw audio) to reduce re-identification risk.
    subsets:
      - name: spectrograms.parquet
        path: spectrograms.parquet
        format: parquet
        description: Dense time-frequency power spectrograms per recording (513 x N) with participant_id, session_id, task_name.
        is_data_split: false
        is_subpopulation: false
      - name: mfcc.parquet
        path: mfcc.parquet
        format: parquet
        description: Mel-frequency cepstral coefficients (60 x N) derived from spectrograms, keyed by participant_id, session_id, task_name.
        is_data_split: false
        is_subpopulation: false
      - name: phenotype.tsv
        path: phenotype.tsv
        format: tsv
        description: One row per participant with demographics, validated questionnaire responses, and acoustic confounders.
        is_data_split: false
        is_subpopulation: false
      - name: phenotype.json
        path: phenotype.json
        format: json
        description: Data dictionary for phenotype.tsv with per-column descriptions.
        is_data_split: false
        is_subpopulation: false
      - name: static_features.tsv
        path: static_features.tsv
        format: tsv
        description: One row per recording with acoustic, phonetic, and prosodic features (openSMILE, Praat, parselmouth, torchaudio).
        is_data_split: false
        is_subpopulation: false
      - name: static_features.json
        path: static_features.json
        format: json
        description: Data dictionary for static_features.tsv feature descriptions.
        is_data_split: false
        is_subpopulation: false
    instances:
      - description: 12,523 recordings from 306 adult participants; most completed one session, a subset multiple sessions; five North American collection sites.
    subpopulations:
      - name: Voice disorders
      - name: Neurological and neurodegenerative disorders
      - name: Mood and psychiatric disorders
      - name: Respiratory disorders
    acquisition_methods:
      - description: Voice tasks collected via standardized protocol (e.g., sustained vowel phonation), using a custom tablet application and headset when possible.
    collection_mechanisms:
      - description: Screening against inclusion/exclusion criteria within five predetermined clinical groups; data exported from REDCap.
    data_collectors:
      - description: Specialty clinics and institutional sites in North America (five sites).
    collection_timeframes:
      - description: Data collected prior to the 2025-01-17 v1.1 release; specific collection dates not disclosed.
    ethical_reviews:
      - description: Data collection and sharing approved by the University of South Florida Institutional Review Board.
    human_subject_research:
      description: Prospective human subjects research with IRB oversight; adult cohort in v1.1.
    informed_consent:
      - description: Participants provided consent for data collection and sharing of de-identified research data.
    participant_privacy:
      - description: HIPAA Safe Harbor de-identification; state/province removed (country retained); free-speech transcripts removed; raw audio not released in v1.1.
    is_deidentified:
      method: HIPAA Safe Harbor
      description: Removal of all Safe Harbor identifiers; omission of raw audio; removal of free-speech transcripts; retention limited to non-identifying fields (e.g., country).
      identifiers_removed:
        - Names
        - Geographic locators below country
        - Dates finer than year
        - Contact numbers and emails
        - IP addresses
        - Government and medical identifiers
        - Device and account identifiers
        - Vehicle and license identifiers
        - URLs
        - Full face photos
        - Biometric identifiers
        - Any unique identifiers
    preprocessing_strategies:
      - name: Raw audio preprocessing
        description: Converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter.
      - name: Spectrogram computation
        description: Short-time FFT with 25 ms window, 10 ms hop, 512-point FFT; stored as power spectrograms.
      - name: MFCC computation
        description: 60 coefficients computed from spectrograms.
      - name: Acoustic feature extraction
        description: openSMILE features capturing temporal dynamics and acoustic characteristics.
      - name: Phonetic/prosodic features
        description: Parselmouth/Praat measures including F0, formants, and voice quality metrics.
      - name: Data export/merge
        description: Export from REDCap and integration using open source library.
      - name: Open-source code
        description: b2aiprep library used to preprocess waveforms and merge phenotype data.
    labeling_strategies:
      - name: ASR transcription
        description: Transcriptions generated using OpenAI Whisper Large; transcripts of free speech audio removed prior to release.
    raw_sources:
      - name: Raw audio waveforms
        description: Original audio recordings collected during study visits (not distributed in v1.1).
    intended_uses:
      - description: Artificial intelligence and clinical research on voice as a biomarker of health using de-identified derived data.
        examples:
          - Development and benchmarking of models linking voice-derived features to health conditions.
          - Exploration of acoustic, phonetic, and prosodic correlates of disease.
        usage_notes: Data are provided as derived representations without raw audio to reduce re-identification risk.
    limitations:
      - Adult cohort only in v1.1; pediatric data not included.
      - No raw audio in v1.1; analyses limited to derived representations.
      - Participants selected for conditions known to manifest in voice, which may affect generalizability.
    distribution_formats:
      - name: Parquet
        extension: .parquet
        media_type: application/vnd.apache.parquet
      - name: Tab-separated values
        extension: .tsv
        media_type: text/tab-separated-values
      - name: JSON
        extension: .json
        media_type: application/json
    distribution_dates:
      - date: 2025-01-17
        description: v1.1 public release on PhysioNet (registered access).
    license_and_use_terms:
      license_name: Bridge2AI Voice Registered Access License
      access_requirements: Registered access on PhysioNet; users must sign the Bridge2AI Voice Registered Access Agreement.
      usage_restrictions: Access and use governed by the Bridge2AI Voice Registered Access Agreement.
    maintainers:
      - name: PhysioNet platform team
        role: Platform/publisher
    updates:
      description: v1.1 released on 2025-01-17; project subsequently updated to versions 2.0.0 and 2.0.1 on the platform.
    version_access:
      description: Files for v1.1 are no longer available; latest version of the project is 2.0.1.
      latest_version_doi: "https://doi.org/10.13026/37yb-1t42"
      versions_available:
        - version: 1.1
          date: 2025-01-17
        - version: 2.0.0
          date: 2025-04-16
        - version: 2.0.1
          date: 2025-08-18
    variables:
      - name: participant_id
        description: Unique participant identifier used across files.
      - name: session_id
        description: Identifier for a specific recording session for a participant.
      - name: task_name
        description: Voice task label associated with a recording.
      - name: spectrogram
        description: Power spectrogram matrix per recording (513 x N).
      - name: mfcc
        description: Mel-frequency cepstral coefficients per recording (60 x N).
      - name: static_features
        description: Aggregate acoustic, phonetic, and prosodic features per recording from multiple toolkits.
      - name: phenotype
        description: Participant-level demographics, acoustic confounders, and validated questionnaire responses.
  - id: https://doi.org/10.57764/qb6h-em84
    name: Bridge2AI-Voice v1.0 (Health Data Nexus)
    title: b2ai-voice 1.0 – Health Data Nexus entry
    description: Entry within Health Data Nexus referencing Bridge2AI-Voice version 1.0. Limited metadata available from the provided source.
    same_as:
      - https://healthdatanexus.ai/content/b2ai-voice/1.0/
    citation: "Johnson, A., Bélisle-Pipon, J., Dorr, D., Ghosh, S., Payne, P., Powell, M., Rameau, A., Ravitsky, V., Sigaras, A., Elemento, O., & Bensoussan, Y. (2024). Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information (version 1.0). Health Data Nexus. https://doi.org/10.57764/qb6h-em84"
    distribution_dates:
      - description: v1.0 initial release (date per platform record, 2024).
# === YAML Fixing Applied ===
id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: >
  Bridge2AI-Voice is a comprehensive, ethically sourced dataset linking derived
  voice data to clinical information to advance research on voice as a biomarker
  of health. Version 1.0 contains 12,523 recordings from 306 adult participants
  across five North American sites, focusing on cohorts with conditions known to
  manifest in voice (voice disorders, neurological disorders, mood/psychiatric
  disorders, and respiratory disorders). To reduce risk, this initial release
  includes spectrograms and other derived features but omits raw audio
  waveforms and free-speech transcripts. Rich demographic, clinical, and
  validated questionnaire data are provided alongside a data dictionary.
page: "https://docs.b2ai-voice.org"
doi: "doi:10.57764/qb6h-em84"
issued: 2024-11-27
version: "1.0"
keywords:
  - voice
  - bridge2ai
  - audio
  - spectrograms
  - clinical
license: Bridge2AI Voice Registered Access License
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
status:
  - bibo:status
purposes:
  - name: Dataset purpose
    response: >
      Create an ethically sourced flagship voice dataset linked to clinical
      information to enable AI research on voice as a health biomarker and
      support critical insights into disease detection and monitoring.
tasks:
  - name: Intended tasks
    response: >
      Development and evaluation of AI/ML methods for health-related voice
      analysis, feature extraction, and linkage to clinical and demographic
      variables; exploration of voice-based biomarkers across multiple disease
      cohorts.
addressing_gaps:
  - name: Gap addressed
    response: >
      Addresses the need for a large, diverse, multi-institutional voice dataset
      with standardized protocols and linked clinical data, overcoming prior
      limitations of small, non-diverse, and non-standardized datasets.
creators:
  - name: Alistair Johnson
  - name: Jean-Christophe Bélisle-Pipon
  - name: David Dorr
  - name: Satrajit Ghosh
  - name: Philip Payne
  - name: Maria Powell
  - name: Anaïs Rameau
  - name: Vardit Ravitsky
  - name: Alexandros Sigaras
  - name: Olivier Elemento
  - name: Yael Bensoussan
funders:
  - grantor:
      name: National Institutes of Health
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
instances:
  - name: Dataset instances
    representation: Voice recordings (derived data) and linked clinical/phenotypic information
    instance_type: >
      Multiple instance types: derived spectrograms per recording; static audio features per recording;
      demographics and questionnaire responses per participant.
    data_type: >
      Derived audio data (spectrograms, acoustic/phonetic/prosodic features) and tabular clinical/phenotypic
      data; raw audio waveforms are not included in v1.0.
    counts: 12523
    label: >
      Cohort membership and clinical/phenotypic variables; no personally identifying information and no raw audio.
    sampling_strategies:
      - name: Recruitment and sampling
        is_sample:
          - "Yes"
        is_random:
          - "No"
        source_data:
          - Patients from specialty clinics across five North American sites
        is_representative:
          - "No"
        why_not_representative:
          - Targeted, cohort-based recruitment by disease category
        strategies:
          - Purposive sampling of predefined disease cohorts
    missing_information:
      - name: Potential missingness
        missing:
          - Some participants required multiple sessions; session-level variability may occur
        why_missing:
          - Operational constraints and multi-session completion for some participants
subpopulations:
  - name: Adult cohort and disease categories
    identification:
      - Adult cohort; predefined disease categories (voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders)
    distribution:
      - 306 participants across five North American sites (adult cohort in v1.0)
is_deidentified:
  name: De-identification summary
  description:
    - HIPAA Safe Harbor identifiers removed (e.g., names, contact details, dates finer than year, IDs, etc.)
    - State and province removed; country of data collection retained
    - Free-speech transcripts removed
    - Raw audio waveforms omitted in v1.0; only derived spectrograms/features released
sensitive_elements:
  - name: Sensitive health-related data
    description:
      - Contains de-identified health, demographic, and validated questionnaire data; initial release deemed low risk
acquisition_methods:
  - name: Data acquisition
    description:
      - Standardized protocol post-consent; demographic and clinical questionnaires; targeted confounder questions; voice tasks (e.g., sustained vowel)
      - Data entered via custom tablet application; headset used when possible; exports from REDCap using an open-source library
    was_directly_observed: "Yes (voice tasks recorded and then transformed to derived data)"
    was_reported_by_subjects: "Yes (validated and targeted questionnaires)"
    was_inferred_derived: "Yes (spectrograms, acoustic/phonetic/prosodic features, ASR transcriptions)"
    was_validated_verified: "Validated questionnaires; standardized collection protocol"
collection_mechanisms:
  - name: Collection mechanisms
    description:
      - Custom tablet application; headset microphone where possible; REDCap-based data capture and export
data_collectors:
  - name: Data collectors
    description:
      - Project investigators at five North American specialty clinic sites
ethical_reviews:
  - name: Ethics approvals
    description:
      - Approved by the University of South Florida Institutional Review Board; submitted for review to the University of Toronto Research Ethics Board
preprocessing_strategies:
  - name: Audio preprocessing and feature derivation
    description:
      - Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter
      - Spectrograms via STFT (25 ms window, 10 ms hop, 512-point FFT)
      - Acoustic features with openSMILE; phonetic/prosodic features with Parselmouth/Praat; additional audio components via torchaudio
    used_software:
      - name: openSMILE
      - name: Parselmouth
      - name: Praat
      - name: torchaudio
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
cleaning_strategies:
  - name: Risk reduction and data cleaning
    description:
      - Removal of HIPAA Safe Harbor identifiers; removal of state/province; retention of country only
      - Removal of free-speech transcripts
      - Omission of raw audio waveforms from v1.0
labeling_strategies:
  - name: Transcription
    description:
      - Automatic speech transcriptions generated using OpenAI Whisper Large; free-speech transcripts removed prior to release
raw_sources:
  - name: Raw data availability
    description:
      - Raw audio was collected but is not released in v1.0; future releases aim to include voice data with additional security precautions
existing_uses: []
use_repository:
  - name: Project documentation
    description:
      - Documentation and usage guidance are available at the project website (https://docs.b2ai-voice.org)
other_tasks: []
future_use_impacts:
  - name: Risk and future releases
    description:
      - Initial release contains low-risk derived data only; raw audio excluded to mitigate re-identification risk.
        Future releases plan to include voice data with additional security precautions.
discouraged_uses: []
third_party_sharing:
  name: Distribution to third parties
  description: >
    Yes. Distributed through Health Data Nexus to credentialed users outside the
    project team, subject to completion of required training and signing the DUA.
distribution_formats:
  - name: Distribution formats and channels
    description:
      - Credentialed access via Health Data Nexus database portal
      - Parquet (spectrograms), TSV (static features, phenotypes), JSON (data dictionaries)
distribution_dates:
  - name: Initial public release
    description:
      - 2024-11-27
license_and_use_terms:
  name: Access, license, and terms
  description:
    - Access policy: Only credentialed users who sign the Data Use Agreement (DUA)
    - License: Bridge2AI Voice Registered Access License
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement
    - Required training: "TCPS 2: CORE 2022"
ip_restrictions: []
regulatory_restrictions: []
maintainers:
  - name: Hosting and maintenance
    description:
      - Hosted via Health Data Nexus; dataset produced and maintained by the Bridge2AI-Voice team; supported by the Temerty Centre for AI Research and Education in Medicine
errata: []
updates:
  name: Update plan
  description:
    - v1.0 is the first release; future releases aim to include raw voice data with additional safeguards
version_access:
  name: Versioning and access
  description:
    - Versioned DOI provided for v1.0 (https: "//doi.org/10.57764/qb6h-em84) and a latest-version DOI (https://doi.org/10.57764/3sg0-7440)"
is_tabular: Partially (tabular TSV/JSON plus array-like Parquet spectrograms)
external_resources:
  - name: Documentation website
    external_resources:
      - https://docs.b2ai-voice.org
    future_guarantees:
      - Not stated
    archival:
      - Not stated
    restrictions:
      - Access to data files requires credentialing, training, and DUA
  - name: REDCap instrument record
    external_resources:
      - https://doi.org/10.5281/zenodo.14148755
    future_guarantees:
      - Not stated
    archival:
      - Zenodo record for Bridge2AI Voice REDCap
    restrictions:
      - None stated
resources:
  - id: spectrograms.parquet
    name: spectrograms.parquet
    title: Spectrograms (derived from raw audio)
    description: >
      Parquet dataset containing 513 x N spectrograms per recording with participant_id,
      session_id, and task_name metadata; represents the majority of derived audio data.
    path: spectrograms.parquet
    media_type: application/x-parquet
    keywords:
      - spectrograms
      - parquet
    is_tabular: "No (array-like)"
  - id: static_features.tsv
    name: static_features.tsv
    title: Static audio features
    description: >
      One row per recording containing features derived with openSMILE, Praat, Parselmouth,
      and torchaudio; accompanied by a data dictionary in static_features.json.
    path: static_features.tsv
    media_type: text/tab-separated-values
    keywords:
      - features
      - tsv
    is_tabular: "Yes"
  - id: static_features.json
    name: static_features.json
    title: Static audio features data dictionary
    description: Data dictionary describing columns in static_features.tsv.
    path: static_features.json
    media_type: application/json
    keywords:
      - data dictionary
      - json
    is_tabular: "Yes"
  - id: phenotype.tsv
    name: phenotype.tsv
    title: Phenotypic and clinical data
    description: >
      Participant-level demographics, acoustic confounders, validated questionnaire responses;
      one row per participant; accompanied by phenotype.json.
    path: phenotype.tsv
    media_type: text/tab-separated-values
    keywords:
      - phenotype
      - clinical
      - tsv
    is_tabular: "Yes"
  - id: phenotype.json
    name: phenotype.json
    title: Phenotype data dictionary
    description: Data dictionary describing each column of phenotype.tsv.
    path: phenotype.json
    media_type: application/json
    keywords:
      - data dictionary
      - phenotype
      - json
    is_tabular: "Yes"
# D4D Datasheet for Bridge2AI-Voice Dataset
# Generation Method: Claude Code Agent Deterministic
# Source: data/preprocessed/concatenated/VOICE_preprocessed.txt (89K, 9 source files)
# Schema: src/data_sheets_schema/schema/data_sheets_schema_all.yaml
# Generated: 2025-12-20

id: https://doi.org/10.13026/37yb-1t42
name: Bridge2AI-Voice
title: Bridge2AI-Voice - An ethically-sourced, diverse voice dataset linked to health information
description: >
  The Bridge2AI-Voice project seeks to create an ethically sourced flagship dataset to enable
  future research in artificial intelligence and support critical insights into the use of voice
  as a biomarker of health. The human voice contains complex acoustic markers which have been
  linked to important health conditions including dementia, mood disorders, and cancer. When viewed
  as a biomarker, voice is a promising characteristic to measure as it is simple to collect,
  cost-effective, and has broad clinical utility. This comprehensive collection provides voice
  recordings with corresponding clinical information from participants selected based on known
  conditions which manifest within the voice waveform including voice disorders, neurological
  disorders, mood disorders, and respiratory disorders. The dataset is designed to fuel voice AI
  research, establish data standards, and promote ethical and trustworthy AI/ML development for
  voice biomarkers of health. Data collection occurs through a multi-institutional collaborative
  effort using standardized protocols, custom smartphone applications, and rigorous ethical
  oversight. The initial release (v1.0) provides 12,523 recordings for 306 participants collected
  across five sites in North America, with derived features such as spectrograms, MFCCs, acoustic
  features, and clinical phenotype data. Raw audio data is available through controlled access
  to protect participant privacy.
page: https://docs.b2ai-voice.org
language: en
keywords:
  - voice biomarker
  - acoustic biomarker
  - Bridge2AI
  - voice AI
  - voice disorders
  - neurological disorders
  - neurodegenerative disorders
  - mood disorders
  - psychiatric disorders
  - respiratory disorders
  - pediatric voice disorders
  - speech disorders
  - Parkinson's disease
  - Alzheimer's disease
  - depression
  - schizophrenia
  - bipolar disorder
  - stroke
  - ALS
  - autism
  - speech delay
  - laryngeal cancer
  - vocal fold paralysis
  - pneumonia
  - COPD
  - heart failure
  - obstructive sleep apnea
  - spectrogram
  - MFCC
  - mel-frequency cepstral coefficients
  - OpenSMILE
  - Praat
  - Parselmouth
  - federated learning
  - ethical AI
  - multimodal health data
  - electronic health records
  - EHR
  - radiomics
  - genomics
  - FAIR principles
  - CARE principles
  - PhysioNet
  - Health Data Nexus

# Motivation
purposes:
  - id: purpose-001
    response: >
      Integrate the use of voice as a biomarker of health in clinical care by generating a
      substantial multi-institutional, ethically sourced, and diverse voice database linked to
      multimodal health biomarkers to fuel voice AI research and build predictive models to assist
      in screening, diagnosis, and treatment of a broad range of diseases.
  - id: purpose-002
    response: >
      Create an ethically sourced flagship dataset to enable future research in artificial
      intelligence and support critical insights into the use of voice as a biomarker of health,
      addressing the pressing need for large, high quality, multi-institutional and diverse voice
      databases linked to other health biomarkers.
  - id: purpose-003
    response: >
      Establish standards, best practices, and guidelines for voice data collection and analysis
      to advance the field of acoustic biomarkers by developing new standards that are AI/ML
      friendly and enable voice to emerge as a biomarker of health.

tasks:
  - id: task-001
    response: >
      Enable development of AI/ML predictive models for screening, diagnosis, and treatment of
      voice disorders including laryngeal cancers, vocal fold paralysis, and benign laryngeal
      lesions, leveraging acoustic changes in phonation resulting from changes in vocal fold
      vibratory function.
  - id: task-002
    response: >
      Support machine learning models for neurological and neurodegenerative disorders including
      Alzheimer's disease, Parkinson's disease, stroke, and ALS, detecting voice and speech
      changes such as slowed speech, low frequency, monotonous speech, vocal tremor, dysarthria,
      and aphasia.
  - id: task-003
    response: >
      Develop AI algorithms for mood and psychiatric disorder detection including depression,
      schizophrenia, and bipolar disorders, identifying vocal markers such as decreased
      fundamental frequency, monotonous speech patterns, and anxiety-related increases in F0.
  - id: task-004
    response: >
      Create machine learning models for respiratory disorder screening and therapeutic monitoring
      using respiratory sounds, cough sounds, and voice, applicable to conditions such as
      pneumonia, COPD, heart failure, and obstructive sleep apnea.
  - id: task-005
    response: >
      Build AI models for pediatric voice and speech disorder detection including autism spectrum
      disorder and speech delays, addressing the relative scarcity of pediatric voice data and
      associated ethical challenges.
  - id: task-006
    response: >
      Promote application of AI/ML for voice research through workforce development, curriculum
      creation, and fostering collaborations especially with researchers from underserved
      communities, building bridges between medical voice research, acoustic engineers, and the
      AI/ML community.

addressing_gaps:
  - id: gap-001
    response: >
      Address the lack of large, high quality, multi-institutional and diverse voice databases
      linked to multimodal health biomarkers (demographics, imaging, genomics, risk factors)
      necessary to fuel voice AI research and answer tangible clinical questions.
  - id: gap-002
    response: >
      Overcome limitations in existing voice and psychiatric disorder research that has relied on
      small datasets with limited demographic diversity reporting, lack of standardized data
      collection protocols precluding meta-analysis, and possible confounders limiting external
      validity and clinical usability.
  - id: gap-003
    response: >
      Fill the gap in pediatric voice and speech analysis research, which is sparser partly due
      to ethical concerns and challenges in data acquisition for this cohort, particularly for
      autism and speech delay detection.
  - id: gap-004
    response: >
      Establish missing standards for voice data collection, acoustic analysis, and ethical
      frameworks for consenting to voice data collection, sharing, and utilization in the context
      of voice AI technology development and clinical adoption.

# Creators and Contributors
creators:
  - id: creator-001
    name: Yael Bensoussan
    description: Contact PI/Project Leader, University of South Florida, Department of Otolaryngology, Assistant Professor
  - id: creator-002
    name: Jean-Christophe BÃ©lisle-Pipon
    description: Co-Principal Investigator, Bioethics lead
  - id: creator-003
    name: David Dorr
    description: Co-Principal Investigator
  - id: creator-004
    name: Satrajit Ghosh
    description: Co-Principal Investigator
  - id: creator-005
    name: Philip R.O. Payne
    description: Co-Principal Investigator
  - id: creator-006
    name: Maria Ellen Powell
    description: Co-Principal Investigator
  - id: creator-007
    name: Anais Rameau
    description: Co-Principal Investigator
  - id: creator-008
    name: Vardit Ravitsky
    description: Co-Principal Investigator
  - id: creator-009
    name: Alexandros Sigaras
    description: Co-Principal Investigator
  - id: creator-010
    name: Olivier Elemento
    description: Co-Principal Investigator
  - id: creator-011
    name: Alistair Johnson
    description: Co-Principal Investigator, data management and PhysioNet distribution lead
  - id: creator-012
    name: Jennifer Siu
    description: Co-Investigator
  - id: creator-013
    name: Bridge2AI-Voice Consortium
    description: Multidisciplinary consortium of voice experts, AI engineers, bioethicists, and social scientists

funders:
  - id: funder-001
    name: NIH Office of the Director
    description: >
      Funded through National Institutes of Health grant 3OT2OD032720-01S3 (Bridge2AI: Voice as
      a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand
      disease like never before). Opportunity Number: OTA-21-008. Project dates: September 1,
      2022 to November 30, 2026. Total funding in 2025: $4,660,942 (Direct Costs: $4,072,321,
      Indirect Costs: $588,621). Administered by NIH Office of the Director through the Bridge2AI
      Program. Study Section: Data Coordination, Mapping, and Modeling [DCMM].
  - id: funder-002
    name: National Institute of Biomedical Imaging and Bioengineering
    description: >
      NIBIB supports PhysioNet managed by MIT Laboratory for Computational Physiology under NIH
      grant number R01EB030362, which serves as a distribution platform for the Bridge2AI-Voice
      dataset.

# Composition
instances:
  - id: instance-001
    description: >
      Adult participants presenting at specialty clinics and institutions across five sites in
      North America. Participants were selected based on membership to five predetermined disease
      cohort groups: Respiratory disorders, Voice disorders, Neurological disorders, Mood
      disorders, and Pediatric. As of v1.1, only data from the adult cohort is available. The
      initial release (v1.0) provides 306 participants with 12,523 recordings collected through
      standardized protocols.
    instance_type: >
      Human participants recruited from specialty clinics at multi-institutional sites. Data
      collection conducted between 2022 and 2026 through IRB-approved protocols with informed
      consent.

subsets:
  - id: subset-001
    name: Public Access Dataset (PhysioNet Registered Access)
    description: >
      Contains derived features from voice recordings including spectrograms, MFCCs, acoustic
      features (OpenSMILE), phonetic and prosodic features (Parselmouth and Praat), and
      transcriptions (OpenAI Whisper). Also includes phenotype data with demographics, acoustic
      confounders, and responses to validated questionnaires. Available through PhysioNet with
      registered access requiring data use agreement. HIPAA Safe Harbor identifiers removed,
      state/province removed, country retained. Audio waveforms omitted, only derived features
      available. Free speech transcripts removed to protect privacy.
  - id: subset-002
    name: Controlled Access Raw Audio Dataset
    description: >
      Original raw audio waveforms available through controlled access only to protect participant
      privacy. Interested users can request access by contacting DACO@b2ai-voice.org. Raw audio
      data disseminated through Data Access Compliance Office (DACO) requiring distinct
      application and formal vetting. Covered under Certificate of Confidentiality which must be
      asserted against compulsory legal demands.

sampling_strategies:
  - id: sampling-001
    description: >
      Patients presenting at specialty clinics and institutions were screened for inclusion and
      exclusion criteria prior to their visit by project investigators. Participants were selected
      based on membership to five predetermined disease cohort groups to ensure representation
      across conditions affecting voice: (1) Voice Disorders - laryngeal cancers, vocal fold
      paralysis, benign laryngeal lesions; (2) Neurological and Neurodegenerative Disorders -
      Alzheimer's, Parkinson's, stroke, ALS; (3) Mood and Psychiatric Disorders - depression,
      schizophrenia, bipolar disorders; (4) Respiratory disorders - pneumonia, COPD, heart
      failure, obstructive sleep apnea; (5) Pediatric diseases - autism, speech delay.
    is_sample:
      - true
    is_random:
      - false
    is_representative:
      - false
    strategies:
      - Targeted recruitment from specialty clinics representing five disease cohort categories
      - Screening based on known conditions manifesting within voice waveform
      - Multi-institutional enrollment across five sites in North America
      - Standardized inclusion and exclusion criteria applied by investigators

subpopulations:
  - id: subpop-001
    name: Voice Disorders cohort
    description: >
      Participants with laryngeal disorders including laryngeal cancers, vocal fold paralysis,
      and benign laryngeal lesions that affect vocal fold shape, mass, density, and tension
      resulting in changes in vibratory function and phonation.
  - id: subpop-002
    name: Neurological and Neurodegenerative Disorders cohort
    description: >
      Participants with conditions such as Alzheimer's disease, Parkinson's disease, stroke, and
      ALS exhibiting voice and speech changes including slowed speech, low frequency, monotonous
      speech, vocal tremor, dysarthria, and aphasia.
  - id: subpop-003
    name: Mood and Psychiatric Disorders cohort
    description: >
      Participants with depression, schizophrenia, bipolar disorders, and anxiety disorders
      showing vocal changes such as decreased fundamental frequency, monotonous speech, and
      anxiety-related increases in F0.
  - id: subpop-004
    name: Respiratory Disorders cohort
    description: >
      Participants with respiratory conditions including pneumonia, COPD, heart failure, and
      obstructive sleep apnea where respiratory sounds, cough sounds, and voice are used for
      diagnostic and monitoring purposes.
  - id: subpop-005
    name: Pediatric cohort
    description: >
      Pediatric participants with voice and speech disorders including autism spectrum disorder
      and speech delays. Data collection for this cohort addresses ethical concerns and
      acquisition challenges specific to pediatric populations. Note: As of v1.1, pediatric data
      not yet released.

# Collection Process
collection_mechanisms:
  - id: collection-001
    description: >
      Data collection conducted using a custom smartphone application on tablet with headset used
      when possible. Standardized protocol for data collection adopted across all sites. Single
      session sufficient for most participants, though subset required multiple sessions resulting
      in more than one session per participant in dataset.
  - id: collection-002
    description: >
      Multi-institutional data collection across five specialty clinic sites in North America.
      Patients presenting at clinics screened for eligibility, consented for data collection
      initiative and data sharing. Enrollment occurred between 2022 and 2026 under IRB-approved
      protocols.
  - id: collection-003
    description: >
      Data collection protocol involved: (1) demographic information collection, (2) health
      questionnaires, (3) targeted questionnaires about known voice confounders, (4) disease-
      specific information, (5) voice recording tasks such as sustained phonation of vowel sounds,
      (6) conventional acoustic tasks including respiratory sounds, cough sounds, and free speech
      prompts. Data exported and converted from REDCap using open source b2aiprep library.

acquisition_methods:
  - id: acquisition-001
    description: >
      Voice recording tasks capturing voice, speech, and language data relating to health. Tasks
      include sustained phonation of vowel sounds, conventional acoustic tasks including
      respiratory sounds, cough sounds, and free speech prompts. Recordings performed using custom
      smartphone application with headset when possible to standardize acoustic quality.
  - id: acquisition-002
    description: >
      Self-reported demographic and medical history questionnaires completed by participants who
      consent. Disease-specific validated questionnaires administered. Targeted questionnaires
      inquiring about known confounders for voice.
  - id: acquisition-003
    description: >
      Electronic health record (EHR) access for participants who consent, permitting investigators
      to access medical information through EHR platforms to perform gold standard validation of
      diagnoses and symptoms. Linkage to multimodal health biomarkers including radiomics and
      genomics.

# Preprocessing, Cleaning, and Labeling
preprocessing_strategies:
  - id: preproc-001
    description: >
      Raw audio preprocessing by converting to monaural and resampling to 16 kHz with Butterworth
      anti-aliasing filter applied. Standardization ensures consistent format across all
      recordings for downstream feature extraction.
    preprocessing_details:
      - Conversion to monaural audio
      - Resampling to 16 kHz sampling rate
      - Butterworth anti-aliasing filter applied
      - Standardized format enables consistent feature extraction
  - id: preproc-002
    description: >
      Spectrogram extraction - Time-frequency representations computed using short-time Fast
      Fourier Transform (FFT) with 25ms window size, 10ms hop length, and 512-point FFT. Output
      spectrograms have 513xN dimensions where N is proportional to audio length.
    preprocessing_details:
      - Short-time FFT with 25ms window
      - 10ms hop length
      - 512-point FFT
      - Output dimension 513xN
  - id: preproc-003
    description: >
      Mel-frequency cepstral coefficients (MFCC) extraction - 60 MFCCs extracted from spectrograms.
      MFCCs capture perceptually-relevant spectral envelope characteristics important for voice
      analysis. Output dimension 60xN.
    preprocessing_details:
      - 60 MFCC coefficients extracted
      - Derived from spectrograms
      - Output dimension 60xN
      - Captures spectral envelope characteristics
  - id: preproc-004
    description: >
      Acoustic feature extraction using OpenSMILE (Speech and Music Interpretation by Large-space
      Extraction), capturing temporal dynamics and acoustic characteristics. Features provided in
      static_features.tsv with one row per unique recording.
    preprocessing_details:
      - OpenSMILE feature extraction
      - Temporal dynamics captured
      - Acoustic characteristics quantified
      - Static features per recording
  - id: preproc-005
    description: >
      Phonetic and prosodic feature computation using Parselmouth and Praat, providing measures
      of fundamental frequency, formants, and voice quality. Features documented in
      static_features.json data dictionary.
    preprocessing_details:
      - Parselmouth and Praat feature extraction
      - Fundamental frequency (F0) measurement
      - Formant analysis
      - Voice quality metrics
  - id: preproc-006
    description: >
      Transcription generation using OpenAI's Whisper Large model. Automated speech recognition
      applied to audio recordings. Free speech transcripts subsequently removed from public
      release to protect participant privacy.
    preprocessing_details:
      - OpenAI Whisper Large model
      - Automated transcription of audio
      - Free speech transcripts removed for privacy
      - Structured task transcripts may be retained
  - id: preproc-007
    description: >
      Data export and conversion from REDCap using open source b2aiprep library developed by the
      team. Phenotype data merged into tab-delimited format with data dictionary (phenotype.json)
      providing column descriptions.
    preprocessing_details:
      - REDCap data export
      - b2aiprep library conversion
      - Tab-delimited phenotype file generation
      - JSON data dictionary creation

cleaning_strategies:
  - id: cleaning-001
    description: >
      HIPAA Safe Harbor de-identification applied. Identifiers removed include: names, geographic
      locators (state/province removed, country retained), dates at resolution finer than years,
      phone/fax numbers, email addresses, IP addresses, Social Security Numbers, medical record
      numbers, health plan beneficiary numbers, device identifiers, license numbers, account
      numbers, vehicle identifiers, website URLs, full face photos, biometric identifiers, and
      any unique identifiers.
    cleaning_details:
      - HIPAA Safe Harbor compliance
      - 18 identifier categories removed
      - Geographic data limited to country level
      - Date precision limited to year
      - Biometric identifiers removed
  - id: cleaning-002
    description: >
      Privacy protection measures for public release - Audio waveforms omitted from public dataset,
      only derived features (spectrograms, MFCCs, acoustic features) made available. Free speech
      transcripts removed. Raw audio available only through controlled access with DACO approval.
    cleaning_details:
      - Audio waveforms excluded from public release
      - Derived features only in public dataset
      - Free speech transcripts removed
      - Raw audio requires controlled access
  - id: cleaning-003
    description: >
      Data standardization across multi-institutional sites through use of standardized protocols,
      common data collection application, and REDCap data management system. Ensures consistency
      and quality across five collection sites.
    cleaning_details:
      - Standardized collection protocols
      - Common smartphone application
      - REDCap data management
      - Multi-site harmonization

# Uses
intended_uses:
  - id: use-001
    description: >
      Primary intended use is development and validation of AI/ML models for voice as a biomarker
      of health, supporting screening, diagnosis, and treatment of voice disorders, neurological
      disorders, mood disorders, respiratory disorders, and pediatric speech disorders.
  - id: use-002
    description: >
      Research into acoustic biomarkers and development of standards for voice data collection
      and analysis. Establishing best practices for AI/ML-friendly voice datasets and contributing
      to the field's maturation as a clinical diagnostic modality.
  - id: use-003
    description: >
      Training and education in voice AI research through workforce development initiatives,
      curriculum creation, and fostering collaborations between medical voice researchers,
      acoustic engineers, and AI/ML specialists, especially from underserved communities.
  - id: use-004
    description: >
      Multimodal health research combining voice data with EHR information, radiomics, genomics,
      and other health biomarkers to understand complex disease relationships and improve
      diagnostic accuracy.
  - id: use-005
    description: >
      Model dataset for ethical AI development in healthcare, demonstrating integration of
      bioethics guidance, ethical data collection practices, informed consent processes, privacy
      protection through federated learning, and trustworthy AI/ML development from data
      generation through clinical adoption.

discouraged_uses:
  - id: discouraged-001
    description: >
      Direct clinical decision-making without appropriate validation. Dataset is for research
      purposes. Any AI/ML models developed should undergo appropriate clinical validation,
      regulatory approval, and testing before use in patient care or clinical decision support.
  - id: discouraged-002
    description: >
      Re-identification attempts or efforts to contact participants. Dataset is de-identified per
      HIPAA Safe Harbor standards and covered under Certificate of Confidentiality. Attempts to
      re-identify participants or make contact violate ethical principles and data use agreements.
  - id: discouraged-003
    description: >
      Uses that violate participant consent or data use agreement terms. Recipients must adhere
      to Data Transfer and Use Agreement (DTUA) terms including restrictions on sharing,
      requirements for secure storage, prohibitions on commercial use (for public dataset), and
      limitations on authorized personnel.
  - id: discouraged-004
    description: >
      Development of surveillance technologies or applications that could be used for
      discrimination, bias amplification, or harm to vulnerable populations. Voice data contains
      sensitive health information and could encode biases that require careful ethical
      consideration.

# Distribution
license: Bridge2AI Voice Registered Access License
license_and_use_terms:
  id: license-001
  name: Bridge2AI Voice Registered Access License
  description: >
    Public access dataset distributed through PhysioNet under Bridge2AI Voice Registered Access
    License. Only registered users who sign the specified Data Use Agreement (Bridge2AI Voice
    Registered Access Agreement) can access files. Data covered under Certificate of
    Confidentiality which must be asserted against compulsory legal demands. Raw audio data
    available through controlled access only via Data Access Compliance Office (DACO) requiring
    distinct application. Recipient must adhere to PhysioNet requirements managed by MIT
    Laboratory for Computational Physiology, supported by NIBIB under grant R01EB030362.
  license_terms:
    - Registered access required
    - Data Use Agreement signature mandatory
    - Use restricted to authorized persons listed in agreement
    - No sharing with third parties without prior written consent
    - Appropriate administrative, technical, physical safeguards required
    - Compliance with applicable laws, rules, regulations, professional standards
    - Public disclosure of results encouraged in open-access journals
    - Recognition of data source required in publications
    - Certificate of Confidentiality protections apply
    - Raw audio requires separate controlled access application
    - PhysioNet platform requirements apply
    - Two-year term from start date or project completion

distribution_formats:
  - id: format-001
    name: Parquet for spectrograms
    description: >
      Spectrograms stored in Parquet format (spectrograms.parquet). Each element contains
      participant_id, session_id, task_name, and 513xN dimension spectrogram array. Compatible
      with Python datasets library and common data science tools.
    access_urls:
      - https://physionet.org/content/b2ai-voice/
  - id: format-002
    name: Parquet for MFCCs
    description: >
      Mel-frequency cepstral coefficients stored in Parquet format (mfcc.parquet). Contains
      60xN dimension MFCC arrays derived from spectrograms. Compatible with Python datasets
      library and common data science tools.
    access_urls:
      - https://physionet.org/content/b2ai-voice/
  - id: format-003
    name: TSV for phenotype data
    description: >
      Tab-delimited phenotype file (phenotype.tsv) with one row per unique participant. Contains
      demographics, acoustic confounders, and validated questionnaire responses. Accompanied by
      JSON data dictionary (phenotype.json) with column descriptions.
    access_urls:
      - https://physionet.org/content/b2ai-voice/
  - id: format-004
    name: TSV for static features
    description: >
      Tab-delimited static features file (static_features.tsv) with one row per unique recording.
      Contains OpenSMILE, Praat, Parselmouth, and torchaudio features. Accompanied by JSON data
      dictionary (static_features.json) with feature descriptions.
    access_urls:
      - https://physionet.org/content/b2ai-voice/
  - id: format-005
    name: Raw audio (controlled access only)
    description: >
      Original raw audio waveforms available through controlled access only. Interested users
      contact DACO@b2ai-voice.org for application process. Disseminated through Data Access
      Compliance Office with formal vetting and approval process.
    access_urls:
      - Contact DACO@b2ai-voice.org

# Maintenance
maintainers:
  - id: maintainer-001
    name: Bridge2AI-Voice Consortium
    description: >
      Multidisciplinary consortium responsible for dataset maintenance including data collection,
      curation, standards development, ethics oversight, and distribution. Led by University of
      South Florida with multi-institutional partnerships.
    maintainer_details:
      - University of South Florida (lead institution)
      - Multi-institutional data collection sites (five sites in North America)
      - MIT Laboratory for Computational Physiology (PhysioNet distribution)
      - Data Access Compliance Office (DACO) for controlled access
      - Bioethics and social science teams
      - Standards and tool development teams
      - Workforce development and education teams
  - id: maintainer-002
    name: PhysioNet / MIT Laboratory for Computational Physiology
    description: >
      PhysioNet platform managed by MIT Laboratory for Computational Physiology serves as primary
      distribution mechanism for public access dataset. Supported by NIBIB under NIH grant
      R01EB030362.

updates:
  id: updates-001
  name: Versioned releases with ongoing data collection
  description: >
    Dataset updated with versioned releases as data collection progresses. Initial release v1.0
    published January 17, 2025 with 12,523 recordings from 306 participants. v1.1 released
    January 17, 2025 adding MFCC features. v2.0.0 released April 16, 2025. v2.0.1 released
    August 18, 2025. Latest version available at https://doi.org/10.13026/37yb-1t42. Data
    collection ongoing through November 30, 2026. Version-specific documentation maintained.
    As of v1.1, only adult cohort data available; pediatric cohort data planned for future
    releases with additional privacy precautions.
  frequency: Periodic versioned releases during data collection period (2022-2026)
  update_details:
    - v1.0 released January 17, 2025 - initial release with 306 participants, 12,523 recordings
    - v1.1 released January 17, 2025 - added MFCC features
    - v2.0.0 released April 16, 2025 - expanded participant cohort
    - v2.0.1 released August 18, 2025 - latest version
    - Ongoing data collection through November 30, 2026
    - Future releases planned with additional participants and pediatric cohort
    - Raw audio data access planned for future releases with additional security precautions
    - Version-specific documentation maintained
    - DOI for latest version vs version-specific DOIs

retention_limit:
  id: retention-001
  name: Data retention and disposition
  description: >
    Data Transfer and Use Agreement specifies retention requirements. Upon termination or
    expiration of agreement (two years after start date, project completion, or ethics approval
    expiration), data shall be destroyed per provider instructions with written certification
    required within 30 days. Recipient may retain one copy to extent necessary to comply with
    records retention requirements under law, regulation, institutional policy, and for research
    integrity and verification purposes. Restrictions apply to archival copies as long as
    recipient holds data.
  retention_details:
    - Two-year agreement term from start date
    - Data destruction required upon termination unless retention justified
    - One archival copy permitted for compliance and verification
    - Written certification of destruction required within 30 days
    - Ongoing restrictions apply to retained copies
    - Provider may unilaterally amend if federal sponsor requires

# Ethics and Human Subjects
human_subject_research:
  id: hsr-001
  name: Bridge2AI-Voice Human Subjects Research
  description: >
    Data collection and sharing approved by University of South Florida Institutional Review
    Board. Participants provided written informed consent for data collection initiative and
    data sharing. Consent process includes authorization for voice data collection, access to
    medical information through EHR platforms for gold standard validation, and permission to
    share research data. Bioethics guidance integrated throughout study design and conduct.
    Ethics module develops new guidelines for consenting to voice data collection, voice data
    sharing, and utilization in context of voice AI technology. Project addresses ethical and
    trustworthy issues from voice data generation and AI/ML research through clinical adoption
    and downstream health decisions.
  involves_human_subjects: true
  irb_approval:
    - University of South Florida Institutional Review Board approval
  ethics_review_board:
    - University of South Florida Institutional Review Board

sensitive_elements:
  - id: sensitive-001
    description: >
      Voice recordings contain personally identifiable information and are considered biometric
      identifiers under HIPAA. Raw audio waveforms omitted from public release to protect privacy.
      Available only through controlled access with DACO approval and formal vetting process.
    sensitive_elements_present: true
    sensitivity_details:
      - Voice as biometric identifier
      - Raw audio waveforms
      - Speech patterns and characteristics
      - Controlled access required for raw audio
  - id: sensitive-002
    description: >
      Electronic health record (EHR) data accessed with participant consent for gold standard
      validation of diagnoses and symptoms. Medical information linked to voice data provides
      sensitive health information requiring protection.
    sensitive_elements_present: true
    sensitivity_details:
      - EHR medical information
      - Diagnoses and symptoms
      - Disease-specific clinical data
      - Multimodal health biomarkers
  - id: sensitive-003
    description: >
      Demographic information and geographic data collected but de-identified for public release.
      State and province removed, only country retained. Protected by HIPAA Safe Harbor
      de-identification standards.
    sensitive_elements_present: true
    sensitivity_details:
      - Demographic data (de-identified)
      - Geographic information (state/province removed)
      - Medical history questionnaires
      - Disease-specific validated questionnaires
  - id: sensitive-004
    description: >
      Dataset covered under Certificate of Confidentiality which must be asserted against
      compulsory legal demands such as court orders and subpoenas for identifying information
      or characteristics of research participants. Provides additional legal protections beyond
      standard de-identification.
    sensitive_elements_present: true
    sensitivity_details:
      - Certificate of Confidentiality coverage
      - Protection against compulsory legal demands
      - Court order and subpoena protection
      - Participant identification protection

# Data Governance and External Resources
external_resources:
  - id: resource-001
    name: PhysioNet Dataset Landing Page
    description: Primary distribution platform for public access dataset with registered access
    external_resources:
      - https://physionet.org/content/b2ai-voice/
  - id: resource-002
    name: Bridge2AI-Voice Project Documentation
    description: Comprehensive project documentation and resources
    external_resources:
      - https://docs.b2ai-voice.org
  - id: resource-003
    name: Bridge2AI-Voice GitHub Repository
    description: Open source code repository including b2aiprep library and documentation dashboard
    external_resources:
      - https://github.com/eipm/bridge2ai-docs
  - id: resource-004
    name: NIH RePORTER Project Details
    description: Federal grant information and project details
    external_resources:
      - https://reporter.nih.gov/project-details/11376382
  - id: resource-005
    name: Health Data Nexus
    description: Alternative data repository platform
    external_resources:
      - https://healthdatanexus.ai/content/b2ai-voice/1.0/
  - id: resource-006
    name: Zenodo Archive
    description: Additional dataset documentation and software releases
    external_resources:
      - https://doi.org/10.5281/zenodo.13834653
  - id: resource-007
    name: PhysioNet Platform
    description: Research resource for complex physiologic signals
    external_resources:
      - https://physionet.org
  - id: resource-008
    name: Interspeech 2024 Protocol Publication
    description: >
      Publication describing multi-disorder voice protocol development through team science
      approach involving clinical expertise, bioethics, standards, and DEI
    external_resources:
      - https://doi.org/10.21437/Interspeech.2024-1926
  - id: resource-009
    name: Data Access Compliance Office
    description: Contact for controlled access to raw audio data
    external_resources:
      - mailto:DACO@b2ai-voice.org
  - id: resource-010
    name: Bridge2AI Program
    description: Parent NIH Common Fund program supporting AI-ready biomedical datasets
    external_resources:
      - https://bridge2ai.org
  - id: resource-011
    name: b2aiprep Software Library
    description: Open source library for preprocessing raw audio and phenotype data
    external_resources:
      - https://github.com/sensein/b2aiprep

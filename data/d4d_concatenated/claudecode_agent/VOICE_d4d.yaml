id: bridge2ai-voice-dataset
name: Bridge2AI-Voice
title: Bridge2AI-Voice - An ethically-sourced, diverse voice dataset linked to health information
description: >-
  The Bridge2AI-Voice dataset contains comprehensive voice, speech, and language data linked to health information, collected
  through a multi-institutional initiative funded by NIH's Bridge to Artificial Intelligence program. The dataset includes
  samples from conventional acoustic tasks such as respiratory sounds, cough sounds, and free speech prompts. Participants
  perform speaking tasks and complete self-reported demographic and medical history questionnaires, as well as disease-specific
  validated questionnaires. The project aims to integrate voice as a biomarker of health in clinical care by generating a
  substantial, ethically sourced, and diverse voice database linked to multimodal health biomarkers (EHR, radiomics, genomics)
  to fuel voice AI research and build predictive models for screening, diagnosis, and treatment across a broad range of diseases.
  Data collection is conducted via smartphone application linked to electronic health records, supported by federated learning
  technology to protect data privacy. Version 1.1 provides 12,523 recordings for 306 participants collected across five sites
  in North America. The dataset is distributed through PhysioNet and Health Data Nexus under a registered access license.



  Governance model:

  description: Data Access Compliance Office (DACO) oversight model with University of South Florida as Provider Institution.
  All data access requires DACO review and approval of Data Transfer and Use Agreement (DTUA). Recipients must have IRB approval
  for their research use. DACO monitors compliance with agreement terms and investigates violations.


  governance_authority: University of South Florida

  oversight_body: Data Access Compliance Office (DACO)

  contact: DACO@b2ai-voice.org

  requirements:
    - DTUA application and approval
    - Recipient IRB approval required
    - Institutional authorized official signature
    - Compliance monitoring
    - Periodic renewal
    - Violation investigation procedures
  description: Provider Institution (University of South Florida) retains ultimate authority over data sharing decisions,
  agreement amendments, and termination. May unilaterally amend DTUA if Federal sponsor requires; recipients may object resulting
  in immediate termination and data destruction.


  governance_authority: Provider Institution

  decision_making:
    - Approval/denial of access requests
    - DTUA amendment authority
    - Unilateral amendment if Federal sponsor requires
    - Termination authority
    - Interpretation of agreement terms
page: https://physionet.org/content/b2ai-voice/
version: '1.1'
license: Bridge2AI Voice Registered Access License
language: en
keywords:
- voice
- speech
- bridge2ai
- voice biomarker
- acoustic biomarker
- AI
- machine learning
- health
- disease screening
- voice disorders
- neurological disorders
- mood disorders
- respiratory disorders
- pediatric
- PhysioNet
- federated learning
- ethical AI
- FAIR data
- CARE principles
- multimodal biomarkers
purposes:
- description: >-
    To integrate the use of voice as a biomarker of health in clinical care by generating a substantial multi-institutional,
    ethically sourced, and diverse voice database linked to multimodal health biomarkers (EHR, radiomics, genomics) to fuel
    voice AI research and build predictive models to assist in screening, diagnosis, and treatment of a broad range of diseases.


    Key details:

    - Voice is a promising biomarker as it is simple to collect, cost-effective, and has broad clinical utility

    - Recent AI advances enable extraction of prognostically useful information from voice data

    - Multi-institutional collaboration ensures diverse, representative datasets

    - Ethical framework ensures trustworthy AI development from data generation to clinical adoption
  response: >-
    To integrate the use of voice as a biomarker of health in clinical care by generating a substantial multi-institutional,
    ethically sourced, and diverse voice database linked to multimodal health biomarkers (EHR, radiomics, genomics) to fuel
    voice AI research and build predictive models to assist in screening, diagnosis, and treatment of a broad range of diseases.


    Key details:

    - Voice is a promising biomarker as it is simple to collect, cost-effective, and has broad clinical utility

    - Recent AI advances enable extraction of prognostically useful information from voice data

    - Multi-institutional collaboration ensures diverse, representative datasets

    - Ethical framework ensures trustworthy AI development from data generation to clinical adoption
- description: >-
    To develop new standards of acoustic and voice data collection and analysis for voice AI research, introducing the field
    of acoustic biomarkers through standardized protocols and quality measures.


    Key details:

    - Standardized voice data collection protocols across sites

    - Acoustic quality standardization and calibration

    - Integration of acoustic amplifiers and quality control tools

    - Development of best practices for voice AI research
  response: >-
    To develop new standards of acoustic and voice data collection and analysis for voice AI research, introducing the field
    of acoustic biomarkers through standardized protocols and quality measures.


    Key details:

    - Standardized voice data collection protocols across sites

    - Acoustic quality standardization and calibration

    - Integration of acoustic amplifiers and quality control tools

    - Development of best practices for voice AI research
- description: >-
    To create software and cloud infrastructure for automated voice data collection through smartphone application that allows
    non-invasive, user-friendly, high quality voice data collection while minimizing human manipulation.


    Key details:

    - Custom tablet/smartphone application for voice recording

    - Integrated acoustic quality standardization

    - Federated learning technology for privacy-preserving multi-institutional analysis

    - Cloud infrastructure supporting scalable data collection
  response: >-
    To create software and cloud infrastructure for automated voice data collection through smartphone application that allows
    non-invasive, user-friendly, high quality voice data collection while minimizing human manipulation.


    Key details:

    - Custom tablet/smartphone application for voice recording

    - Integrated acoustic quality standardization

    - Federated learning technology for privacy-preserving multi-institutional analysis

    - Cloud infrastructure supporting scalable data collection
tasks:
- description: >-
    Task type: AI/ML model development


    Enable AI/ML research for disease screening, diagnosis, and treatment monitoring across five disease categories: (1) Vocal
    Pathologies (laryngeal cancers, vocal fold paralysis, benign laryngeal lesions), (2) Neurological and Neurodegenerative
    Disorders (Alzheimer's, Parkinson's, Stroke, ALS), (3) Mood and Psychiatric Disorders (Depression, Schizophrenia, Bipolar
    Disorders), (4) Respiratory disorders (Pneumonia, COPD, Heart Failure, OSA), and (5) Pediatric diseases (Autism, Speech
    Delay).


    Target populations:

    - Adults with voice disorders

    - Adults with neurological/neurodegenerative conditions

    - Adults with mood and psychiatric disorders

    - Adults with respiratory disorders

    - Pediatric patients (future releases)
  response: >-
    Task type: AI/ML model development


    Enable AI/ML research for disease screening, diagnosis, and treatment monitoring across five disease categories: (1) Vocal
    Pathologies (laryngeal cancers, vocal fold paralysis, benign laryngeal lesions), (2) Neurological and Neurodegenerative
    Disorders (Alzheimer's, Parkinson's, Stroke, ALS), (3) Mood and Psychiatric Disorders (Depression, Schizophrenia, Bipolar
    Disorders), (4) Respiratory disorders (Pneumonia, COPD, Heart Failure, OSA), and (5) Pediatric diseases (Autism, Speech
    Delay).


    Target populations:

    - Adults with voice disorders

    - Adults with neurological/neurodegenerative conditions

    - Adults with mood and psychiatric disorders

    - Adults with respiratory disorders

    - Pediatric patients (future releases)
- description: >-
    Task type: Biomarker discovery


    Discovery and validation of novel acoustic biomarkers associated with health conditions, expanding beyond currently recognized
    voice-disease associations to identify new clinical applications.


    Target applications:

    - Voice changes in depression (decreased fundamental frequency, monotonous speech)

    - Voice changes in anxiety (increased fundamental frequency)

    - Voice/speech changes in acute stroke (dysarthria, aphasia)

    - Voice changes in Parkinson's and ALS (slowed, low frequency, monotonous speech, vocal tremor)

    - Respiratory sounds for disease screening (croup, pneumonia, COPD)
  response: >-
    Task type: Biomarker discovery


    Discovery and validation of novel acoustic biomarkers associated with health conditions, expanding beyond currently recognized
    voice-disease associations to identify new clinical applications.


    Target applications:

    - Voice changes in depression (decreased fundamental frequency, monotonous speech)

    - Voice changes in anxiety (increased fundamental frequency)

    - Voice/speech changes in acute stroke (dysarthria, aphasia)

    - Voice changes in Parkinson's and ALS (slowed, low frequency, monotonous speech, vocal tremor)

    - Respiratory sounds for disease screening (croup, pneumonia, COPD)
- description: >-
    Task type: Clinical application


    Development of clinical decision support tools integrating voice biomarkers into healthcare workflows for screening, diagnosis,
    and therapeutic monitoring.


    Target applications:

    - Point-of-care voice screening tools

    - Remote patient monitoring using voice

    - EHR-integrated voice biomarker dashboards

    - Longitudinal disease progression tracking
  response: >-
    Task type: Clinical application


    Development of clinical decision support tools integrating voice biomarkers into healthcare workflows for screening, diagnosis,
    and therapeutic monitoring.


    Target applications:

    - Point-of-care voice screening tools

    - Remote patient monitoring using voice

    - EHR-integrated voice biomarker dashboards

    - Longitudinal disease progression tracking
- description: >-
    Task type: Multi-modal integration


    Multi-modal biomarker research integrating voice with EHR, radiomics, genomics, and other data sources to build comprehensive
    predictive models.


    Target applications:

    - Voice + EHR integration for diagnosis validation

    - Voice + genomics for personalized medicine

    - Voice + radiomics for disease staging

    - Federated learning across data modalities
  response: >-
    Task type: Multi-modal integration


    Multi-modal biomarker research integrating voice with EHR, radiomics, genomics, and other data sources to build comprehensive
    predictive models.


    Target applications:

    - Voice + EHR integration for diagnosis validation

    - Voice + genomics for personalized medicine

    - Voice + radiomics for disease staging

    - Federated learning across data modalities
- response: >
    Aim 1: Data Acquisition Module

    To build a multi-modal, multi-institutional, large scale, diverse and ethically sourced human voice database linked to
    other biomarkers of health that is AI/ML friendly to fuel voice AI research.
  description: >
    To build a multi-modal, multi-institutional, large scale, diverse and ethically sourced human voice database linked to
    other biomarkers of health that is AI/ML friendly to fuel voice AI research.
  name: Data Acquisition Module
- response: >
    Aim 2: Standard Module

    To introduce the field of acoustic biomarkers by developing new standards of acoustic and voice data collection and analysis
    for voice AI research.
  description: >
    To introduce the field of acoustic biomarkers by developing new standards of acoustic and voice data collection and analysis
    for voice AI research.
  name: Standard Module
- response: >
    Aim 3: Tool Development and Optimization

    To develop a software and cloud infrastructure for automated voice data collection through a smartphone application that
    allows non-invasive, user-friendly, high quality voice data collection while minimizing human manipulation. To implement
    Federated Learning technology to allow analysis of multi-institutional data while minimizing data sharing and preserving
    patient privacy.
  description: >
    To develop a software and cloud infrastructure for automated voice data collection through a smartphone application that
    allows non-invasive, user-friendly, high quality voice data collection while minimizing human manipulation. To implement
    Federated Learning technology to allow analysis of multi-institutional data while minimizing data sharing and preserving
    patient privacy.
  name: Tool Development and Optimization
- response: >
    Aim 4: Ethics Module

    To integrate existing scholarship, tools, and guidance with development of new standard and normative insights for identifying,
    anticipating, addressing, and providing guidance on ethical and trustworthy issues from voice data generation and AI/ML
    research and development to clinical adoption and downstream health decisions and outcomes. To develop new guidelines
    for consenting to voice data collection, voice data sharing and utilization in the context of voice AI technology.
  description: >
    To integrate existing scholarship, tools, and guidance with development of new standard and normative insights for identifying,
    anticipating, addressing, and providing guidance on ethical and trustworthy issues from voice data generation and AI/ML
    research and development to clinical adoption and downstream health decisions and outcomes. To develop new guidelines
    for consenting to voice data collection, voice data sharing and utilization in the context of voice AI technology.
  name: Ethics Module
- response: >
    Aim 5: Teaming Module

    To build bridges between the medical voice research world, the acoustic engineers, and the AI/ML world to promote the
    integration of tangible clinical application for Voice AI algorithms.
  description: >
    To build bridges between the medical voice research world, the acoustic engineers, and the AI/ML world to promote the
    integration of tangible clinical application for Voice AI algorithms.
  name: Teaming Module
- response: >
    Aim 6: Skills and Workforce Development Module

    To develop a unique curriculum on voice biomarkers of health and the development, validation, and implementation for AI
    models that are FAIR and CARE. To create a community of voice AI researchers, especially those from underserved communities,
    and foster collaborations to promote application of ML for Voice Research. To engage a broad range of learners with competency
    assessment and mentorship.
  description: >
    To develop a unique curriculum on voice biomarkers of health and the development, validation, and implementation for AI
    models that are FAIR and CARE. To create a community of voice AI researchers, especially those from underserved communities,
    and foster collaborations to promote application of ML for Voice Research. To engage a broad range of learners with competency
    assessment and mentorship.
  name: Skills and Workforce Development Module
addressing_gaps:
- description: >-
    Gap type: Dataset availability


    Address the pressing need for large, high quality, multi-institutional and diverse voice databases linked to other health
    biomarkers from various data modalities (demographics, imaging, genomics, risk factors, etc.) to fuel voice AI research
    and answer tangible clinical questions through multi-institutional collaborations between voice experts and AI engineers,
    supported by bioethicists and social scientists to ensure ethically sourced voice databases representing our populations.


    Existing limitations:

    - Previous literature used small datasets with limited demographic diversity reporting

    - Lack of standardized data collection protocols precluding meta-analysis

    - Possible confounders not controlled across studies

    - Limited external validity and clinical usability

    - Sparse pediatric voice/speech analysis data

    - Ethical concerns in data acquisition
  response: >-
    Gap type: Dataset availability


    Address the pressing need for large, high quality, multi-institutional and diverse voice databases linked to other health
    biomarkers from various data modalities (demographics, imaging, genomics, risk factors, etc.) to fuel voice AI research
    and answer tangible clinical questions through multi-institutional collaborations between voice experts and AI engineers,
    supported by bioethicists and social scientists to ensure ethically sourced voice databases representing our populations.


    Existing limitations:

    - Previous literature used small datasets with limited demographic diversity reporting

    - Lack of standardized data collection protocols precluding meta-analysis

    - Possible confounders not controlled across studies

    - Limited external validity and clinical usability

    - Sparse pediatric voice/speech analysis data

    - Ethical concerns in data acquisition
- description: >-
    Gap type: Ethical framework


    Address ethical concerns about patient privacy protection, fair representation of populations, and clinical accuracy as
    voice AI gains attention from multi-nationals (Google, Amazon, Mozilla, Apple). Influence and guide the world of voice
    AI by ensuring patient protection through ethical and fairness principles.


    Existing limitations:

    - Industry development lacks comprehensive ethical oversight

    - Privacy protection inadequate in commercial voice AI

    - Population representation biased toward majority groups

    - Clinical validation often insufficient

    - Lack of standards for consent and data governance
  response: >-
    Gap type: Ethical framework


    Address ethical concerns about patient privacy protection, fair representation of populations, and clinical accuracy as
    voice AI gains attention from multi-nationals (Google, Amazon, Mozilla, Apple). Influence and guide the world of voice
    AI by ensuring patient protection through ethical and fairness principles.


    Existing limitations:

    - Industry development lacks comprehensive ethical oversight

    - Privacy protection inadequate in commercial voice AI

    - Population representation biased toward majority groups

    - Clinical validation often insufficient

    - Lack of standards for consent and data governance
- description: >-
    Gap type: Interdisciplinary collaboration


    Build bridges between the medical voice research world, acoustic engineers, and the AI/ML community to promote integration
    of tangible clinical applications for voice AI algorithms.


    Existing limitations:

    - Siloed research communities

    - Limited clinical translation of voice AI research

    - Gap between acoustic engineering and medical applications

    - Insufficient cross-training of researchers
  response: >-
    Gap type: Interdisciplinary collaboration


    Build bridges between the medical voice research world, acoustic engineers, and the AI/ML community to promote integration
    of tangible clinical applications for voice AI algorithms.


    Existing limitations:

    - Siloed research communities

    - Limited clinical translation of voice AI research

    - Gap between acoustic engineering and medical applications

    - Insufficient cross-training of researchers
creators:
- description: >-
    Role: Principal Investigator


    Dr. Yael Emilie Bensoussan (Assistant Professor, University of South Florida, Department of Otolaryngology, Tampa, FL,
    Congressional District 15, Principal Investigator/Contact PI)
  affiliations:
  - id: university-of-south-florida
    name: University of South Florida
- description: >-
    Role: Co-Investigator


    Dr. Jean-Christophe Bélisle-Pipon (Co-Investigator, Bioethics expert)
  affiliations:
  - id: university-of-south-florida
    name: University of South Florida
- description: >-
    Role: Co-Investigator


    Dr. David A. Dorr (Co-Investigator, EHR integration and clinical informatics)
  affiliations:
  - id: oregon-health-and-science-university
    name: Oregon Health & Science University
- description: >-
    Role: Co-Investigator


    Dr. Satrajit Sujit Ghosh (Co-Investigator, Neuroimaging and voice analysis, MIT)
  affiliations:
  - id: massachusetts-institute-of-technology
    name: Massachusetts Institute of Technology
- description: >-
    Role: Co-Investigator


    Dr. Philip R.O. Payne (Co-Investigator, Biomedical informatics)
  affiliations:
  - id: washington-university-in-st.-louis
    name: Washington University in St. Louis
- description: >-
    Role: Co-Investigator


    Dr. Maria Ellen Powell (Co-Investigator, Ethics module)
  affiliations:
  - id: university-of-south-florida
    name: University of South Florida
- description: >-
    Role: Co-Investigator


    Dr. Anais Rameau (Co-Investigator, Voice disorders specialist, Weill Cornell Medicine)
  affiliations:
  - id: weill-cornell-medicine
    name: Weill Cornell Medicine
- description: >-
    Role: Co-Investigator


    Dr. Vardit Ravitsky (Co-Investigator, Bioethics)
  affiliations:
  - id: université-de-montréal
    name: Université de Montréal
- description: >-
    Role: Co-Investigator


    Dr. Alexandros Sigaras (Co-Investigator, Technical lead, Weill Cornell Medicine)
  affiliations:
  - id: weill-cornell-medicine
    name: Weill Cornell Medicine
- description: >-
    Role: Co-Investigator


    Dr. Olivier Elemento (Co-Investigator, Computational biology, Weill Cornell Medicine)
  affiliations:
  - id: weill-cornell-medicine
    name: Weill Cornell Medicine
- description: >-
    Role: Co-Investigator


    Dr. Alistair Johnson (Co-Investigator, Clinical data management, The Hospital for Sick Children)
  affiliations:
  - id: the-hospital-for-sick-children
    name: The Hospital for Sick Children
- description: >-
    Role: Consortium


    Bridge2AI-Voice Consortium including University of South Florida (lead institution), Massachusetts Institute of Technology,
    Weill Cornell Medicine, Oregon Health & Science University, Washington University in St. Louis, and other participating
    North American clinical sites.
funders:
- description: >-
    NIH Office of the Director, Bridge to Artificial Intelligence (Bridge2AI) program, grant 3OT2OD032720-01S1 (originally
    3OT2OD032720-01S3), supporting creation of ethically sourced, AI-ready biomedical datasets. Project title: "Bridge2AI:
    Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never
    before."


    Grant information:

    - Grant number 3OT2OD032720-01S1 (current), 3OT2OD032720-01S3 (referenced)

    Administering IC: NIH Office of the Director

    Opportunity Number: OTA-21-008

    Study Section: Data Coordination, Mapping, and Modeling [DCMM]

    Fiscal Year 2025 funding: $4,660,942 (total), $4,072,321 (direct costs), $588,621 (indirect costs)

    Award Notice Date: 05-September-2025

    Project Start Date: 01-September-2022

    Project End Date: 30-November-2026

    Budget Start Date: 15-September-2025

    Budget End Date: 30-November-2026

    No Cost Extension: N

    Assistance Listing Number: 93.31

    DUNS Number: 069687242

    UEI: NKAZLXLL7Z91
  name: National Institutes of Health (NIH)
- description: >-
    Additional infrastructure support from National Institute of Biomedical Imaging and Bioengineering (NIBIB) grant R01EB030362
    for PhysioNet data distribution platform managed by MIT Laboratory for Computational Physiology.


    Grant information:

    - Grant number R01EB030362

    - Supports PhysioNet infrastructure

    - MIT Laboratory for Computational Physiology
  name: NIBIB
instances:
- description: >-
    Count: 12523


    Voice and speech audio recordings from 306 participants across five clinical sites in North America, totaling 12,523 recordings.
    Recordings include sustained phonation of vowel sounds (e.g., /e/), respiratory sounds, cough sounds, and free speech
    prompts. Raw audio preprocessed to monaural 16 kHz format with Butterworth anti-aliasing filter. Original audio waveforms
    omitted from v1.0/v1.1 public releases for privacy protection.


    Format: Derived features (spectrograms, MFCCs) in Parquet format
  instance_type: Audio recordings
- description: >-
    Count: 12523


    Spectrograms computed using short-time Fast Fourier Transform (FFT) with 25ms window size, 10ms hop length, and 512-point
    FFT, resulting in 513xN dimension time-frequency representations where N is proportional to recording length.


    Format: Parquet (spectrograms.parquet)
  instance_type: Spectrograms
- description: >-
    Count: 12523


    Mel-frequency cepstral coefficients (MFCCs) with 60 coefficients extracted from spectrograms, resulting in 60xN dimension
    arrays. Added in version 1.1 release.


    Format: Parquet (mfcc.parquet)
  instance_type: MFCCs
- description: >-
    Acoustic features extracted using OpenSMILE (Speech and Music Interpretation by Large-space Extraction), capturing temporal
    dynamics and acoustic characteristics of voice recordings.


    Format: TSV (static_features.tsv)
  instance_type: Acoustic features
- description: >-
    Phonetic and prosodic features computed using Parselmouth (Python interface to Praat), providing measures of fundamental
    frequency (f0), formants, and voice quality parameters.


    Format: TSV (static_features.tsv)
  instance_type: Prosodic features
- description: >-
    Count: 306


    Demographic data from 306 participants including de-identified geographic information (country retained, state/province
    removed), age (years only), and other HIPAA Safe Harbor compliant variables.


    Format: TSV (phenotype.tsv)
  instance_type: Demographics
- description: >-
    Count: 306


    Self-reported medical history questionnaires covering health status, disease history, medication use, and lifestyle factors
    relevant to voice production.


    Format: TSV (phenotype.tsv)
  instance_type: Medical history
- description: >-
    Disease-specific validated questionnaires tailored to participant's disease cohort membership (voice disorders, neurological,
    mood, respiratory, pediatric).


    Format: TSV (phenotype.tsv)
  instance_type: Clinical questionnaires
- description: >-
    Targeted questionnaires on known confounders for voice including smoking status, vocal use patterns, environmental factors,
    and acute conditions affecting voice.


    Format: TSV (phenotype.tsv)
  instance_type: Voice confounders
- description: >-
    Electronic health record (EHR) data accessed with participant consent for gold standard validation of diagnoses and symptoms,
    linked through institutional EHR platforms.


    Access: With participant consent
  instance_type: EHR data
- description: >-
    Automated transcriptions generated using OpenAI's Whisper Large model. Free speech transcripts removed from public release
    for privacy protection (only task-based transcriptions for non-identifying prompts).


    Privacy note: Free speech transcripts removed for privacy
  instance_type: Transcriptions
subsets:
- id: voice:spectrograms
  name: Spectrograms
  description: >-
    Parquet file (spectrograms.parquet) containing time-frequency representations with participant_id, session_id, task_name,
    and 513xN dimension spectrogram arrays. One element per recording.


    Format: Parquet

    File Size: Large (dense array data)
- id: voice:mfcc
  name: Mel-frequency Cepstral Coefficients
  description: >-
    Parquet file (mfcc.parquet) containing 60xN dimension MFCC arrays derived from spectrograms. Added in version 1.1 release
    (January 17, 2025).


    Format: Parquet

    Version Added: 1.1
- id: voice:phenotype
  name: Phenotype Data
  description: >-
    Tab-delimited file (phenotype.tsv) with one row per unique participant (306 rows), containing demographics, acoustic confounders,
    and responses to validated questionnaires. Each column represents a question asked during clinical data collection within
    the custom data collection app.


    Data Dictionary: phenotype.json

    Rows: 306
  format: TSV
- id: voice:static-features
  name: Static Acoustic Features
  description: >-
    Tab-delimited file (static_features.tsv) containing features derived from raw audio using OpenSMILE, Praat, parselmouth,
    and torchaudio libraries. One row per unique recording (12,523 rows). Features include temporal dynamics, acoustic characteristics,
    fundamental frequency, formants, and voice quality measures.


    Data Dictionary: static_features.json

    Rows: 12523
  format: TSV
- id: voice:cohort-voice-disorders
  name: Voice Disorders Cohort
  description: >-
    Participants with vocal pathologies including laryngeal cancers, vocal fold paralysis, and benign laryngeal lesions. Voice
    disorders are the most studied pathologies linked to vocal changes due to effects on vocal fold shape, mass, density,
    and tension.


    Cohort: Voice disorders
- id: voice:cohort-neuro
  name: Neurological Disorders Cohort
  description: >-
    Participants with neurological and neurodegenerative conditions including Alzheimer's disease, Parkinson's disease, stroke,
    and ALS. Voice and speech alterations include dysarthria, aphasia, slowed speech, low frequency speech, monotonous speech,
    and vocal tremor.


    Cohort: Neurological disorders
- id: voice:cohort-mood
  name: Mood and Psychiatric Disorders Cohort
  description: >-
    Participants with mood and psychiatric conditions including depression, schizophrenia, and bipolar disorders. Voice changes
    associated with depression include decreased fundamental frequency and monotonous speech, while anxiety disorders show
    increased fundamental frequency.


    Cohort: Mood and psychiatric disorders
- id: voice:cohort-respiratory
  name: Respiratory Disorders Cohort
  description: >-
    Participants with respiratory conditions including pneumonia, COPD, heart failure, and obstructive sleep apnea (OSA).
    Respiratory sounds (breath, cough, voice) have long been used for diagnostic purposes.


    Cohort: Respiratory disorders
- id: voice:cohort-pediatric
  name: Pediatric Cohort
  description: >-
    Pediatric participants with conditions including autism and speech delay. Not included in version 1.1 release; planned
    for future versions. Pediatric voice/speech analysis literature is sparser due to ethical concerns and data acquisition
    challenges.


    Cohort: Pediatric

    Status: Not included in v1.1 (adult cohort only)
subpopulations:
- description: >-
    Type: Geographic diversity


    Multi-institutional participants recruited from five clinical sites across North America to ensure geographic and demographic
    diversity. Sites include University of South Florida (lead), MIT, Weill Cornell Medicine, Oregon Health & Science University,
    and other participating institutions.
- description: >-
    Type: Disease cohort stratification


    Disease cohort-based sampling targeting five categories with known voice manifestations: (1) Voice disorders, (2) Neurological/neurodegenerative
    disorders, (3) Mood/psychiatric disorders, (4) Respiratory disorders, (5) Pediatric conditions.
- description: >-
    Type: DEI-focused recruitment


    Intentional recruitment of diverse participants to address historical underrepresentation in voice AI research, following
    fairness, equity, diversity, and inclusion (DEI) principles integrated into project design.
sampling_strategies:
- description: >-
    Participants selected based on membership to five predetermined disease cohort groups identified from literature review
    as having well-recognized voice manifestations and unmet clinical needs. Patients presenting at specialty clinics screened
    for inclusion/exclusion criteria prior to enrollment.


    Sampling Method: Disease cohort-based selection

    Rationale: Target conditions with established voice-disease associations and clinical unmet needs
- description: >-
    Multi-institutional recruitment across five sites in North America to ensure geographic diversity, site-specific clinical
    expertise, and representation of different healthcare systems and patient populations.


    Sampling Method: Multi-site geographic sampling

    Rationale: Generalizability and reduced site-specific bias
- description: >-
    Intentional focus on recruiting diverse participants historically underrepresented in voice AI research, addressing fairness
    and equity principles integrated throughout the project's DEI module.


    Sampling Method: Diversity-targeted recruitment

    Rationale: Fairness, representativeness, and reduction of algorithmic bias
- description: >-
    Patients screened at specialty clinics based on predetermined inclusion/exclusion criteria developed by project investigators,
    ensuring appropriate clinical phenotyping and data quality.


    Sampling Method: Clinician-guided screening

    Rationale: Clinical validity and gold standard diagnosis
acquisition_methods:
- description: >-
    Voice recordings collected using custom tablet application with headsets at clinical sites during scheduled study visits.
    Participants perform standardized voice tasks including sustained phonation of vowel sounds (e.g., /e/), respiratory sounds,
    cough sounds, and free speech prompts following structured protocols.


    Collection Mode: In-person at clinical sites


    Equipment:

    - Custom tablet application (REDCap-based v3.20.0)

    - Headsets for audio capture with acoustic quality control

    - Acoustic amplifiers for standardization

    - Smartphones (planned for future scalable collection)
  was_directly_observed: true
- description: >-
    Structured questionnaires administered via custom data collection application on tablets, capturing demographic information,
    medical history, voice confounders, and disease-specific validated instruments.


    Collection Mode: Self-report via tablet application


    Instruments:

    - Demographic questionnaires

    - Medical history questionnaires

    - Voice confounder questionnaires (smoking, vocal use, environment)

    - Disease-specific validated questionnaires
  was_directly_observed: true
- description: >-
    Electronic health record (EHR) data accessed through institutional platforms with participant consent for gold standard
    validation of diagnoses and symptoms. EHR linkage enables verification of clinical phenotypes and longitudinal health
    information.


    Collection Mode: EHR data extraction with consent


    Data Sources:

    - Institutional EHR systems at participating sites

    - Diagnostic codes and clinical notes

    - Laboratory values and imaging reports

    - Medication histories
  was_directly_observed: false
collection_mechanisms:
- description: >-
    Hardware infrastructure including tablets with integrated headsets for standardized audio capture, acoustic amplifiers,
    and quality control monitoring tools.


    Mechanism Type: Hardware


    Components:

    - Tablets for application deployment

    - Headsets with acoustic specifications

    - Acoustic amplifiers for standardization

    - Quality monitoring sensors
- description: >-
    Software infrastructure including REDCap electronic data capture framework (v3.20.0), custom voice recording application,
    automated preprocessing pipelines (b2aiprep v0.21.0), and federated learning platform for privacy-preserving multi-institutional
    analysis.


    Mechanism Type: Software


    Components:

    - REDCap v3.20.0 (doi:10.5281/zenodo.14148755)

    - Custom tablet/smartphone application

    - b2aiprep preprocessing library (v0.21.0, https://github.com/sensein/b2aiprep)

    - Federated learning infrastructure

    - Cloud storage and compute infrastructure

    - OpenSMILE feature extraction

    - Praat/parselmouth prosodic analysis

    - OpenAI Whisper transcription

    - torchaudio audio processing
- description: >-
    EHR integration platforms enabling secure linkage between voice data and clinical records across participating institutions
    while maintaining patient privacy and HIPAA compliance.


    Mechanism Type: Data integration


    Components:

    - Institutional EHR APIs

    - Secure data linkage protocols

    - De-identification pipelines

    - Federated query systems
- description: >-
    Software tool: b2aiprep

    Open source library for preprocessing raw audio waveforms and merging source data into phenotype files

    Mechanism Type: Software


    Components:

    - b2aiprep 0.21.0
- description: >-
    Software tool: Bridge2AI Voice REDCap

    Custom REDCap configuration for voice data collection

    Mechanism Type: Software


    Components:

    - Bridge2AI Voice REDCap v3.20.0
- description: >-
    Software tool: bridge2ai-docs

    Documentation dashboard and project documentation

    Mechanism Type: Software


    Components:

    - bridge2ai-docs 2.0.5
- description: >-
    Software tool: OpenSMILE

    The Munich Versatile and Fast Open-Source Audio Feature Extractor

    Mechanism Type: Software


    Components:

    - OpenSMILE
- description: >-
    Software tool: Praat

    Phonetic analysis software

    Mechanism Type: Software


    Components:

    - Praat
- description: >-
    Software tool: Parselmouth

    Python interface to Praat for phonetic analysis

    Mechanism Type: Software


    Components:

    - Parselmouth
- description: >-
    Software tool: TorchAudio

    Audio processing library for PyTorch

    Mechanism Type: Software


    Components:

    - TorchAudio
- description: >-
    Software tool: OpenAI Whisper

    Automatic speech recognition model (Large variant)

    Mechanism Type: Software


    Components:

    - OpenAI Whisper
data_collectors:
- description: >-
    Clinical research coordinators and trained study personnel at participating sites responsible for participant enrollment,
    consent administration, and supervised data collection sessions.


    Collector Type: Human - Clinical research staff


    Sites:

    - University of South Florida

    - Massachusetts Institute of Technology

    - Weill Cornell Medicine

    - Oregon Health & Science University

    - Other participating North American sites
- description: >-
    Automated computational systems for audio preprocessing, feature extraction, transcription, and quality control.


    Collector Type: Automated - Computational pipelines


    Systems:

    - b2aiprep preprocessing library

    - OpenSMILE acoustic feature extraction

    - Praat/parselmouth prosodic analysis

    - OpenAI Whisper Large model transcription

    - torchaudio audio processing

    - Custom quality control algorithms
collection_timeframes:
- description: >-
    Project initiated September 1, 2022 with planned completion November 30, 2026. Ongoing data collection with periodic versioned
    releases.


    Collection Status: Ongoing
  start_date: '2022-09-01'
  end_date: '2026-11-30'
- description: >-
    Version release timeline: v1.0 released January 2024 (initial release with 306 participants, 12,523 recordings), v1.1
    released January 17, 2025 (added MFCCs), v2.0.0 planned April 16, 2025, v2.0.1 planned August 18, 2025.


    Release Schedule:

    v1.0: January 2024

    v1.1: January 17, 2025

    v2.0.0: April 16, 2025 (planned)

    v2.0.1: August 18, 2025 (planned)
- description: >-
    Most participants complete data collection in a single session. Subset of participants require multiple sessions to complete
    protocol, resulting in multiple sessions per participant for some individuals.


    Session Structure: Single or multi-session per participant
preprocessing_strategies:
- description: >-
    Raw audio preprocessing pipeline standardizes all recordings to monaural (single-channel) format and resamples to 16 kHz
    sampling rate with Butterworth anti-aliasing filter applied to prevent frequency aliasing artifacts.


    Preprocessing Type: Audio standardization


    Methods:

    - Conversion to monaural (mono) audio

    - Resampling to 16 kHz

    - Butterworth anti-aliasing filter
- description: >-
    Spectrogram extraction using short-time Fast Fourier Transform (FFT) with 25ms window size, 10ms hop length, and 512-point
    FFT, producing 513xN dimension time-frequency representations stored in Parquet format for efficient access.


    Preprocessing Type: Time-frequency transformation


    Methods:

    - Short-time FFT with 25ms window

    - 10ms hop length

    - 512-point FFT

    - Power spectrum representation

    Output: 513xN dimension arrays
- description: >-
    Mel-frequency cepstral coefficient (MFCC) extraction with 60 coefficients computed from spectrograms, capturing perceptually-relevant
    acoustic features commonly used in speech and voice analysis. Added in v1.1.


    Preprocessing Type: Perceptual feature extraction


    Methods:

    - 60 MFCC coefficients

    - Derived from spectrograms

    Output: 60xN dimension arrays

    - Added in version 1.1
- description: >-
    Acoustic feature extraction using OpenSMILE (Speech and Music Interpretation by Large-space Extraction) toolkit to compute
    extensive set of low-level descriptors (LLDs), statistical functionals, and temporal features capturing voice dynamics.


    Preprocessing Type: Acoustic feature extraction


    Tools:

    - OpenSMILE (Eyben et al. 2010)

    - LLD computation

    - Statistical functionals

    - Temporal dynamics
- description: >-
    Phonetic and prosodic feature computation using Parselmouth (Python interface to Praat) for fundamental frequency (f0)
    estimation, formant extraction (F1, F2, F3), voice quality parameters (jitter, shimmer, harmonics-to-noise ratio), and
    intensity measures.


    Preprocessing Type: Prosodic analysis


    Tools:

    - Parselmouth (Jadoul et al. 2018)

    - Praat phonetic analysis

    - Fundamental frequency (f0)

    - Formants (F1, F2, F3)

    - Voice quality (jitter, shimmer, HNR)
- description: >-
    Automated speech transcription using OpenAI's Whisper Large model for accurate transcription of voice recordings. Free
    speech transcripts removed from public release for privacy; only task-based transcriptions for non-identifying prompts
    retained.


    Preprocessing Type: Automated transcription


    Tools:

    - OpenAI Whisper Large model

    - Automatic speech recognition (ASR)


    Privacy Measures:

    - Free speech transcripts removed

    - Only non-identifying task transcriptions retained
- description: >-
    REDCap data export and conversion using open-source b2aiprep library (v0.21.0) for standardized extraction, transformation,
    and formatting of clinical questionnaire data and voice recordings into analysis-ready formats.


    Preprocessing Type: Data export and formatting


    Tools:

    - b2aiprep v0.21.0 (https://github.com/sensein/b2aiprep)

    - REDCap API integration

    - Parquet file generation

    - TSV/JSON data dictionaries
cleaning_strategies:
- description: >-
    HIPAA Safe Harbor de-identification method applied systematically to remove all 18 categories of identifiers specified
    in 45 CFR §164.514(b)(2), ensuring dataset meets regulatory requirements for de-identified health information.


    Cleaning Type: HIPAA Safe Harbor de-identification


    Identifiers Removed:

    - Names

    - Geographic subdivisions smaller than state (state/province removed, country retained)

    - All elements of dates except year (dates at resolution finer than years removed)

    - Telephone numbers

    - Fax numbers

    - Email addresses

    - Social Security numbers

    - Medical record numbers

    - Health plan beneficiary numbers

    - Account numbers

    - Certificate/license numbers

    - Vehicle identifiers and serial numbers

    - Device identifiers and serial numbers

    - Web Universal Resource Locators (URLs)

    - Internet Protocol (IP) addresses

    - Biometric identifiers (including finger and voice prints)

    - Full-face photographs and comparable images

    - Any other unique identifying number, characteristic, or code
- description: >-
    Raw audio waveforms excluded from public releases v1.0 and v1.1 to protect participant privacy and prevent potential biometric
    identification. Only derived features (spectrograms, MFCCs, acoustic features) provided in public release. Raw audio available
    through controlled access by contacting DACO@b2ai-voice.org.


    Cleaning Type: Privacy-preserving feature extraction


    Privacy Measures:

    - Raw audio omitted from v1.0 and v1.1

    - Only derived features publicly released

    - Raw audio available via controlled access (DACO@b2ai-voice.org)

    - Future releases will include additional privacy protections for raw audio
- description: >-
    Free speech transcripts removed from all public releases to prevent disclosure of potentially identifying or sensitive
    information contained in participant utterances. Only transcriptions of standardized task-based prompts retained where
    content is non-identifying.


    Cleaning Type: Transcript privacy protection


    Privacy Measures:

    - Free speech transcripts removed

    - Task-based transcriptions retained (non-identifying prompts only)

    - Reduces re-identification risk from unique speech patterns
- description: >-
    Data quality control procedures including acoustic quality validation, outlier detection, completeness checks, and consistency
    verification across linked data sources (voice, questionnaires, EHR).


    Cleaning Type: Quality assurance


    Quality Measures:

    - Acoustic quality thresholds

    - Outlier detection and flagging

    - Completeness validation

    - Cross-source consistency checks

    - Session-level metadata verification
existing_uses:
- description: >-
    Dataset publicly released through PhysioNet and Health Data Nexus for voice AI research community access under registered
    access license. Initial research outputs include protocol development publication and open-source software tools.


    Publications:

    - Rameau A, et al. (2024) Developing Multi-Disorder Voice Protocols: A team science approach involving clinical expertise,
    bioethics, standards, and DEI. Proc. Interspeech 2024, 1445-1449, doi:10.21437/Interspeech.2024-1926

    - Bensoussan Y, et al. (2024) Bridge2AI Voice REDCap (v3.20.0). Zenodo, doi:10.5281/zenodo.14148755

    - Sigaras A, et al. (2024) eipm/bridge2ai-docs. Zenodo, doi:10.5281/zenodo.13834653

    - Johnson A, et al. (2024) Bridge2AI-Voice v1.0. Health Data Nexus, doi:10.57764/qb6h-em84
- description: >
    Publication: Rameau, A., Ghosh, S., Sigaras, A., Elemento, O., Belisle-Pipon, J.-C., Ravitsky, V., Powell, M., Johnson,
    A., Dorr, D., Payne, P., Boyer, M., Watts, S., Bahr, R., Rudzicz, F., Lerner-Ellis, J., Awan, S., Bolser, D., Bensoussan,
    Y. (2024) Developing Multi-Disorder Voice Protocols: A team science approach involving clinical expertise, bioethics,
    standards, and DEI. Proc. Interspeech 2024, 1445-1449, doi: 10.21437/Interspeech.2024-1926
- description: >
    Publication: Bensoussan, Y., Ghosh, S. S., Rameau, A., Boyer, M., Bahr, R., Watts, S., Rudzicz, F., Bolser, D., Lerner-Ellis,
    J., Awan, S., Powell, M. E., Belisle-Pipon, J.-C., Ravitsky, V., Johnson, A., Zisimopoulos, P., Tang, J., Sigaras, A.,
    Elemento, O., Dorr, D., ... Bridge2AI-Voice. (2024). Bridge2AI Voice REDCap (v3.20.0). Zenodo. https://doi.org/10.5281/zenodo.14148755
- description: >
    Publication: Sigaras, A., Zisimopoulos, P., Tang, J., Bevers, I., Gallois, H., Bernier, A., Bensoussan, Y., Ghosh, S.
    S., Rameau, A., Powell, M. E., Belisle-Pipon, J.-C., Ravitsky, V., Johnson, A., Elemento, O., Dorr, D., ... Bridge2AI-Voice.
    (2024). eipm/bridge2ai-docs. Zenodo. https://zenodo.org/doi/10.5281/zenodo.13834653
- description: >
    Publication: Johnson, A., Bélisle-Pipon, J., Dorr, D., Ghosh, S., Payne, P., Powell, M., Rameau, A., Ravitsky, V., Sigaras,
    A., Elemento, O., & Bensoussan, Y. (2024). Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health
    information (version 1.0). Health Data Nexus. https://doi.org/10.57764/qb6h-em84
future_use_impacts:
- description: >-
    Voice biomarker discovery for disease screening and diagnosis may enable earlier detection, non-invasive monitoring, and
    broader access to diagnostic tools, but requires careful validation to avoid false positives/ negatives and ensure clinical
    utility across diverse populations.


    Impact Type: Clinical decision support


    Potential Benefits:

    - Earlier disease detection through voice screening

    - Non-invasive monitoring tools

    - Cost-effective screening at scale

    - Remote patient monitoring capabilities

    - Broader access to diagnostic tools


    Potential Harms:

    - False positive results causing unnecessary anxiety and interventions

    - False negative results delaying diagnosis and treatment

    - Over-reliance on AI tools without clinical judgment

    - Generalization failures across populations

    - Algorithmic bias if training data not representative
- description: >-
    Multi-modal AI model development integrating voice with EHR, genomics, and imaging data may provide comprehensive patient
    assessments, but raises privacy concerns about data linkage and potential for re-identification through combined data
    sources.


    Impact Type: Multi-modal integration


    Potential Benefits:

    - Comprehensive patient phenotyping

    - Improved diagnostic accuracy through data fusion

    - Personalized medicine applications

    - Longitudinal disease progression tracking


    Potential Harms:

    - Increased re-identification risk from linked data

    - Privacy concerns about comprehensive patient profiles

    - Data security vulnerabilities from multiple sources

    - Consent complexities for multi-modal sharing
- description: >-
    Federated learning applications may enable privacy-preserving collaborative research across institutions, but requires
    careful governance to prevent model inversion attacks and ensure equitable benefit sharing.


    Impact Type: Privacy-preserving collaboration


    Potential Benefits:

    - Multi-institutional model training without data sharing

    - Preservation of patient privacy

    - Larger effective training datasets

    - Institutional autonomy over data


    Potential Harms:

    - Model inversion attacks extracting training data

    - Gradient leakage revealing patient information

    - Unequal contribution and benefit distribution

    - Technical barriers for smaller institutions
- description: >-
    Commercial voice AI applications (e.g., smartphone-based screening) may increase accessibility but raise concerns about
    data exploitation, surveillance, and equitable access across socioeconomic groups.


    Impact Type: Commercial applications


    Potential Benefits:

    - Consumer-accessible health monitoring

    - Scalable screening tools

    - Integration with consumer devices

    - Remote healthcare delivery


    Potential Harms:

    - Data exploitation for profit

    - Biometric surveillance concerns

    - Digital divide excluding disadvantaged groups

    - Lack of clinical oversight

    - Privacy erosion through continuous monitoring
intended_uses:
- description: >-
    Use case: AI/ML model development


    Development and validation of AI/ML models for voice-based disease screening, diagnosis, and monitoring across five target
    disease categories (voice disorders, neurological, mood, respiratory, pediatric).
- description: >-
    Use case: Biomarker discovery


    Discovery and validation of novel acoustic biomarkers associated with health conditions not previously recognized as clinically
    relevant, expanding clinical applications of voice analysis.
- description: >-
    Use case: Clinical decision support


    Development of clinical decision support tools integrating voice biomarkers into healthcare workflows for point-of-care
    screening, remote monitoring, and EHR integration.
- description: >-
    Use case: Multi-modal data integration


    Multi-modal biomarker research integrating voice with EHR, radiomics, genomics, and other data sources to build comprehensive
    predictive models for disease screening and progression monitoring.
- description: >-
    Use case: Federated learning research


    Federated learning applications for privacy-preserving collaborative research across institutions, enabling model training
    on distributed datasets without centralized data sharing.
- description: >-
    Use case: Standards development


    Development of standards, best practices, and quality measures for acoustic and voice data collection, analysis, and clinical
    validation in voice AI research.
- description: >-
    Use case: Workforce development


    Education and training of interdisciplinary researchers in voice biomarkers, AI/ML methods, and ethical AI development
    through curriculum development and community building efforts.
discouraged_uses:
- description: >-
    Any attempt to re-identify participants or contact research subjects without appropriate IRB approval, Provider consent,
    and individual informed consent is strictly prohibited under Data Transfer and Use Agreement terms.


    Prohibition Reason: Privacy protection and ethical principles


    Prohibited Activities:

    - Participant re-identification efforts

    - Contact attempts without triple approval (IRB + Provider + participant)

    - Linkage with external databases for re-identification

    - Biometric matching against other voice databases
- description: >-
    Unauthorized sharing, redistribution, selling, renting, leasing, or granting access to third parties without prior written
    consent from Provider Institution is prohibited. Collaborators must apply independently for access with separate Data
    Transfer and Use Agreement.


    Prohibition Reason: Data governance and access control


    Prohibited Activities:

    - Data sharing without Provider consent

    - Commercial sale or licensing without authorization

    - Third-party access without independent DTUA

    - Redistribution to unauthorized users
- description: >-
    Use of intellectual property protection, database rights, or related rights in ways that prevent or limit access to any
    element of the data or research conclusions derived from it is prohibited to ensure scientific openness and reproducibility.


    Prohibition Reason: Open science principles


    Prohibited Activities:

    - IP restrictions preventing data access

    - Database rights limiting research use

    - Proprietary claims on derived conclusions

    - Preventing replication or validation studies
- description: >-
    Biometric surveillance, profiling, or applications infringing on privacy rights or civil liberties are strongly discouraged
    and violate ethical principles underlying the dataset. Certificate of Confidentiality must be asserted against compulsory
    legal demands.


    Prohibition Reason: Ethical framework and privacy rights


    Discouraged Activities:

    - Biometric surveillance systems

    - Unauthorized profiling or tracking

    - Privacy-infringing applications

    - Civil liberties violations


    Legal Protections:

    - Certificate of Confidentiality against legal demands
- description: >-
    Applications resulting in unfair discrimination or bias against individuals or groups based on voice characteristics are
    discouraged. Fairness and equity principles must be followed, with bias mitigation required for clinical applications.


    Prohibition Reason: Fairness and equity principles


    Discouraged Activities:

    - Discriminatory screening or diagnosis

    - Biased risk assessments

    - Unfair treatment decisions based on voice

    - Applications perpetuating health disparities
distribution_formats:
- description: >-
    Parquet file containing spectrograms with participant_id, session_id, task_name, and 513xN dimension time-frequency representation
    arrays. Parquet format provides efficient columnar storage and fast queries.


    File Name: spectrograms.parquet

    Format: Parquet

    Structure: Columnar with metadata and dense arrays

    Size: Large (dense spectrogram data)
- description: >-
    Parquet file containing 60xN dimension MFCC arrays derived from spectrograms. Added in version 1.1 release (January 17,
    2025).


    File Name: mfcc.parquet

    Format: Parquet

    Structure: Columnar with metadata and dense arrays

    Version Added: 1.1
- description: >-
    Tab-delimited phenotype data with one row per unique participant (306 rows total), containing demographics, acoustic confounders,
    and responses to validated questionnaires. Accompanied by JSON data dictionary (phenotype.json) with column descriptions.


    File Name: phenotype.tsv

    Format: TSV (tab-separated values)

    Structure: One row per participant

    Rows: 306

    Data Dictionary: phenotype.json
- description: >-
    Tab-delimited static features with one row per unique recording (12,523 rows total), containing features derived from
    OpenSMILE, Praat, parselmouth, and torchaudio. Accompanied by JSON data dictionary (static_features.json) with feature
    descriptions.


    File Name: static_features.tsv

    Format: TSV (tab-separated values)

    Structure: One row per recording

    Rows: 12523

    Data Dictionary: static_features.json
- description: >-
    Primary distribution through PhysioNet registered access system managed by MIT Laboratory for Computational Physiology,
    supported by NIBIB grant R01EB030362. Requires Data Access Compliance Office (DACO) approval with Data Transfer and Use
    Agreement (DTUA).


    Platform: PhysioNet

    Url: https://physionet.org/content/b2ai-voice/

    Doi V1 1: https://doi.org/10.13026/249v-w155

    Doi Latest: https://doi.org/10.13026/37yb-1t42

    Access Mechanism: Registered access with DTUA
- description: >-
    Secondary distribution through Health Data Nexus platform providing alternative access point for AI-ready biomedical datasets.


    Platform: Health Data Nexus

    Url: https://healthdatanexus.ai/content/b2ai-voice/1.0/

    Access Mechanism: Registered access
- description: >-
    Project documentation, protocols, and software tools available through official website and GitHub repositories under
    open-source licenses (MIT License for software).


    Platform: Project website and GitHub

    Url Documentation: https://docs.b2ai-voice.org

    Url Github Docs: https://github.com/eipm/bridge2ai-docs

    Url Github B2Aiprep: https://github.com/sensein/b2aiprep

    License: MIT License (software)
- description: >-
    Raw audio data available through controlled access only by contacting Data Access Compliance Office (DACO@b2ai-voice.org).
    Raw audio waveforms disseminated with additional privacy protections to protect participant confidentiality.


    Platform: Controlled access (DACO)

    Contact: DACO@b2ai-voice.org

    Data Type: Raw audio waveforms

    Privacy Level: Enhanced (controlled access only)
license_and_use_terms:
  description: >-
    Bridge2AI Voice Registered Access License with Data Transfer and Use Agreement (DTUA) required for all data access. Registered
    users must sign DTUA and obtain approval from Data Access Compliance Office (DACO) before accessing files. Recipients
    must establish administrative, technical, and physical safeguards to protect Personally Identifiable Information (PII)
    per OMB M-07-16 and ensure only authorized persons access data. Data provided "AS IS" without warranties of any kind.
    Recipients assume all liability for use, storage, disclosure, or disposal. No unauthorized disclosure to third parties;
    collaborators must apply independently. Attribution required citing both dataset DOI and PhysioNet platform. Commercial
    use allowed under DTUA terms. Recipients may retain derivative works with proper attribution and may publish results (open-access
    encouraged). Two-year use period from DTUA start date upon completion of project, expiration of ethics approval, or termination,
    whichever occurs first; renewable with Provider approval. One archival copy allowed for records retention compliance.
    Provider Institution (University of South Florida) may unilaterally amend if Federal sponsor requires; recipient may object
    resulting in immediate termination. Certificate of Confidentiality protections apply and must be asserted against compulsory
    legal demands. DTUA approved for use through August 31, 2025.



    Citation requirements:

    description: Primary dataset citation required for all publications, presentations, and other uses of data. Should cite
    specific version used (via version DOI) for reproducibility.


    citation_type: Dataset citation

    format: Johnson, A., Bélisle-Pipon, J., Dorr, D., Ghosh, S., Payne, P., Powell, M., Rameau, A., Ravitsky, V., Sigaras,
    A., Elemento, O., & Bensoussan, Y. (2025). Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health
    information (version 1.1). PhysioNet. RRID:SCR_007345. https://doi.org/10.13026/249v-w155


    description: PhysioNet platform citation required as standard acknowledgment of infrastructure supporting data distribution.


    citation_type: Platform citation

    format: Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank,
    PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online].
    101 (23), pp. e215–e220. RRID:SCR_007345.


    description: Recipient agrees to recognize contribution of Provider as source of data in all written, visual, or oral
    public disclosures of research using data, as appropriate in accordance with scholarly standards.


    citation_type: Attribution requirement

    policy: Provider recognition required in all public disclosures

    description: Recipients encouraged to make results publicly available in open-access journals or pre-print servers where
    possible to maximize scientific dissemination and reproducibility.


    citation_type: Publication encouragement

    policy: Open-access publication encouraged

    License Name: Bridge2AI Voice Registered Access License

    Agreement Required: Data Transfer and Use Agreement (DTUA)

    Approval Authority: Data Access Compliance Office (DACO)

    Provider Institution: University of South Florida Board of Trustees

    Effective Through: August 31, 2025


    Key Terms:

    - Registered access with DACO approval required

    - Data classified as Personally Identifiable Information (PII, OMB M-07-16)

    - Administrative, technical, physical safeguards required

    - Certificate of Confidentiality protections (must assert against legal demands)

    - Data provided "AS IS" without warranties

    - Recipients assume liability for use

    - No unauthorized third-party disclosure

    - Collaborators apply independently

    - Attribution requirements (dataset DOI + PhysioNet)

    - Commercial use allowed

    - Open-access publication encouraged

    - Two-year use period (renewable)

    - Archival copy allowed for records retention

    - Provider may amend if Federal sponsor requires

    - Termination results in data destruction (certification required)
maintainers:
- description: >-
    Long-term dataset stewardship provided through PhysioNet infrastructure maintained by MIT Laboratory for Computational
    Physiology, supported by NIBIB grant R01EB030362. Ensures persistent access, version control, and DOI assignment for citability.


    Maintainer: MIT Laboratory for Computational Physiology (PhysioNet)

    Funding: NIBIB grant R01EB030362


    Responsibilities:

    - Data hosting and distribution

    - Version control and DOI assignment

    - Technical infrastructure maintenance

    - User support for data access

    - Long-term preservation
- description: >-
    Data access governance managed by University of South Florida as Provider Institution through Data Access Compliance Office
    (DACO), responsible for DTUA review, approval, and compliance monitoring.


    Maintainer: University of South Florida (Provider Institution)


    Responsibilities:

    - DTUA review and approval

    - User access management

    - Compliance monitoring

    - Agreement amendments

    - Violation investigation

    Unit: Data Access Compliance Office (DACO)

    Contact: DACO@b2ai-voice.org
- description: >-
    Bridge2AI-Voice Consortium led by University of South Florida maintains dataset curation, quality control, ongoing data
    collection, version releases, and scientific oversight throughout project lifecycle (2022-2026) and beyond.


    Maintainer: Bridge2AI-Voice Consortium


    Responsibilities:

    - Ongoing data collection

    - Dataset curation and quality control

    - Version releases and documentation

    - Scientific oversight

    - Ethics compliance

    - Community engagement

    - Workforce development

    Lead Institution: University of South Florida

    Project Period: 2022-09-01 to 2026-11-30
- description: >-
    Technical support and documentation maintained through project website (docs.b2ai-voice.org), GitHub repositories, and
    community forums. Open-source software tools (b2aiprep, bridge2ai-docs) maintained by development team.


    Maintainer: Technical development team


    Responsibilities:

    - Documentation maintenance

    - Software tool development and support

    - Tutorial and example creation

    - User community building


    Resources:

    - https://docs.b2ai-voice.org

    - https://github.com/eipm/bridge2ai-docs

    - https://github.com/sensein/b2aiprep
updates:
  description: >-
    Update frequency and schedule:

    Ongoing data collection with periodic versioned releases. Major releases planned approximately every 6-12 months during
    active project period (2022-2026). Future releases will include additional participants from adult cohorts, pediatric
    cohort data (currently not included), and potentially raw audio waveforms with enhanced privacy protections. Post-project
    maintenance will continue through PhysioNet infrastructure with updates as needed for corrections, documentation, and
    community contributions.




    Version 1.0:

    Initial release of Bridge2AI-Voice dataset with 12,523 recordings from 306 participants across five clinical sites. Included
    spectrograms, acoustic features, phenotype data, and static features.



    Version 1.1:

    Added Mel-frequency cepstral coefficients (MFCCs) with 60 coefficients per recording, providing additional perceptually-relevant
    acoustic features commonly used in speech and voice analysis.



    Version 2.0.0:

    Planned future release with additional participants, enhanced features, and expanded cohorts. Details to be announced.



    Version 2.0.1:

    Planned maintenance release with bug fixes, documentation updates, and minor enhancements. Currently the latest version
    available.
version_access:
  description: >-
    All versions available through PhysioNet with version-specific DOIs for citability and reproducibility. Latest version
    DOI always points to most recent release. Users can access specific versions for replication or access latest version
    for most current data.


    Version Doi 1 0: https://doi.org/10.57764/qb6h-em84

    Version Doi 1 1: https://doi.org/10.13026/249v-w155

    Latest Doi: https://doi.org/10.13026/37yb-1t42

    Current Latest Version: 2.0.1
participant_privacy:
- description: >-
    Data classified as Personally Identifiable Information (PII) per OMB Memorandum M-07-16. Not covered under HIPAA, FERPA,
    or similar personal information regulations. HIPAA Safe Harbor de-identification applied but data still treated as sensitive
    requiring protection.


    Classification: Personally Identifiable Information (PII, OMB M-07-16)

    De Identification: HIPAA Safe Harbor method applied


    Not Covered By:

    - HIPAA

    - FERPA

    - Similar personal information regulations
- description: >-
    Certificate of Confidentiality (CoC) protects participant privacy against compulsory legal demands such as court orders
    and subpoenas. Recipients must assert CoC protections if legally compelled to disclose data.


    Protection Mechanism: Certificate of Confidentiality


    Legal Protections:

    - Protection against court orders

    - Protection against subpoenas

    - Mandatory assertion by recipients

    - Federal protections for research participants

    Reference: https://grants.nih.gov/policy/humansubjects/coc.htm
- description: >-
    Recipients required to establish administrative, technical, and physical safeguards adequate to protect PII. Safeguards
    must ensure only authorized persons access data and maintain appropriate control at all times. Controls include those
    for electronic protected health information security.


    Safeguard Requirements:

    - Administrative safeguards for access control

    - Technical safeguards preventing unauthorized use

    - Physical safeguards for data storage and transmission

    - Access limited to authorized persons

    - Electronic PHI security standards

    - Continuous monitoring and control
- description: >-
    Federated learning infrastructure implemented for multi-institutional analysis while minimizing data sharing and preserving
    patient privacy. Enables collaborative model development without centralized data pooling.


    Privacy Technology: Federated learning


    Privacy Benefits:

    - No centralized data sharing required

    - Institutional data sovereignty maintained

    - Privacy-preserving collaborative research

    - Reduced data transfer and exposure
regulatory_restrictions:
  description: >-
    Collaborators at other research organizations and other research teams at the same organization must apply independently
    for data access and sign separate Data Transfer and Use Agreement (DTUA) with Provider before accessing data. No sub-licensing
    or derivative access permissions.



    No disclosure, release, sale, rent, lease, loan, or granting access to data to any third party except authorized persons
    without prior written consent of Provider. Data must be retained under recipient control at all times.



    Provider may unilaterally amend DTUA if Federal sponsor requires revision. If recipient objects to amendment, DTUA immediately
    terminates and recipient must immediately return or destroy all data.

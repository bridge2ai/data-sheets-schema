# D4D Datasheet for VOICE Dataset
# Generated by: Claude Code Assistant (In-Session Synthesis)
# Source: data/preprocessed/concatenated/VOICE_preprocessed.txt (9 source files)
# Schema: data_sheets_schema_all.yaml
# Generation Date: 2025-12-06

id: https://doi.org/10.13026/249v-w155
name: Bridge2AI-Voice Dataset
title: Bridge2AI-Voice - An ethically-sourced, diverse voice dataset linked to health information
description: 'The Bridge2AI-Voice project creates an ethically sourced flagship dataset to enable future

  research in artificial intelligence and support critical insights into the use of voice as a biomarker

  of health. Version 1.1 provides 12,523 recordings for 306 adult participants collected across five sites

  in North America. Participants were selected based on known conditions which manifest within the voice

  waveform including voice disorders, neurological disorders, mood disorders, and respiratory disorders.

  This release contains de-identified derived data including spectrograms, MFCCs, and acoustic features

  but not the original voice recordings.'
page: https://physionet.org/content/b2ai-voice/1.1/
language: en
keywords:
- Bridge2AI
- voice biomarker
- speech
- health
- voice disorders
- neurological disorders
- mood disorders
- respiratory disorders
- spectrogram
- MFCC
- acoustic features
- PhysioNet
purposes:
- description: 'Create an ethically sourced flagship dataset to enable future research in artificial intelligence

    and support critical insights into the use of voice as a biomarker of health.'
tasks:
- description: 'Enable AI research on voice as a biomarker for health conditions including voice disorders,

    neurological disorders, mood disorders, and respiratory disorders.'
addressing_gaps:
- description: 'Address the need for large, high quality, multi-institutional and diverse voice databases
    linked

    to health biomarkers to fuel voice AI research and answer clinical questions.'
instances:
- description: 'Version 1.1 contains 12,523 recordings from 306 adult participants collected across five
    sites

    in North America. Most participants completed one session, with a subset completing multiple sessions.'
subsets:
- id: voice:spectrograms
  name: spectrograms.parquet
  description: 'Time-frequency power spectrograms (513 x N dimension) computed using short-time FFT with
    25ms

    window, 10ms hop length, and 512-point FFT.'
- id: voice:mfcc
  name: mfcc.parquet
  description: '60 Mel-frequency cepstral coefficients (MFCCs) derived from spectrograms, 60 x N dimension

    per recording.'
- id: voice:phenotype
  name: phenotype.tsv
  description: 'Participant demographics, validated questionnaire responses, and acoustic confounders
    with

    one row per unique participant.'
- id: voice:static-features
  name: static_features.tsv
  description: 'Acoustic features from openSMILE, Praat, parselmouth, and torchaudio with one row per
    unique

    recording.'
subpopulations:
- description: Voice disorders (benign and malignant lesions affecting vocal folds)
- description: Neurological and neurodegenerative disorders (including Parkinson's, ALS)
- description: Mood and psychiatric disorders (depression, anxiety)
- description: Respiratory disorders (cough, breathing sounds)
sampling_strategies:
- description: 'Participants selected based on membership to five predetermined disease groups from specialty

    clinics and institutions. Patients screened for inclusion/exclusion criteria prior to visit by

    project investigators.'
acquisition_methods:
- description: 'Voice tasks collected via standardized protocol including sustained vowel phonation using
    a

    custom tablet application with headset.'
  was_directly_observed: true
  acquisition_details:
  - Custom tablet application for data collection
  - Headset used for voice recording when possible
  - Standardized protocol across five collection sites
collection_mechanisms:
- description: Data collection using REDCap with custom application.
  mechanism_details:
  - Custom tablet application for voice recording
  - REDCap for clinical and questionnaire data
  - Headset microphone for audio capture
data_collectors:
- description: Specialty clinics and institutions across five North American sites.
  collector_details:
  - Five North American clinical sites
  - Specialty clinics for each disease cohort
collection_timeframes:
- description: Data collected prior to January 2025 release.
  timeframe_details:
  - v1.1 released January 17, 2025
preprocessing_strategies:
- description: 'Raw audio converted to mono and resampled to 16 kHz with Butterworth anti-aliasing filter.

    Derived data computed using multiple feature extraction pipelines.'
  preprocessing_details:
  - Audio resampled to 16 kHz mono
  - Spectrograms computed via short-time FFT (25ms window, 10ms hop, 512-point FFT)
  - 60 MFCCs extracted from spectrograms
  - Acoustic features extracted using openSMILE
  - Phonetic and prosodic features computed using Parselmouth/Praat
  - Transcriptions generated using OpenAI Whisper Large (free speech transcripts removed)
cleaning_strategies:
- description: 'HIPAA Safe Harbor de-identification applied. Free speech transcripts removed to reduce

    re-identification risk. Raw audio waveforms not released in v1.1.'
  cleaning_details:
  - HIPAA Safe Harbor identifiers removed
  - State and province removed (country retained)
  - Free speech transcripts removed
  - Raw audio waveforms omitted
ethical_reviews:
- description: 'Data collection and sharing approved by the University of South Florida Institutional
    Review

    Board.'
  review_details:
  - IRB approval from University of South Florida
informed_consent:
- consent_obtained: true
  consent_type:
  - Written consent for data collection
  - Consent for research data sharing
  description: Participants provided consent for data collection and sharing of de-identified research
    data.
is_deidentified:
  description: 'De-identification using HIPAA Safe Harbor method. All Safe Harbor identifiers removed
    including

    names, geographic locators, dates, contact information, government identifiers, and biometric identifiers.'
future_use_impacts:
- description: 'Dataset designed for AI research on voice as health biomarker. Data are provided as derived

    representations without raw audio to reduce re-identification risk.'
  impact_details:
  - Adult cohort only in v1.1 (pediatric data not included)
  - No raw audio in v1.1 (analyses limited to derived representations)
  - Participants selected for conditions manifesting in voice
discouraged_uses:
- description: 'Access requires signing the Bridge2AI Voice Registered Access Agreement. Use governed
    by the

    agreement terms.'
  discouragement_details:
  - Registered access required
  - Must sign data use agreement
distribution_formats:
- description: Dataset available via PhysioNet in Parquet, TSV, and JSON formats.
  access_urls:
  - https://physionet.org/content/b2ai-voice/1.1/
license_and_use_terms:
  description: 'Bridge2AI Voice Registered Access License. Only registered users who sign the specified
    data

    use agreement can access the files.'
  license_terms:
  - Bridge2AI Voice Registered Access License
  - Requires signing Bridge2AI Voice Registered Access Agreement
  - Registered access on PhysioNet
maintainers:
- name: PhysioNet platform team
  description: Dataset hosted and maintained by PhysioNet.
  maintainer_details:
  - PhysioNet platform and infrastructure
  - MIT Laboratory for Computational Physiology
updates:
  description: 'Version 1.1 released January 17, 2025 adding MFCCs. Project subsequently updated to versions

    2.0.0 and 2.0.1.'
  update_details:
  - v1.0 initial release 2024
  - v1.1 released 2025-01-17 (added MFCCs)
  - v2.0.0 released 2025-04-16
  - v2.0.1 released 2025-08-18
version_access:
  description: 'Multiple versions available through PhysioNet. Files for v1.1 may no longer be available;

    latest version is 2.0.1.'
  latest_version_doi: https://doi.org/10.13026/37yb-1t42
  versions_available:
  - 1.1 (January 2025)
  - 2.0.0 (April 2025)
  - 2.0.1 (August 2025)

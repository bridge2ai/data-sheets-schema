
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="datasheet-common.css">
    <title>healthnexus tab conflicts-of-interest d4d - Datasheet for Dataset</title>
</head>
<body>
    <div class="header">
        <h1>healthnexus tab conflicts-of-interest d4d</h1>
        <p class="subtitle">Datasheet for Dataset - Human Readable Format</p>
    </div>
    
    
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üéØ</span>
                    <div>
                        <h2 class="section-title">Motivation</h2>
                        <p class="section-description">Why was the dataset created?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Purposes
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Purpose</dd><dt>Response</dt><dd>Create an ethically sourced flagship dataset to enable AI research on the use of voice as a biomarker of health by linking diverse voice recordings with clinical and demographic information.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Funders
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Grantor</th><th>Grant Name</th><th>Grant Number</th></tr></thead><tbody><tr><td>National Institutes of Health (NIH)</td><td>Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease</td><td>3OT2OD032720-01S1</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üìä</span>
                    <div>
                        <h2 class="section-title">Composition</h2>
                        <p class="section-description">What do the instances represent?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Instances
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Instance class</dd><dt>Representation</dt><dd>Voice recordings linked to participant-level clinical, demographic, and questionnaire data; derived spectrogram matrices and acoustic/phonetic/prosodic features per recording.</dd><dt>Instance Type</dt><dd>Participants, recording sessions, and recordings (per task); derived data instances per recording.</dd><dt>Data Type</dt><dd>Derived features (e.g., spectrograms, acoustic, phonetic, prosodic) from standardized audio; raw audio waveforms are withheld in v1.0.</dd><dt>Counts</dt><dd>12,523</dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subpopulations
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Adult cohort</dd><dt>Identification</dt><dd><ul class='formatted-list'><li>Adult participants meeting inclusion criteria within predefined disease cohorts</li></ul></dd><dt>Distribution</dt><dd><ul class='formatted-list'><li>306 participants; 12,523 recordings across multiple recording tasks</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Formats
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Parquet (.parquet) for spectrograms</li><li>Tab-delimited text (.tsv) for phenotype and static features</li><li>JSON (.json) data dictionaries</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Dates
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>2024-11-27 (initial public release v1.0)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution
                            
                        </label>
                        <div class="item-value"></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîç</span>
                    <div>
                        <h2 class="section-title">Collection Process</h2>
                        <p class="section-description">How was the data acquired?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label required-field">
                            ID
                            <span class="required-indicator" title="Required field">*</span>
                        </label>
                        <div class="item-value">bridge2ai-voice-v1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Name
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Title
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Description
                            
                        </label>
                        <div class="item-value"><div class="long-description">Bridge2AI-Voice v1.0 is an ethically sourced, multi-institutional voice dataset focused on the use of voice as a biomarker of health. The initial release provides 12,523 recordings for 306 adult participants collected across five sites in North America. Participants were selected from five predefined cohorts where voice/speech changes are associated with disease: voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders, and pediatric voice/speech disorders (note: v1.0 includes adults only). This release contains low-risk derived data (e.g., spectrograms and acoustic/phonetic/prosodic features) and corresponding demographic, clinical, and validated questionnaire data; raw audio waveforms are not included in v1.0. Documentation: "https://docs.b2ai-voice.org"</div></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Page
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">https://doi.org/10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Issued
                            
                        </label>
                        <div class="item-value">2024-11-27</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Keywords
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>voice</li><li>bridge2ai</li><li>audio</li><li>health</li><li>biomarker</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Created By
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>Alistair Johnson</li><li>Jean-Christophe B√©lisle-Pipon</li><li>David Dorr</li><li>Satrajit Ghosh</li><li>Philip Payne</li><li>Maria Powell</li><li>Ana√Øs Rameau</li><li>Vardit Ravitsky</li><li>Alexandros Sigaras</li><li>Olivier Elemento</li><li>Yael Bensoussan</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Addressing Gaps
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>AddressingGap</dd><dt>Response</dt><dd>Address the lack of large, high-quality, multi-institutional, diverse voice datasets linked to other health biomarkers and collected under standardized, ethically governed protocols.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sampling Strategies
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Cohort sampling strategy</dd><dt>Is Sample</dt><dd><ul class='formatted-list'><li>True</li></ul></dd><dt>Is Random</dt><dd><ul class='formatted-list'><li>False</li></ul></dd><dt>Source Data</dt><dd><ul class='formatted-list'><li>Patients at specialty clinics across five sites in North America</li></ul></dd><dt>Is Representative</dt><dd><ul class='formatted-list'><li>False</li></ul></dd><dt>Why Not Representative</dt><dd><ul class='formatted-list'><li>Participants were recruited based on membership in predefined disease cohorts (voice, neurological, mood/psychiatric, respiratory, pediatric), and v1.0 includes adult cohort only.</li></ul></dd><dt>Strategies</dt><dd><ul class='formatted-list'><li>Purposive cohort-based sampling within specialty clinics</li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sensitive Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Health-related clinical information and demographics are included; identifiers removed per HIPAA Safe Harbor.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Acquisition Methods
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li><div class="long-description">Data were collected at specialty clinics using a standardized protocol capturing demographics, health questionnaires (including validated instruments), targeted confounder questions, disease-specific information, and voice tasks (e.g., sustained vowel).</div></li><li>Data reported by subjects (questionnaires) and directly observed (voice recordings); some data are indirectly derived (features, transcriptions).</li></ul></dd><dt>Was Directly Observed</dt><dd>yes (voice recordings)</dd><dt>Was Reported By Subjects</dt><dd>yes (questionnaires)</dd><dt>Was Inferred Derived</dt><dd>yes (features, transcriptions)</dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Collection Mechanisms
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Custom tablet-based data collection application; headset used for recording when possible; data exported from REDCap using an open-source library developed by the team.</li></ul></dd><dt>Used Software</dt><dd><table class="data-table"><thead><tr><th>Name</th></tr></thead><tbody><tr><td>Bridge2AI-Voice tablet data collection app</td></tr><tr><td>REDCap</td></tr><tr><td>b2aiprep</td></tr></tbody></table></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Data Collectors
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Project investigators and clinical teams at five North American sites</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Ethical Reviews
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Data collection and sharing approved by the University of South Florida Institutional Review Board; submission to the University of Toronto Research Ethics Board noted.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Preprocessing Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Raw audio converted to monaural, resampled to 16 kHz with a Butterworth anti-aliasing filter; spectrograms computed via STFT (25 ms window, 10 ms hop, 512-point FFT).</li><li>Acoustic features extracted with OpenSMILE; phonetic/prosodic features computed with Parselmouth and Praat; transcriptions generated using OpenAI Whisper Large.</li><li>Code to preprocess and merge source data provided via the b2aiprep library.</li></ul></dd><dt>Used Software</dt><dd><table class="data-table"><thead><tr><th>Name</th></tr></thead><tbody><tr><td>openSMILE</td></tr><tr><td>Parselmouth</td></tr><tr><td>Praat</td></tr><tr><td>torchaudio</td></tr><tr><td>OpenAI Whisper Large</td></tr><tr><td>b2aiprep</td></tr></tbody></table></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Cleaning Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor identifiers removed; state/province removed; country retained.</li><li>Transcripts of free speech audio removed from the release.</li><li>Only derived data (e.g., spectrograms, features) included in v1.0; audio waveforms omitted.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Labeling Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Automated transcriptions generated using OpenAI Whisper Large; transcripts of free speech audio not released in v1.0.</li></ul></dd><dt>Used Software</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>OpenAI Whisper Large</dd></dl></li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Raw Sources
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Raw voice audio collected but withheld from v1.0 distribution; planned for future releases with additional safeguards.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Maintainers
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Health Data Nexus (Temerty Centre for AI Research and Education in Medicine)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Deidentified
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor de-identification applied; removal of direct identifiers and fine-grained dates; state/province removed; country retained; free-speech transcripts removed; no raw audio in v1.0.</li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Tabular
                            
                        </label>
                        <div class="item-value">partial (tabular phenotype/features; array-based spectrograms)</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            External Resources
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>External Resources</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Project Documentation Website</dt><dd><a href="https://docs.b2ai-voice.org" target="_blank">https://docs.b2ai-voice.org</a></dd></dl></li><li>Publication/record landing via DOI</li></ul></dd></dl></li><li><dl class='nested-dict'><dt>Archival</dt><dd><ul class='formatted-list'><li>Versioned DOIs indicate archival/versioning support via persistent identifiers</li></ul></dd></dl></li><li><dl class='nested-dict'><dt>Restrictions</dt><dd><ul class='formatted-list'><li>Registered access with DUA and required training</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subsets
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Description</th><th>ID</th><th>Media Type</th><th>Name</th><th>Path</th><th>Title</th></tr></thead><tbody><tr><td>Parquet dataset containing 513 x N spectrogram matrices per recording, with participant_id, session_...</td><td>bridge2ai-voice-v1.0-spectrograms</td><td>application/x-parquet</td><td>spectrograms.parquet</td><td>spectrograms.parquet</td><td>Derived spectrograms</td></tr><tr><td>Tab-delimited file with one row per participant including demographics, acoustic confounders, and re...</td><td>bridge2ai-voice-v1.0-phenotype</td><td>text/tab-separated-values</td><td>phenotype.tsv</td><td>phenotype.tsv</td><td>Participant phenotype and questionnaires</td></tr><tr><td>JSON data dictionary mapping column names to descriptions for phenotype.tsv.</td><td>bridge2ai-voice-v1.0-phenotype-dict</td><td>application/json</td><td>phenotype.json</td><td>phenotype.json</td><td>Phenotype data dictionary</td></tr><tr><td>Tab-delimited file with one row per unique recording; includes features derived using openSMILE, Pra...</td><td>bridge2ai-voice-v1.0-static-features</td><td>text/tab-separated-values</td><td>static_features.tsv</td><td>static_features.tsv</td><td>Recording-level static features</td></tr><tr><td>JSON data dictionary mapping feature column names to descriptions for static_features.tsv.</td><td>bridge2ai-voice-v1.0-static-features-dict</td><td>application/json</td><td>static_features.json</td><td>static_features.json</td><td>Static features data dictionary</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üöÄ</span>
                    <div>
                        <h2 class="section-title">Uses</h2>
                        <p class="section-description">What (other) tasks could the dataset be used for?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Tasks
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Task</dd><dt>Response</dt><dd>Support AI-driven analysis of voice (e.g., feature extraction, modeling, and evaluation) for health-related research across disease cohorts where voice/speech changes are clinically relevant.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Future Use Impacts
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li><div class="long-description">Restricting v1.0 to low-risk derived data (no raw audio) mitigates privacy risks but may limit certain modeling tasks requiring waveforms; future releases aim to include audio with additional safeguards.</div></li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License And Use Terms
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Name</dt><dd>Bridge2AI Voice Registered Access</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Access restricted to credentialed users who sign the Bridge2AI Voice Registered Access Agreement (DUA) under the Bridge2AI Voice Registered Access License.</li><li><dl class='nested-dict'><dt>Required Training</dt><dd>TCPS 2: CORE 2022.</dd></dl></li><li><dl class='nested-dict'><dt>Access Platform</dt><dd>Health Data Nexus (credentialed access).</dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üì§</span>
                    <div>
                        <h2 class="section-title">Distribution</h2>
                        <p class="section-description">How will the dataset be distributed?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            DOI
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License
                            
                        </label>
                        <div class="item-value">Bridge2AI Voice Registered Access License</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version Access
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Version Specific DOI</dt><dd><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">https://doi.org/10.57764/qb6h-em84</a></dd></dl></li><li><dl class='nested-dict'><dt>Latest Version DOI</dt><dd><a href="https://doi.org/10.57764/3sg0-7440" target="_blank">https://doi.org/10.57764/3sg0-7440</a></dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîÑ</span>
                    <div>
                        <h2 class="section-title">Maintenance</h2>
                        <p class="section-description">How will the dataset be maintained?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version
                            
                        </label>
                        <div class="item-value">1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Updates
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Future releases planned to include raw voice data with additional security and privacy precautions; ongoing additions and corrections anticipated.</li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
    
    
    <div class="timestamp">
        Generated on 2025-11-08 22:21:59 using Bridge2AI Data Sheets Schema
    </div>
</body>
</html>
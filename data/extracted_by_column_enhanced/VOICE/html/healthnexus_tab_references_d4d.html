
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="datasheet-common.css">
    <title>healthnexus tab references d4d - Datasheet for Dataset</title>
</head>
<body>
    <div class="header">
        <h1>healthnexus tab references d4d</h1>
        <p class="subtitle">Datasheet for Dataset - Human Readable Format</p>
    </div>
    
    
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üéØ</span>
                    <div>
                        <h2 class="section-title">Motivation</h2>
                        <p class="section-description">Why was the dataset created?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Purposes
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Purpose</dd><dt>Response</dt><dd>Create an ethically sourced, diverse, multi-institutional voice dataset linked to clinical information to enable AI research on voice as a biomarker of health.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Funders
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Grantor</th><th>Grant Name</th><th>Grant Number</th></tr></thead><tbody><tr><td>National Institutes of Health</td><td>Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease like never before.</td><td>3OT2OD032720-01S1</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üìä</span>
                    <div>
                        <h2 class="section-title">Composition</h2>
                        <p class="section-description">What do the instances represent?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Instances
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Instance description</dd><dt>Representation</dt><dd>Voice recordings with derived spectrograms/features and participant-level phenotype/clinical data.</dd><dt>Instance Type</dt><dd>participants, sessions, and recordings (participant_id, session_id, task_name).</dd><dt>Data Type</dt><dd>Derived spectrogram arrays; acoustic, phonetic, and prosodic features; limited transcriptions; tabular phenotype and feature files.</dd><dt>Counts</dt><dd>12,523</dd><dt>Label</dt><dd>Cohort/disease group membership and clinical/phenotype variables; no raw audio included in v1.0.</dd><dt>Sampling Strategies</dt><dd><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Targeted clinical cohort sampling</dd><dt>Is Sample</dt><dd><ul class='formatted-list'><li>sample from patients presenting at specialty clinics at five North American sites</li></ul></dd><dt>Is Random</dt><dd><ul class='formatted-list'><li>False</li></ul></dd><dt>Source Data</dt><dd><ul class='formatted-list'><li>Adults with conditions affecting voice (voice, neurological/neurodegenerative, mood/psychiatric, respiratory disorders)</li></ul></dd><dt>Is Representative</dt><dd><ul class='formatted-list'><li>not stated</li></ul></dd><dt>Why Not Representative</dt><dd><ul class='formatted-list'><li>Targeted sampling of specific disorders; pediatric cohort not included in v1.0</li></ul></dd><dt>Strategies</dt><dd><ul class='formatted-list'><li>targeted clinical cohort sampling at participating sites</li></ul></dd></dl></li></ol></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subpopulations
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Cohort categories</dd><dt>Identification</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Disease Cohorts Identified At Enrollment</dt><dd>Voice disorders; Neurological and Neurodegenerative; Mood and Psychiatric; Respiratory; Pediatric (planned but not included in v1.0).</dd></dl></li></ul></dd><dt>Distribution</dt><dd><ul class='formatted-list'><li>Adult cohort only in v1.0; 306 participants across five sites in North America.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Formats
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Distribution formats</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Parquet (spectrograms.parquet)</li><li>TSV (phenotype.tsv, static_features.tsv)</li><li>JSON (phenotype.json, static_features.json)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Dates
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Initial release</dd><dt>Description</dt><dd><ul class='formatted-list'><li>2024-11-27 (v1.0)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîç</span>
                    <div>
                        <h2 class="section-title">Collection Process</h2>
                        <p class="section-description">How was the data acquired?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label required-field">
                            ID
                            <span class="required-indicator" title="Required field">*</span>
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Name
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice v1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Title
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Description
                            
                        </label>
                        <div class="item-value"><div class="long-description">The Bridge2AI-Voice project presents a comprehensive, ethically sourced dataset enabling research on voice as a biomarker of health. Bridge2AI-Voice v1.0 provides 12,523 recordings for 306 adult participants collected across five sites in North America, with corresponding demographic, clinical, and validated questionnaire information. The initial release is considered low risk and includes derived data (e.g., spectrograms, acoustic/phonetic/prosodic features) and data dictionaries; original voice audio waveforms are not included. Participants were enrolled in predetermined groups reflecting conditions that manifest in voice (voice disorders, neurological and neurodegenerative disorders, mood and psychiatric disorders, respiratory disorders), with pediatric cohorts planned but not included in v1.0. Data were collected via a standardized protocol and subsequently de-identified using HIPAA Safe Harbor principles.</div></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Language
                            
                        </label>
                        <div class="item-value">en</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Issued
                            
                        </label>
                        <div class="item-value">2024-11-27</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Page
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">https://doi.org/10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Created By
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>Alistair Johnson</li><li>Jean-Christophe B√©lisle-Pipon</li><li>David Dorr</li><li>Satrajit Ghosh</li><li>Philip Payne</li><li>Maria Powell</li><li>Ana√Øs Rameau</li><li>Vardit Ravitsky</li><li>Alexandros Sigaras</li><li>Olivier Elemento</li><li>Yael Bensoussan</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Keywords
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>voice</li><li>bridge2ai</li><li>audio</li><li>biomarker</li><li>spectrograms</li><li>clinical</li><li>health</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Addressing Gaps
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>AddressingGap</dd><dt>Response</dt><dd>Address the lack of large, high-quality, multi-institutional, demographically diverse voice datasets linked to health and clinical data.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sensitive Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Sensitive health data</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Contains health-related clinical and demographic questionnaire information.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Deidentified
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Name</dt><dd>De-identification status</dd><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor identifiers removed (e.g., names, contact details, finer-than-year dates, identifiers).</li><li>State and province removed; country of data collection retained.</li><li>Transcripts of free speech audio removed.</li><li>Original audio waveforms omitted in v1.0; only derived spectrograms and features released.</li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Acquisition Methods
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Data acquisition</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Standardized protocol at specialty clinics; demographic, clinical, and validated questionnaires; voice tasks (e.g., sustained vowel).</li><li>Custom tablet application used; headset microphone when possible.</li><li>Some participants completed multiple sessions.</li></ul></dd><dt>Was Directly Observed</dt><dd>yes (voice recordings)</dd><dt>Was Reported By Subjects</dt><dd>yes (validated questionnaires)</dd><dt>Was Inferred Derived</dt><dd>yes (spectrograms, acoustic/phonetic/prosodic features, transcriptions)</dd><dt>Was Validated Verified</dt><dd>Standardized data collection protocol; IRB/REB oversight.</dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Collection Mechanisms
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Collection mechanisms</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Custom tablet application for standardized data capture; headset microphone when feasible.</li><li>Export and conversion from REDCap using an open-source b2aiprep library.</li></ul></dd><dt>Used Software</dt><dd><table class="data-table"><thead><tr><th>Name</th><th>URL</th><th>Version</th></tr></thead><tbody><tr><td>REDCap</td><td></td><td>3.20.0</td></tr><tr><td>b2aiprep</td><td>https://github.com/sensein/b2aiprep</td><td></td></tr></tbody></table></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Data Collectors
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Data collection team</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Project investigators at five North American clinical sites.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Ethical Reviews
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Ethics and review</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Data collection and sharing approved by the University of South Florida Institutional Review Board.</li><li>Submitted for review to the University of Toronto Research Ethics Board.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Preprocessing Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Audio preprocessing and feature extraction</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter.</li><li>Spectrograms computed via STFT with 25 ms window, 10 ms hop, 512-point FFT.</li><li>Acoustic features via OpenSMILE; phonetic/prosodic features via Parselmouth and Praat.</li><li>Transcriptions generated with OpenAI's Whisper Large model (free-speech transcripts later removed from release).</li></ul></dd><dt>Used Software</dt><dd><table class="data-table"><thead><tr><th>Name</th><th>Version</th></tr></thead><tbody><tr><td>OpenSMILE</td><td></td></tr><tr><td>Parselmouth</td><td></td></tr><tr><td>Praat</td><td></td></tr><tr><td>Torchaudio</td><td>2.1</td></tr><tr><td>OpenAI Whisper Large</td><td></td></tr></tbody></table></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Cleaning Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>De-identification and release filtering</dd><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor removal; state/province removed; country retained.</li><li>Free-speech transcripts removed; only derived data released (no raw audio).</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Labeling Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Transcription</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Automatic transcriptions generated using OpenAI's Whisper Large model; free-speech transcripts removed prior to release.</li></ul></dd><dt>Used Software</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>OpenAI Whisper Large</dd></dl></li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Raw Sources
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Raw audio availability</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Raw audio waveforms are not included in v1.0; only spectrograms and derived features are provided. Future releases aim to include voice waveforms with additional security precautions.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            External Resources
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>External resources</dd><dt>External Resources</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Documentation Website</dt><dd><a href="https://docs.b2ai-voice.org" target="_blank">https://docs.b2ai-voice.org</a></dd></dl></li><li><dl class='nested-dict'><dt>Zenodo Record (bridge2ai Voice Redcap V3.20.0)</dt><dd><a href="https://doi.org/10.5281/zenodo.14148755" target="_blank">https://doi.org/10.5281/zenodo.14148755</a></dd></dl></li><li><dl class='nested-dict'><dt>B2aiprep Preprocessing Library</dt><dd><a href="https://github.com/sensein/b2aiprep" target="_blank">https://github.com/sensein/b2aiprep</a></dd></dl></li></ul></dd><dt>Archival</dt><dd><ul class='formatted-list'><li>Version-specific and latest DOIs provided.</li></ul></dd><dt>Restrictions</dt><dd><ul class='formatted-list'><li>Registered, credentialed access; signed DUA and training required.</li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Retention Limit
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Name</dt><dd>Retention limits</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Not specified in source.</li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Tabular
                            
                        </label>
                        <div class="item-value">mixed (tabular TSV/JSON dictionaries and array-based Parquet spectrograms)</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subsets
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Description</th><th>ID</th><th>Media Type</th><th>Name</th><th>Path</th><th>Title</th></tr></thead><tbody><tr><td>Parquet dataset containing 513xN spectrograms per recording with participant_id, session_id, and tas...</td><td>spectrograms.parquet</td><td>application/x-parquet</td><td>spectrograms.parquet</td><td>spectrograms.parquet</td><td>Spectrograms derived from voice waveforms</td></tr><tr><td>Tab-delimited participant-level demographics, acoustic confounders, and validated questionnaire resp...</td><td>phenotype.tsv</td><td>text/tab-separated-values</td><td>phenotype.tsv</td><td>phenotype.tsv</td><td>Participant-level phenotype data</td></tr><tr><td>JSON data dictionary describing columns in phenotype.tsv.</td><td>phenotype.json</td><td>application/json</td><td>phenotype.json</td><td>phenotype.json</td><td>Phenotype data dictionary</td></tr><tr><td>Tab-delimited features derived from raw audio (one row per recording).</td><td>static_features.tsv</td><td>text/tab-separated-values</td><td>static_features.tsv</td><td>static_features.tsv</td><td>Recording-level static features</td></tr><tr><td>JSON data dictionary describing columns in static_features.tsv.</td><td>static_features.json</td><td>application/json</td><td>static_features.json</td><td>static_features.json</td><td>Static features data dictionary</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üöÄ</span>
                    <div>
                        <h2 class="section-title">Uses</h2>
                        <p class="section-description">What (other) tasks could the dataset be used for?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Tasks
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Task</dd><dt>Response</dt><dd>AI/ML research on voice-based biomarkers for disease screening, monitoring, and prognosis.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Other Tasks
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Potential uses</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Disease screening and therapeutic monitoring for respiratory, voice, neurological, and mood/psychiatric disorders.</li><li>Development and evaluation of AI methods for voice analysis.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Future Use Impacts
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Considerations for future use</dd><dt>Description</dt><dd><ul class='formatted-list'><li>v1.0 includes only derived features and spectrograms (no raw audio), which may limit tasks requiring waveforms.</li><li>Free-speech transcripts removed.</li><li>Adult-only dataset in v1.0; pediatric cohort not yet included.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License And Use Terms
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Name</dt><dd>Access and licensing</dd><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>License</dt><dd>Bridge2AI Voice Registered Access License.</dd></dl></li><li><dl class='nested-dict'><dt>Access Policy</dt><dd>Only credentialed users who sign the Bridge2AI Voice Registered Access Agreement.</dd></dl></li><li><dl class='nested-dict'><dt>Required Training</dt><dd>TCPS 2: CORE 2022.</dd></dl></li></ul></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üì§</span>
                    <div>
                        <h2 class="section-title">Distribution</h2>
                        <p class="section-description">How will the dataset be distributed?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            DOI
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License
                            
                        </label>
                        <div class="item-value">Bridge2AI Voice Registered Access License</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version Access
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Name</dt><dd>Versioning and access to older versions</dd><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Versioned DOI (v1.0)</dt><dd><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">https://doi.org/10.57764/qb6h-em84</a></dd></dl></li><li><dl class='nested-dict'><dt>Latest Version DOI</dt><dd><a href="https://doi.org/10.57764/3sg0-7440" target="_blank">https://doi.org/10.57764/3sg0-7440</a></dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîÑ</span>
                    <div>
                        <h2 class="section-title">Maintenance</h2>
                        <p class="section-description">How will the dataset be maintained?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version
                            
                        </label>
                        <div class="item-value">1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Last Updated On
                            
                        </label>
                        <div class="item-value">2024-11-27</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Updates
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Name</dt><dd>Update plan</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Future releases aim to include original voice audio waveforms with additional security measures; see latest DOI for updates.</li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
    
    
    <div class="timestamp">
        Generated on 2025-11-09 10:17:34 using Bridge2AI Data Sheets Schema
    </div>
</body>
</html>
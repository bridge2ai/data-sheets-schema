
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="datasheet-common.css">
    <title>healthnexus tab ethics d4d - Datasheet for Dataset</title>
</head>
<body>
    <div class="header">
        <h1>healthnexus tab ethics d4d</h1>
        <p class="subtitle">Datasheet for Dataset - Human Readable Format</p>
    </div>
    
    
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üéØ</span>
                    <div>
                        <h2 class="section-title">Motivation</h2>
                        <p class="section-description">Why was the dataset created?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Purposes
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>purpose-1</dd><dt>Name</dt><dd>Dataset purpose</dd><dt>Response</dt><dd>Enable AI research and critical insights into the use of voice as a biomarker of health via an ethically sourced, diverse, multi-institutional dataset linked to clinical information.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Funders
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Grantor</th><th>Grant Name</th><th>Grant Number</th></tr></thead><tbody><tr><td>National Institutes of Health (NIH)</td><td>Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before</td><td>3OT2OD032720-01S1</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üìä</span>
                    <div>
                        <h2 class="section-title">Composition</h2>
                        <p class="section-description">What do the instances represent?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Instances
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Counts</th><th>Data Type</th><th>ID</th><th>Instance Type</th><th>Name</th><th>Representation</th></tr></thead><tbody><tr><td>12523</td><td>Spectrograms (513xN), acoustic/phonetic/prosodic features; raw waveforms not included in v1.0.</td><td>instance-recordings</td><td>participants, sessions, and recordings</td><td>Derived recording instances</td><td>Derived voice data elements per recording (e.g., spectrogram matrices, static features) linked to se...</td></tr><tr><td>306</td><td>Tabular phenotype data with one row per participant; associated data dictionary.</td><td>instance-participants</td><td>participants</td><td>Participant instances</td><td>Adult participants with demographic, clinical, and validated questionnaire responses.</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subpopulations
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>subp-1</dd><dt>Name</dt><dd>Disease cohorts</dd><dt>Identification</dt><dd><ul class='formatted-list'><li>Voice disorders</li><li>Neurological and neurodegenerative disorders</li><li>Mood and psychiatric disorders</li><li>Respiratory disorders</li><li>Pediatric voice and speech disorders (adult cohort only in v1.0)</li></ul></dd><dt>Distribution</dt><dd><ul class='formatted-list'><li>Adult cohort only; 306 participants across five sites in North America.</li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Formats
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>distfmt-1</dd><dt>Name</dt><dd>Distribution formats and files</dd><dt>Description</dt><dd><ul class='formatted-list'><li>spectrograms.parquet (Parquet; spectrogram matrices and metadata)</li><li>phenotype.tsv (tab-delimited; one row per participant)</li><li>phenotype.json (data dictionary for phenotype)</li><li>static_features.tsv (tab-delimited; one row per recording with features)</li><li>static_features.json (data dictionary for features)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Dates
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>distdate-1</dd><dt>Name</dt><dd>Initial release date</dd><dt>Description</dt><dd><ul class='formatted-list'><li>2024-11-27 (v1.0 first release)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>access-1</dd><dt>Name</dt><dd>Access modality</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Restricted (Credentialed Access) via Health Data Nexus; DUA and training required; no public download URLs provided for files.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîç</span>
                    <div>
                        <h2 class="section-title">Collection Process</h2>
                        <p class="section-description">How was the data acquired?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label required-field">
                            ID
                            <span class="required-indicator" title="Required field">*</span>
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Name
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice v1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Title
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Description
                            
                        </label>
                        <div class="item-value"><div class="long-description">Bridge2AI-Voice is a comprehensive, ethically sourced dataset enabling research on the human voice as a biomarker of health. The v1.0 release provides 12,523 recordings from 306 adult participants collected across five North American sites, with data derived from voice recordings (e.g., spectrograms, acoustic/phonetic/prosodic features) and linked clinical, demographic, and validated questionnaire information. Raw audio waveforms and free speech transcripts are not included in v1.0; only low-risk derivations are provided.
</div></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Language
                            
                        </label>
                        <div class="item-value">en</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Page
                            
                        </label>
                        <div class="item-value"><a href="https://docs.b2ai-voice.org" target="_blank">https://docs.b2ai-voice.org</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Issued
                            
                        </label>
                        <div class="item-value">2024-11-27</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Keywords
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>voice</li><li>audio</li><li>Bridge2AI</li><li>biomarker</li><li>clinical</li><li>spectrograms</li><li>credentialed access</li><li>multi-institutional</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Addressing Gaps
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>gap-1</dd><dt>Name</dt><dd>Gap addressed</dd><dt>Response</dt><dd>Addresses the lack of large, high-quality, diverse, and standardized multi-institutional voice datasets linked to other health biomarkers for robust AI research.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Creators
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Role</th><th>Name</th><th>ORCID</th><th>Affiliation</th></tr></thead><tbody><tr><td>Principal Investigator</td><td>Alistair Johnson</td><td>person-alistair-johnson</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Jean-Christophe B√©lisle-Pipon</td><td>person-jean-christophe-belisle-pipon</td><td>-</td></tr><tr><td>Principal Investigator</td><td>David Dorr</td><td>person-david-dorr</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Satrajit Ghosh</td><td>person-satrajit-ghosh</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Philip Payne</td><td>person-philip-payne</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Maria Powell</td><td>person-maria-powell</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Ana√Øs Rameau</td><td>person-anais-rameau</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Vardit Ravitsky</td><td>person-vardit-ravitsky</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Alexandros Sigaras</td><td>person-alexandros-sigaras</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Olivier Elemento</td><td>person-olivier-elemento</td><td>-</td></tr><tr><td>Principal Investigator</td><td>Yael Bensoussan</td><td>person-yael-bensoussan</td><td>-</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Created By
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>Bridge2AI-Voice Team</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sampling Strategies
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>sampling-1</dd><dt>Name</dt><dd>Clinical cohort sampling</dd><dt>Is Sample</dt><dd><ul class='formatted-list'><li>True</li></ul></dd><dt>Is Random</dt><dd><ul class='formatted-list'><li>False</li></ul></dd><dt>Source Data</dt><dd><ul class='formatted-list'><li>Patients at specialty clinics across five North American sites</li></ul></dd><dt>Is Representative</dt><dd><ul class='formatted-list'><li>No (targeted cohorts by condition)</li></ul></dd><dt>Why Not Representative</dt><dd><ul class='formatted-list'><li>Participants selected based on five predetermined disease groups (voice, neurological/neurodegenerative, mood/psychiatric, respiratory, pediatric)</li></ul></dd><dt>Strategies</dt><dd><ul class='formatted-list'><li>Targeted clinical cohort sampling based on known voice-related conditions</li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Relationships
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>rel-1</dd><dt>Name</dt><dd>Instance relationships</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Recordings are nested within sessions and participants; features and spectrograms link via participant_id, session_id, and task_name.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Confidential Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>confidential-1</dd><dt>Name</dt><dd>Clinical and questionnaire data</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Contains clinical, demographic, and questionnaire information; released in de-identified, low-risk form.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sensitive Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>sensitive-1</dd><dt>Name</dt><dd>Sensitive health-related data</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Health, demographic, and questionnaire data linked to voice recordings (de-identified).</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Deidentified
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>ID</dt><dd>deid-1</dd><dt>Name</dt><dd>De-identification</dd><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor identifiers removed (e.g., names, detailed geography, dates below year, contact and ID numbers, biometric identifiers).</li><li>State and province removed; country of data collection retained.</li><li>Transcripts of free speech audio removed prior to release.</li><li>Audio waveforms omitted from v1.0; only derived spectrograms and features released.</li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Acquisition Methods
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>acq-1</dd><dt>Name</dt><dd>Data acquisition</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Standardized protocol including demographics, health and targeted questionnaires, disease-specific information, and voice tasks (e.g., sustained vowel).</li><li>Data captured via custom tablet application with headset when possible; consent obtained prior to collection.</li></ul></dd><dt>Was Directly Observed</dt><dd>Yes (voice recordings, tasks)</dd><dt>Was Reported By Subjects</dt><dd>Yes (validated questionnaires)</dd><dt>Was Inferred Derived</dt><dd>Yes (features, spectrograms, ASR transcriptions)</dd><dt>Was Validated Verified</dt><dd>Standardized protocol and validated questionnaires; processing pipeline described and open-sourced.</dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Collection Mechanisms
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>mech-1</dd><dt>Name</dt><dd>Collection mechanisms</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Custom tablet app; headset-based recording when possible; data exported from REDCap and converted using an open-source library (b2aiprep).</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Data Collectors
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>collectors-1</dd><dt>Name</dt><dd>Data collectors</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Project investigators at specialty clinics screened patients and obtained consent; most participants completed a single session, some multiple sessions.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Ethical Reviews
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>irb-1</dd><dt>Name</dt><dd>Ethical review</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Data collection and sharing approved by University of South Florida Institutional Review Board; submitted for review to University of Toronto Research Ethics Board.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Preprocessing Strategies
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Description</th><th>ID</th><th>Name</th><th>Used Software</th></tr></thead><tbody><tr><td>Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter; STFT spectrograms computed with 25 ms window, 10 ms hop, 512-point FFT.</td><td>prep-1</td><td>Audio standardization and spectrogram extraction</td><td>{'id': 'sw-torchaudio', 'name': 'Torchaudio'}</td></tr><tr><td>Temporal and acoustic characteristics extracted using OpenSMILE.</td><td>prep-2</td><td>Acoustic feature extraction</td><td>{'id': 'sw-opensmile', 'name': 'OpenSMILE'}</td></tr><tr><td>Fundamental frequency, formants, and voice quality computed using Parselmouth and Praat.</td><td>prep-3</td><td>Phonetic and prosodic feature extraction</td><td>{'id': 'sw-parselmouth', 'name': 'Parselmouth'}, {'id': 'sw-praat', 'name': 'Praat'}</td></tr><tr><td>Automatic speech transcriptions generated using OpenAI Whisper Large (free speech transcripts removed prior to release).</td><td>prep-4</td><td>Transcription</td><td>{'id': 'sw-whisper', 'name': 'OpenAI Whisper Large'}</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Cleaning Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>clean-1</dd><dt>Name</dt><dd>Data integration and standardization</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Source data exported from REDCap and merged into phenotype and feature files; accompanying JSON data dictionaries provide variable descriptions; processing code available in b2aiprep.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Labeling Strategies
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>label-1</dd><dt>Name</dt><dd>Automatic transcription</dd><dt>Description</dt><dd><ul class='formatted-list'><li>ASR transcriptions generated using OpenAI Whisper Large; free speech transcripts removed from released data.</li></ul></dd><dt>Used Software</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>sw-whisper</dd><dt>Name</dt><dd>OpenAI Whisper Large</dd></dl></li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Raw Sources
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>raw-1</dd><dt>Name</dt><dd>Raw audio waveforms</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Raw audio collected but omitted from v1.0 release; future releases aim to include voice data with additional security precautions.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            External Resources
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>ext-1</dd><dt>Name</dt><dd>External resources and documentation</dd><dt>External Resources</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Documentation Site</dt><dd><a href="https://docs.b2ai-voice.org" target="_blank">https://docs.b2ai-voice.org</a></dd></dl></li><li>REDCap resource record (Zenodo citation provided in references)</li><li>b2aiprep open-source processing library</li></ul></dd><dt>Future Guarantees</dt><dd><ul class='formatted-list'><li>Versioned DOIs available for releases.</li></ul></dd><dt>Archival</dt><dd><ul class='formatted-list'><li>DOIs provided (versioned and latest).</li></ul></dd><dt>Restrictions</dt><dd><ul class='formatted-list'><li>Access via Health Data Nexus under registered access with DUA and required training.</li></ul></dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subsets
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Description</th><th>Dialect</th><th>Format</th><th>ID</th><th>Media Type</th><th>Name</th><th>Path</th><th>Title</th></tr></thead><tbody><tr><td>Parquet dataset with participant_id, session_id, task_name, and 513xN spectrogram matrices derived f...</td><td></td><td></td><td>subset-spectrograms-parquet</td><td>application/x-parquet</td><td>spectrograms.parquet</td><td>spectrograms.parquet</td><td>Spectrograms derived from raw audio</td></tr><tr><td>Tab-delimited table with demographics, acoustic confounders, and validated questionnaire responses (...</td><td>delimiter: 	<br>header: true</td><td></td><td>subset-phenotype-tsv</td><td>text/tab-separated-values</td><td>phenotype.tsv</td><td>phenotype.tsv</td><td>Participant phenotype data</td></tr><tr><td>JSON data dictionary providing descriptions of columns in phenotype.tsv.</td><td></td><td>JSON</td><td>subset-phenotype-json</td><td>application/json</td><td>phenotype.json</td><td>phenotype.json</td><td>Phenotype data dictionary</td></tr><tr><td>Tab-delimited table with one row per recording containing features derived from openSMILE, Praat, Pa...</td><td>delimiter: 	<br>header: true</td><td></td><td>subset-static-features-tsv</td><td>text/tab-separated-values</td><td>static_features.tsv</td><td>static_features.tsv</td><td>Static acoustic features per recording</td></tr><tr><td>JSON data dictionary providing feature descriptions for static_features.tsv.</td><td></td><td>JSON</td><td>subset-static-features-json</td><td>application/json</td><td>static_features.json</td><td>static_features.json</td><td>Static features data dictionary</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üöÄ</span>
                    <div>
                        <h2 class="section-title">Uses</h2>
                        <p class="section-description">What (other) tasks could the dataset be used for?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Tasks
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>task-1</dd><dt>Name</dt><dd>Intended tasks</dd><dt>Response</dt><dd>Research and development of AI methods for disease-related voice/speech changes, feature discovery, and health prediction using voice-derived representations linked to clinical data.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License And Use Terms
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>ID</dt><dd>license-1</dd><dt>Name</dt><dd>Access, license, and use terms</dd><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>License</dt><dd>Bridge2AI Voice Registered Access License.</dd></dl></li><li><dl class='nested-dict'><dt>Access Policy</dt><dd>Only credentialed users who sign the Data Use Agreement (DUA) can access the files.</dd></dl></li><li><dl class='nested-dict'><dt>Data Use Agreement</dt><dd>Bridge2AI Voice Registered Access Agreement.</dd></dl></li><li><dl class='nested-dict'><dt>Required Training</dt><dd>TCPS 2: CORE 2022.</dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Existing Uses
                            
                        </label>
                        <div class="item-value"></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Use Repository
                            
                        </label>
                        <div class="item-value"></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Future Use Impacts
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>ID</dt><dd>future-impact-1</dd><dt>Name</dt><dd>Potential impacts on future use</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Absence of raw audio in v1.0 may limit certain signal processing and modeling tasks; inclusion planned in future releases with additional safeguards.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üì§</span>
                    <div>
                        <h2 class="section-title">Distribution</h2>
                        <p class="section-description">How will the dataset be distributed?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            DOI
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version Access
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>ID</dt><dd>versioning-1</dd><dt>Name</dt><dd>Versioning and access</dd><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Version 1.0 DOI</dt><dd><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">https://doi.org/10.57764/qb6h-em84</a></dd></dl></li><li><dl class='nested-dict'><dt>Latest Version DOI</dt><dd><a href="https://doi.org/10.57764/3sg0-7440" target="_blank">https://doi.org/10.57764/3sg0-7440</a></dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîÑ</span>
                    <div>
                        <h2 class="section-title">Maintenance</h2>
                        <p class="section-description">How will the dataset be maintained?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version
                            
                        </label>
                        <div class="item-value">1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Updates
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>ID</dt><dd>update-1</dd><dt>Name</dt><dd>Update plan</dd><dt>Description</dt><dd><ul class='formatted-list'><li>Future releases aim to include voice waveforms with additional precautions to ensure data security; v1.0 provides low-risk derived data only.</li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
    
    
    <div class="timestamp">
        Generated on 2025-11-09 10:17:34 using Bridge2AI Data Sheets Schema
    </div>
</body>
</html>
# D4D Metadata extracted from: healthnexus_tab_background_row15.txt
# Source: downloads_by_column_enhanced/VOICE/healthnexus_tab_background_row15.txt
# Column: VOICE
# Validation: Download ✅ success
# Relevance: ✅ relevant
# Generated: 2025-10-31T17:19:39
# Generator: validated_d4d_wrapper (openai:gpt-5)
# Method: automated
# Schema: https://raw.githubusercontent.com/monarch-initiative/ontogpt/main/src/ontogpt/templates/data_sheets_schema.yaml

id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: The Bridge2AI-Voice project provides a comprehensive, ethically sourced dataset of derived voice data linked to clinical information to enable research on voice as a biomarker of health. Version 1.0 includes 12,523 recordings from 306 adult participants collected across five sites in North America. Participants were selected based on known conditions with vocal manifestations, including voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, and respiratory disorders. This initial release includes low-risk derived data (e.g., spectrograms and engineered acoustic features) and detailed demographic, clinical, and validated questionnaire data; original audio waveforms and free speech transcripts are not included.
doi: "doi:10.57764/qb6h-em84"
issued: 2024-11-27
version: "1.0"
page: "https://docs.b2ai-voice.org"
language: en
keywords:
  - voice
  - bridge2ai
  - audio
license: Bridge2AI Voice Registered Access License
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
purposes:
  - response: Create an ethically sourced, diverse voice dataset linked to clinical information to enable AI research on voice as a biomarker of health.
tasks:
  - response: Develop and evaluate AI methods for analyzing voice-derived representations to study associations with health conditions (e.g., voice, neurological, mood/psychiatric, and respiratory disorders).
addressing_gaps:
  - response: Provide a large, multi-institutional, diverse voice resource with standardized collection protocols and linked clinical data to address limitations of small, demographically limited prior datasets.
creators:
  - name: Alistair Johnson
  - name: Jean-Christophe Bélisle-Pipon
  - name: David Dorr
  - name: Satrajit Ghosh
  - name: Philip Payne
  - name: Maria Powell
  - name: Anaïs Rameau
  - name: Vardit Ravitsky
  - name: Alexandros Sigaras
  - name: Olivier Elemento
  - name: Yael Bensoussan
funders:
  - grantor:
      name: NIH
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before."
      grant_number: 3OT2OD032720-01S1
instances:
  - representation: Voice recordings with derived spectrograms and engineered acoustic/phonetic/prosodic features, linked to participant- and session-level clinical and questionnaire data.
    instance_type: Participants and recording sessions; one row per recording in static features; one row per participant in phenotype; spectrogram tensors per recording.
    data_type: Derived data including 513×N spectrograms, OpenSMILE features, Praat/Parselmouth measures, and torchaudio features; detailed demographic/clinical/questionnaire tabular data.
    counts: 12523
    label: Not specified; dataset focuses on derived features and linked clinical/questionnaire variables.
    sampling_strategies:
      - strategies:
          - Participants recruited at specialty clinics across five North American sites based on membership in predetermined disease cohort categories (respiratory, voice, neurological, mood; adult cohort available in v1.0).
        is_sample:
          - yes
        is_random:
          - no
        source_data:
          - Clinic populations presenting to specialty clinics and institutions.
        is_representative:
          - not guaranteed; selection based on clinical cohorts and site availability
        representative_verification:
          - Not described.
        why_not_representative:
          - Cohort-based recruitment at specialty clinics; geographic/state-level detail removed; adult cohort only in v1.0.
    missing_information:
      - missing:
          - Original audio waveforms and free speech transcripts are not included in v1.0.
        why_missing:
          - Privacy and de-identification; low-risk derived data only in initial release.
relationships: []
splits: []
anomalies: []
external_resources:
  - external_resources:
      - https://docs.b2ai-voice.org
    archival:
      - Versioned DOIs provided (version-specific and latest).
    restrictions:
      - Credentialed access with signed DUA and required training.
confidential_elements:
  - description:
      - Dataset includes de-identified clinical and questionnaire information linked to voice-derived data; identifiers removed under HIPAA Safe Harbor.
content_warnings: []
subpopulations:
  - identification:
      - Adult cohort (v1.0).
      - Participants recruited based on disease cohort categories (voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders).
    distribution:
      - 306 adult participants across five sites in North America.
sensitive_elements:
  - description:
      - Health-related demographic, clinical, and validated questionnaire data; biometric voice-derived features (spectrograms and acoustic measures). Original audio not released in v1.0.
acquisition_methods:
  - description:
      - Data include directly observed voice tasks (e.g., sustained vowel), participant-reported questionnaire responses, and indirectly derived features from audio. Standardized protocol followed by investigators.
    was_directly_observed: yes
    was_reported_by_subjects: yes
    was_inferred_derived: yes
    was_validated_verified: yes
collection_mechanisms:
  - description:
      - Standardized data collection via a custom tablet application; headset used when possible; demographic/clinical/questionnaire capture; audio tasks including sustained phonation. Data exported from REDCap and converted using an open-source library (b2aiprep).
data_collectors:
  - description:
      - Project investigators at specialty clinics and institutions across five sites in North America.
ethical_reviews:
  - description:
      - Data collection and sharing approved by the University of South Florida Institutional Review Board; submitted for review to the University of Toronto Research Ethics Board.
preprocessing_strategies:
  - description:
      - Raw audio converted to monaural, resampled to 16 kHz with a Butterworth anti-aliasing filter. Spectrograms computed via STFT with 25 ms window, 10 ms hop, 512-point FFT. Acoustic features extracted with OpenSMILE; phonetic/prosodic measures via Parselmouth/Praat; additional features via torchaudio. Transcriptions generated using OpenAI's Whisper Large (free speech transcripts not released).
    used_software:
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
      - name: OpenSMILE
      - name: Parselmouth
      - name: Praat
      - name: torchaudio
      - name: OpenAI Whisper Large
cleaning_strategies:
  - description:
      - HIPAA Safe Harbor identifiers removed.
      - State and province removed; country of data collection retained.
      - Free speech transcripts removed; original audio waveforms omitted from v1.0 release.
labeling_strategies:
  - description:
      - Automatic transcriptions generated using OpenAI's Whisper Large; free speech transcripts excluded from the release.
raw_sources:
  - description:
      - Original audio waveforms were not distributed in v1.0; only derived spectrograms and features are provided. Future releases aim to include voice data with additional safeguards.
distribution_formats:
  - description:
      - Parquet (.parquet) for spectrogram tensors
  - description:
      - Tab-delimited text (.tsv) for phenotype and static features
  - description:
      - JSON (.json) data dictionaries for phenotype and features
distribution_dates:
  - description:
      - 2024-11-27 (v1.0 released)
license_and_use_terms:
  description:
    - License (files): Bridge2AI Voice Registered Access License.
    - Data Use Agreement (DUA): Bridge2AI Voice Registered Access Agreement.
    - Access policy (credentialed): Only credentialed users who sign the DUA can access the files.
    - Required training: TCPS 2 CORE 2022.
updates:
  description:
    - b2ai-voice v1.0 is the initial release; future releases are planned to include voice audio waveforms with additional precautions to ensure data security.
version_access:
  description:
    - Latest version is tracked via DOI. Version 1.0 DOI https://doi.org/10.57764/qb6h-em84; latest version DOI https://doi.org/10.57764/3sg0-7440.
is_deidentified:
  description:
    - Dataset prepared to minimize re-identification risk; HIPAA Safe Harbor identifiers removed; state/province removed; original audio and free speech transcripts not included in v1.0.
is_tabular: mixed
distribution: []
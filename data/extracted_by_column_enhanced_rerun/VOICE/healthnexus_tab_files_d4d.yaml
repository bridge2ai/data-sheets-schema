# D4D Metadata extracted from: healthnexus_tab_files_row15.txt
# Source: downloads_by_column_enhanced/VOICE/healthnexus_tab_files_row15.txt
# Column: VOICE
# Validation: Download ✅ success
# Relevance: ✅ relevant
# Generated: 2025-10-31T17:16:25
# Generator: validated_d4d_wrapper (openai:gpt-5)
# Method: automated
# Schema: https://raw.githubusercontent.com/monarch-initiative/ontogpt/main/src/ontogpt/templates/data_sheets_schema.yaml

id: Bridge2AI-Voice_v1.0
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information v1.0"
description: >-
  Bridge2AI-Voice is a comprehensive, ethically-sourced, multi-site dataset of
  derived voice data linked to clinical, demographic, and validated questionnaire
  information to enable AI research on voice as a biomarker of health. Version
  1.0 includes 12,523 derived recordings for 306 adult participants collected
  across five North American sites. The initial release provides low-risk
  derivatives (e.g., spectrograms, acoustic/phonetic/prosodic features) and
  phenotype data; raw audio waveforms and free-speech transcripts are not
  included. Standardized collection protocols, de-identification under HIPAA Safe
  Harbor, and ethics approvals were applied.
page: "https://docs.b2ai-voice.org"
doi: "doi:10.57764/qb6h-em84"
issued: "2024-11-27"
created_on: "2024-11-27"
last_updated_on: "2024-11-27"
version: "1.0"
keywords:
  - voice
  - bridge2ai
  - audio
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
license: Bridge2AI Voice Registered Access License
purposes:
  - name: Purpose
    response: >-
      Create an ethically sourced flagship dataset to enable AI research on voice
      as a biomarker of health and support insights into links between voice and
      health conditions.
tasks:
  - name: Task
    response: >-
      AI/ML research using derived voice representations (e.g., spectrograms and
      acoustic/phonetic/prosodic features) for health-related analyses, including
      studies of voice, neurological, mood/psychiatric, respiratory, and pediatric
      voice/speech disorders.
addressing_gaps:
  - name: AddressingGap
    response: >-
      Addresses the need for a large, high-quality, multi-institutional, diverse
      voice dataset linked to health and demographic data, collected under
      standardized protocols with ethical oversight.
instances:
  - name: Instance
    representation: >-
      Derived representations of voice recordings linked to clinical/demographic
      and validated questionnaire data.
    instance_type: >-
      Participants (people), recording sessions, and tasks (e.g., sustained vowel
      phonation) with per-recording derived feature sets.
    data_type: >-
      Derived spectrograms (513 x N), acoustic features (openSMILE), phonetic and
      prosodic features (Praat/Parselmouth), machine-generated transcriptions
      (Whisper; free-speech transcripts removed for release), and phenotype
      (tabular) data.
    counts: 12523
    sampling_strategies:
      - name: SamplingStrategy
        is_sample:
          - "yes"
        is_random:
          - "no"
        source_data:
          - Patients at specialty clinics and institutions across five North American sites
        is_representative:
          - "no"
        why_not_representative:
          - >-
            Participants selected into five predetermined clinical cohorts (voice disorders,
            neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory
            disorders, pediatric) rather than a population-representative sample.
        strategies:
          - >-
            Targeted clinical cohort enrollment based on inclusion/exclusion criteria and
            known conditions with voice manifestations.
subpopulations:
  - name: Subpopulation
    identification:
      - Voice disorders
      - Neurological and neurodegenerative disorders
      - Mood and psychiatric disorders
      - Respiratory disorders
      - Pediatric voice and speech disorders
    distribution:
      - "Adult cohort only in v1.0; 306 participants across five sites in North America."
      - "12,523 recordings (derived) with session/task structure."
is_deidentified:
  name: Deidentification
  description:
    - HIPAA Safe Harbor identifiers removed (e.g., names, fine-grained dates, contact/billing identifiers).
    - State and province removed; country of data collection retained.
    - Free-speech transcripts removed.
    - Raw audio waveforms omitted in v1.0; only low-risk derivatives released.
sensitive_elements:
  - name: SensitiveElement
    description:
      - >-
        Contains health-related clinical, demographic, and validated questionnaire data
        linked to voice-derived features; released in de-identified form with low-risk
        derivatives only.
confidential_elements:
  - name: Confidentiality
    description:
      - >-
        Potentially sensitive health information present but released in de-identified form.
        Higher-risk elements (raw audio, free-speech transcripts) are not included in v1.0.
acquisition_methods:
  - name: InstanceAcquisition
    description:
      - >-
        Standardized clinical protocol including demographic information, health questionnaires,
        targeted confounders, disease-specific information, and voice recording tasks
        (e.g., sustained vowel). Single-session collection typical; some participants
        required multiple sessions.
      - >-
        Data captured via custom tablet application; headset used when possible; data exported
        from REDCap and converted using open-source tooling.
    was_directly_observed: "yes (voice recordings)"
    was_reported_by_subjects: "yes (questionnaires)"
    was_inferred_derived: "yes (features, spectrograms, machine-generated transcripts)"
    used_software:
      - name: REDCap
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
collection_mechanisms:
  - name: CollectionMechanism
    description:
      - >-
        Custom tablet-based data collection application; headset microphone used when possible;
        standardized clinical protocols at specialty clinics.
    used_software:
      - name: REDCap
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
data_collectors:
  - name: DataCollector
    description:
      - >-
        Project investigators and clinical staff at specialty clinics across five North American
        sites; participants enrolled based on inclusion/exclusion criteria within predetermined cohorts.
collection_timeframes: []
ethical_reviews:
  - name: EthicalReview
    description:
      - >-
        Data collection and sharing approved by the University of South Florida Institutional
        Review Board; submitted for review to the University of Toronto Research Ethics Board.
data_protection_impacts:
  - name: DataProtectionImpact
    description:
      - >-
        De-identification under HIPAA Safe Harbor; exclusion of raw audio and free-speech transcripts
        in v1.0 reduces re-identification risk; access restricted via registered/credentialed access
        with DUA and required training.
preprocessing_strategies:
  - name: PreprocessingStrategy
    description:
      - "Raw audio converted to mono; resampled to 16 kHz with Butterworth anti-aliasing filter."
      - "Spectrograms via STFT: 25ms window, 10ms hop, 512-point FFT (513 x N)."
      - "Acoustic features extracted with openSMILE."
      - "Phonetic/prosodic features computed with Praat/Parselmouth."
      - "Transcriptions generated with OpenAI Whisper (free-speech transcripts not released)."
    used_software:
      - name: openSMILE
      - name: Praat
      - name: Parselmouth
      - name: Torchaudio
      - name: Whisper Large
      - name: librosa
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
labeling_strategies:
  - name: LabelingStrategy
    description:
      - "Machine-generated transcriptions using OpenAI Whisper Large."
      - "Validated questionnaire responses captured via standardized protocol."
    used_software:
      - name: Whisper Large
      - name: REDCap
raw_sources:
  - name: RawData
    description:
      - >-
        Raw audio waveforms were collected but are omitted from v1.0 release. Future releases may
        include raw voice data with additional security precautions.
existing_uses: []
use_repository:
  - name: UseRepository
    description:
      - "Documentation and usage guidance: https://docs.b2ai-voice.org"
other_tasks:
  - name: OtherTask
    description:
      - >-
        Exploratory analyses of acoustic markers linked to health conditions; benchmarking AI models
        on derived voice features for clinical research questions.
future_use_impacts:
  - name: FutureUseImpact
    description:
      - >-
        v1.0 includes only adult cohort data and derived features without raw audio, which may
        limit certain modeling approaches (e.g., end-to-end audio models). Future inclusion of
        raw audio will require heightened privacy and security considerations.
distribution_formats:
  - name: DistributionFormat
    description:
      - "Parquet (.parquet) for spectrograms"
      - "Tab-separated values (.tsv) for phenotype and static features"
      - "JSON (.json) data dictionaries"
distribution_dates:
  - name: DistributionDate
    description:
      - "Initial release (v1.0): 2024-11-27"
license_and_use_terms:
  name: LicenseAndUseTerms
  description:
    - "License: Bridge2AI Voice Registered Access License."
    - "Access requires credentialed user status, completion of TCPS 2: CORE 2022 training, and signing the DUA."
    - "Data Use Agreement: Bridge2AI Voice Registered Access Agreement."
ip_restrictions: {}
regulatory_restrictions: {}
maintainers:
  - name: Maintainer
    description:
      - "Hosted via Health Data Nexus; maintained by the Bridge2AI-Voice project team."
errata: []
updates:
  name: UpdatePlan
  description:
    - >-
      Future releases aim to include raw voice data with additional data security precautions;
      updates and materials will be communicated via the project documentation site.
retention_limit: {}
version_access: {}
extension_mechanism: {}
is_tabular: "Mixed: tabular phenotype/features and array-based spectrograms (Parquet)"
subsets:
  - id: spectrograms.parquet
    name: Spectrograms
    title: Derived spectrograms
    description: >-
      Parquet dataset containing 513 x N spectrograms per recording, with participant_id,
      session_id, and task_name metadata.
    media_type: application/x-parquet
    path: spectrograms.parquet
  - id: phenotype.tsv
    name: Phenotype TSV
    title: Participant phenotype and questionnaires
    description: >-
      Tab-delimited file with one row per participant; demographics, acoustic confounders,
      validated questionnaire responses.
    media_type: text/tab-separated-values
    path: phenotype.tsv
    is_data_split: "no"
    is_subpopulation: "no"
  - id: phenotype.json
    name: Phenotype Data Dictionary
    title: Phenotype data dictionary
    description: >-
      JSON data dictionary describing columns in phenotype.tsv.
    media_type: application/json
    path: phenotype.json
  - id: static_features.tsv
    name: Static Features TSV
    title: Acoustic/phonetic/prosodic features per recording
    description: >-
      Tab-delimited file with one row per unique recording containing features derived using
      openSMILE, Praat/Parselmouth, and torchaudio.
    media_type: text/tab-separated-values
    path: static_features.tsv
  - id: static_features.json
    name: Static Features Data Dictionary
    title: Static features data dictionary
    description: >-
      JSON data dictionary describing columns in static_features.tsv.
    media_type: application/json
    path: static_features.json
funders:
  - name: FundingMechanism
    grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
external_resources:
  - name: ExternalResource
    external_resources:
      - "Project documentation website: https://docs.b2ai-voice.org"
      - "Bridge2AI Voice REDCap (v3.20.0) resource on Zenodo: https://doi.org/10.5281/zenodo.14148755"
    archival:
      - "Zenodo record for REDCap resource"
    restrictions:
      - "Dataset access is credentialed with DUA and required training"
software:
  - name: openSMILE
  - name: Praat
  - name: Parselmouth
  - name: Torchaudio
  - name: Whisper Large
  - name: librosa
  - name: REDCap
  - name: b2aiprep
    url: "https://github.com/sensein/b2aiprep"
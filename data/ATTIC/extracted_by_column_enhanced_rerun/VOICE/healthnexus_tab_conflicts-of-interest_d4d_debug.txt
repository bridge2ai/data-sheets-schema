=== YAML Fixing Applied ===
id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information (version 1.0)"
description: >-
  Bridge2AI-Voice is an ethically sourced, multi-institutional voice dataset to
  enable AI research on voice as a biomarker of health. The initial v1.0 release
  provides 12,523 recordings from 306 adult participants collected across five
  sites in North America. Participants were selected from cohorts with conditions
  known to manifest in voice, including voice disorders, neurological and
  neurodegenerative disorders, mood and psychiatric disorders, and respiratory
  disorders. This release contains low-risk, de-identified derived data including
  spectrograms and engineered acoustic, phonetic, and prosodic features, plus
  detailed demographic, clinical, and validated questionnaire data; original
  audio waveforms and free speech transcripts are not included in v1.0. See
  documentation at https://docs.b2ai-voice.org/.
doi: "doi:10.57764/qb6h-em84"
issued: "2024-11-27"
version: "1.0"
page: "https://doi.org/10.57764/qb6h-em84"
keywords:
  - voice
  - bridge2ai
  - audio
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
purposes:
  - name: Purpose
    response: >-
      Create an ethically sourced flagship dataset to enable AI research on
      voice as a biomarker of health and support insights into links between
      acoustic markers and clinical conditions.
tasks:
  - name: Task
    response: >-
      Develop and evaluate AI methods for disease screening, diagnosis, and
      monitoring using voice-derived representations (e.g., spectrograms and
      acoustic/phonetic/prosodic features) linked to clinical and questionnaire
      data.
addressing_gaps:
  - name: AddressingGap
    response: >-
      Address the lack of large, high-quality, diverse, multi-institutional
      voice datasets linked to clinical and demographic information, collected
      under standardized protocols with ethical oversight.
funders:
  - name: Funding
    grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
creators:
  - name: Bridge2AI-Voice Investigators
instances:
  - name: Instance Description
    representation: >-
      Voice recordings and derived acoustic representations linked to clinical,
      demographic, and questionnaire data.
    instance_type: >-
      Participants, sessions, and audio recordings; derived spectrograms and
      engineered features per recording; phenotype records per participant.
    data_type: >-
      Derived spectrograms (513 × N), acoustic features (OpenSMILE), phonetic
      and prosodic features (Parselmouth/Praat), and tabular phenotype data
      (TSV/JSON); original audio omitted in v1.0.
    counts: 12523
    label: >-
      No task-specific ground-truth labels provided; dataset includes clinical
      variables, disease cohort membership, and validated questionnaire responses.
    sampling_strategies:
      - name: Sampling
        is_sample:
          - "yes"
        is_random:
          - "no"
        source_data:
          - Specialty clinic patients at five North American sites
        is_representative:
          - "no"
        why_not_representative:
          - >-
            Participants were selected based on predefined disease cohorts rather
            than population sampling; adult cohort only in v1.0.
        strategies:
          - >-
            Deterministic cohort-based recruitment using inclusion/exclusion
            criteria and standardized protocols.
    missing_information:
      - name: MissingInfo
        missing:
          - Free speech transcripts
          - Original audio waveforms
          - Sub-state/province geolocation
          - Dates finer than year
        why_missing:
          - Removed during de-identification per HIPAA Safe Harbor
relationships:
  - name: Relationships
    description:
      - Participant-to-session-to-recording hierarchy with per-recording derived
        features and per-participant phenotype; tasks identified by task_name.
subpopulations:
  - name: Subpopulation
    identification:
      - Adult cohort only in v1.0
      - Disease cohorts: voice disorders; neurological/neurodegenerative; mood/psychiatric; respiratory
    distribution:
      - 306 participants across five North American sites; 12,523 recordings
is_deidentified:
  name: Deidentification
  description:
    - >-
      HIPAA Safe Harbor de-identification applied; removal of names,
      fine-grained dates, contact identifiers, device/account identifiers,
      URLs, biometric identifiers, and other PHI as applicable.
    - State/province removed; country retained.
    - Free speech transcripts removed.
    - Original audio waveforms omitted from v1.0; only derived data released.
sensitive_elements:
  - name: SensitiveElement
    description:
      - Contains de-identified clinical, demographic, and validated questionnaire
        data linked to voice-derived features.
acquisition_methods:
  - name: InstanceAcquisition
    description:
      - >-
        Data collected in specialty clinics using a standardized protocol:
        demographic and clinical questionnaires, targeted questionnaires on
        acoustic confounders, disease-specific information, and voice tasks
        (e.g., sustained vowel phonation).
      - >-
        Some participants completed multiple sessions; data exported from
        REDCap and processed via open-source pipelines.
    was_directly_observed: "yes (voice recordings and standardized tasks)"
    was_reported_by_subjects: "yes (questionnaires and self-reported information)"
    was_inferred_derived: "yes (spectrograms, engineered features, automatic transcriptions)"
    was_validated_verified: >-
      Standardized multi-site protocol; IRB/REB oversight; software pipelines
      documented; specific validation procedures for features not specified.
collection_mechanisms:
  - name: CollectionMechanism
    description:
      - Custom tablet application; headset used for recording when possible
      - REDCap used for data capture and management
      - Data exported and converted using the open-source b2aiprep library
data_collectors:
  - name: DataCollector
    description:
      - Project investigators at five North American specialty clinic sites
collection_timeframes: []
ethical_reviews:
  - name: EthicalReview
    description:
      - >-
        Data collection and sharing approved by the University of South Florida
        Institutional Review Board; submitted for review to the University of
        Toronto Research Ethics Board.
preprocessing_strategies:
  - name: Preprocessing
    description:
      - Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter
      - Spectrograms via STFT (25 ms window, 10 ms hop, 512-point FFT)
      - Acoustic features extracted with OpenSMILE
      - Phonetic and prosodic features via Parselmouth and Praat
      - Automatic transcriptions generated using OpenAI's Whisper Large
    used_software:
      - name: openSMILE
        url: "https://audeering.github.io/opensmile/"
      - name: Parselmouth
        url: "https://parselmouth.readthedocs.io/"
      - name: Praat
        url: "https://www.fon.hum.uva.nl/praat/"
      - name: OpenAI Whisper Large
        url: "https://github.com/openai/whisper"
      - name: torchaudio
        url: "https://pytorch.org/audio/stable/index.html"
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
cleaning_strategies:
  - name: Cleaning
    description:
      - HIPAA Safe Harbor de-identification procedures applied
      - Removal of state/province; retention of country only
      - Removal of free speech transcripts
      - Omission of original audio waveforms in v1.0
labeling_strategies:
  - name: Labeling
    description:
      - Automatic transcription using OpenAI Whisper Large (note: free speech transcripts removed in release)
      - Task identifiers (e.g., sustained vowel) recorded as task_name
raw_sources:
  - name: RawData
    description:
      - Original audio waveforms collected but not released in v1.0; planned for future releases with additional safeguards
external_resources:
  - name: ExternalResource
    external_resources:
      - Documentation website: https://docs.b2ai-voice.org
      - REDCap project reference (Zenodo): https://doi.org/10.5281/zenodo.14148755
      - Preprocessing library (b2aiprep): https://github.com/sensein/b2aiprep
    future_guarantees:
      - Not specified
    archival:
      - Versioned DOI available; latest: https://doi.org/10.57764/3sg0-7440
    restrictions:
      - Access restricted to credentialed users under Registered Access terms and DUA
use_repository: []
other_tasks:
  - name: OtherTask
    description:
      - Development of general-purpose voice embeddings for health applications
      - Biomarker discovery and longitudinal monitoring
      - Cross-cohort transfer learning across disease categories
future_use_impacts:
  - name: FutureUseImpact
    description:
      - >-
        Cohort-based recruitment and adult-only v1.0 may limit generalizability;
        models trained solely on v1.0 may not represent broader populations.
        Users should consider cohort selection factors and site effects to avoid
        biased or unfair outcomes.
discouraged_uses: []
distribution_formats:
  - name: DistributionFormat
    description:
      - Parquet: spectrograms.parquet (derived spectrograms, 513 × N arrays)
      - TSV: phenotype.tsv (per-participant) and static_features.tsv (per-recording)
      - JSON: phenotype.json and static_features.json (data dictionaries)
      - Database credentialed access via Health Data Nexus portal
distribution_dates:
  - name: DistributionDate
    description:
      - "2024-11-27 (v1.0 release)"
license: Bridge2AI Voice Registered Access License
license_and_use_terms:
  name: LicenseAndUseTerms
  description:
    - License: Bridge2AI Voice Registered Access License
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement
    - Access policy: Only credentialed users who sign the DUA and complete required training may access files
    - Required training: TCPS 2: CORE 2022
ip_restrictions:
  name: IPRestrictions
  description:
    - >-
      No third-party IP restrictions specified beyond Registered Access license
      and DUA terms.
regulatory_restrictions:
  name: ExportControlRegulatoryRestrictions
  description:
    - Not specified
maintainers:
  - name: Maintainer
    description:
      - Health Data Nexus (Temerty Centre for AI Research and Education in Medicine) hosts credentialed access portal
errata: []
updates:
  name: UpdatePlan
  description:
    - >-
      Future releases aim to include voice audio data with additional security
      precautions; dataset expected to be updated as protocols and safeguards
      evolve.
version_access:
  name: VersionAccess
  description:
    - Latest version DOI: https://doi.org/10.57764/3sg0-7440
    - Versioned releases maintained via DOI; v1.0 at https://doi.org/10.57764/qb6h-em84
extension_mechanism: {}
third_party_sharing:
  name: ThirdPartySharing
  description: >-
    Yes. Distributed to external credentialed users via Health Data Nexus under
    Registered Access and DUA requirements.
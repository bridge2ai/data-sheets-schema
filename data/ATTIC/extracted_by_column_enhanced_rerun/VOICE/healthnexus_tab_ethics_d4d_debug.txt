=== YAML Fixing Applied ===
id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice v1.0
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: >-
  Bridge2AI-Voice is a comprehensive, ethically-sourced dataset of derived data
  from human voice recordings linked to clinical and demographic information,
  released as version 1.0 on November 27, 2024. The initial release provides
  12,523 recordings for 306 adult participants collected across five clinical
  sites in North America, spanning disease cohorts where voice and speech
  changes are associated with health conditions: voice disorders, neurological
  and neurodegenerative disorders, mood and psychiatric disorders, and
  respiratory disorders. To minimize risk, this release contains low-risk
  derivations such as spectrograms and engineered acoustic/phonetic/prosodic
  features, plus phenotypic data and data dictionaries; original audio
  waveforms and free-speech transcripts are not included. Data were acquired
  under a standardized multi-institutional protocol with consent, de-identified
  using HIPAA Safe Harbor principles (with state/province removed and country
  retained), and distributed under registered, credentialed access with a DUA
  and required training. Documentation: https://docs.b2ai-voice.org
language: en
issued: 2024-11-27
page: "https://docs.b2ai-voice.org"
doi: "doi:10.57764/qb6h-em84"
version: "1.0"
keywords:
  - voice
  - bridge2ai
  - audio
license: Bridge2AI Voice Registered Access License
purposes:
  - name: Primary purpose
    response: >-
      Enable ethically-sourced, large-scale research into voice as a biomarker
      of health by providing diverse, multi-site clinical voice-derived data
      linked to health information for AI/ML development and evaluation.
tasks:
  - name: Intended tasks
    response: >-
      Development and evaluation of AI/ML methods for health-related inference
      from voice-derived representations (e.g., classification, screening,
      risk prediction, and biomarker discovery across voice, neurological, mood,
      and respiratory conditions).
addressing_gaps:
  - name: Addressing gaps
    response: >-
      Addresses the lack of large, diverse, ethically-sourced, multi-institutional
      voice datasets with linked clinical/phenotypic data and standardized
      protocols suitable for AI research; mitigates privacy risks by releasing
      derived features and spectrograms rather than raw audio.
creators:
  - name: Author
    principal_investigator:
      name: Alistair Johnson
  - name: Author
    principal_investigator:
      name: Jean-Christophe Bélisle-Pipon
  - name: Author
    principal_investigator:
      name: David Dorr
  - name: Author
    principal_investigator:
      name: Satrajit Ghosh
  - name: Author
    principal_investigator:
      name: Philip Payne
  - name: Author
    principal_investigator:
      name: Maria Powell
  - name: Author
    principal_investigator:
      name: Anaïs Rameau
  - name: Author
    principal_investigator:
      name: Vardit Ravitsky
  - name: Author
    principal_investigator:
      name: Alexandros Sigaras
  - name: Author
    principal_investigator:
      name: Olivier Elemento
  - name: Author
    principal_investigator:
      name: Yael Bensoussan
funders:
  - name: NIH Bridge2AI funding
    grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
subsets:
  - id: spectrograms.parquet
    name: spectrograms.parquet
    title: Spectrograms derived from voice waveforms
    description: >-
      Parquet dataset of time-frequency spectrograms (513 × N) per recording,
      with participant_id, session_id, and task_name metadata.
    media_type: application/x-parquet
    path: spectrograms.parquet
  - id: phenotype.tsv
    name: phenotype.tsv
    title: Participant phenotypic and questionnaire data (tab-delimited)
    description: >-
      One row per participant with demographics, acoustic confounders, validated
      questionnaire responses, and disease-specific information collected via
      standardized clinical protocol.
    media_type: text/tab-separated-values
    path: phenotype.tsv
    dialect:
      delimiter: "\t"
      header: true
  - id: phenotype.json
    name: phenotype.json
    title: Data dictionary for phenotype.tsv
    description: >-
      JSON data dictionary with column-level descriptions for phenotype.tsv.
    format: JSON
    media_type: application/json
    path: phenotype.json
  - id: static_features.tsv
    name: static_features.tsv
    title: Acoustic/phonetic/prosodic features per recording (tab-delimited)
    description: >-
      One row per unique recording with features extracted using openSMILE,
      Praat, Parselmouth, and torchaudio; includes engineered temporal and
      spectral characteristics.
    media_type: text/tab-separated-values
    path: static_features.tsv
    dialect:
      delimiter: "\t"
      header: true
  - id: static_features.json
    name: static_features.json
    title: Data dictionary for static_features.tsv
    description: >-
      JSON data dictionary with column-level descriptions for static_features.tsv.
    format: JSON
    media_type: application/json
    path: static_features.json
instances:
  - name: Voice-derived instances
    representation: Voice-derived data linked to clinical/phenotypic information
    instance_type: Participants, sessions, recordings, derived spectrograms/features
    data_type: >-
      Derived spectrograms (power), engineered acoustic/phonetic/prosodic features,
      phenotypic tabular data and data dictionaries; raw audio excluded in v1.0.
    counts: 12523
    label: >-
      No explicit gold-standard labels provided beyond clinical/phenotypic variables
      and cohort membership; tasks captured via task_name.
    sampling_strategies:
      - name: Clinical cohort sampling
        strategies:
          - >-
            Non-probability sampling of patients presenting at specialty clinics,
            screened against inclusion/exclusion criteria for predefined disease cohorts.
        is_sample:
          - yes
        is_random:
          - no
        source_data:
          - >-
            Patients evaluated at five North American clinical sites within
            specialty clinics.
        is_representative:
          - >-
            Not designed to be population-representative; targeted cohorts selected
            for known voice-related manifestations.
        why_not_representative:
          - Targeted disease cohorts recruited in clinical settings.
relationships:
  - name: Instance linkages
    description:
      - >-
        Each spectrogram/feature row links to participant_id, session_id, and task_name,
        enabling mapping between recordings, sessions, and participants.
splits:
  - name: Data splits
    description:
      - No predefined train/validation/test splits provided in v1.0.
subpopulations:
  - name: Disease cohorts
    identification:
      - >-
        Participants selected for membership in five predefined disease categories:
        voice disorders, neurological/neurodegenerative disorders, mood/psychiatric
        disorders, respiratory disorders, and pediatric (pediatric not included in v1.0).
    distribution:
      - Adult cohort only in v1.0; 306 participants across five North American sites.
is_deidentified:
  name: De-identification
  description:
    - >-
      HIPAA Safe Harbor identifiers removed (e.g., names, detailed dates, contact
      and account identifiers, device/biometric identifiers, full-face images).
    - State and province removed; country of data collection retained.
    - Free-speech transcripts removed.
    - Raw audio waveforms omitted from this release; only derived data provided.
sensitive_elements:
  - name: Health-related data
    description:
      - >-
        Contains clinical, demographic, and questionnaire-derived information
        linked to voice-derived features; access is restricted and de-identified.
acquisition_methods:
  - name: Data acquisition protocol
    description:
      - >-
        Standardized protocol: demographics, validated health questionnaires,
        targeted confounders, disease-specific information, and structured voice tasks
        (e.g., sustained vowel phonation).
      - >-
        Recordings obtained using a custom tablet application; headset used when possible.
      - >-
        Single session for most participants; subset required multiple sessions.
      - >-
        Data exported from REDCap and converted using an open-source library (b2aiprep).
    was_directly_observed: yes
    was_reported_by_subjects: yes
    was_inferred_derived: yes
collection_mechanisms:
  - name: Collection mechanisms
    description:
      - Custom tablet application for data capture
      - Headset microphone when possible
      - Export/conversion from REDCap via b2aiprep library
data_collectors:
  - name: Data collectors
    description:
      - Project investigators at five North American clinical sites
collection_timeframes:
  - name: Collection setting
    description:
      - >-
        Multi-site clinical data collection at five North American sites; timeframe
        not specified in this release.
ethical_reviews:
  - name: IRB/REB oversight
    description:
      - >-
        Data collection and sharing approved by the University of South Florida
        Institutional Review Board.
      - >-
        Submitted for review to the University of Toronto Research Ethics Board.
preprocessing_strategies:
  - name: Audio preprocessing and feature derivation
    description:
      - >-
        Raw audio converted to mono and resampled to 16 kHz with a Butterworth
        anti-aliasing filter.
      - >-
        Spectrograms computed with STFT: 25 ms window, 10 ms hop, 512-point FFT;
        stored as power spectrograms.
      - >-
        Acoustic features extracted using openSMILE; phonetic/prosodic measures
        via Parselmouth and Praat; additional features with torchaudio.
      - >-
        Transcriptions generated with OpenAI Whisper Large; free-speech transcripts
        not included in this release.
    used_software:
      - name: openSMILE
      - name: Praat
      - name: Parselmouth
      - name: torchaudio
        version: "2.1"
      - name: OpenAI Whisper Large
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
cleaning_strategies:
  - name: Risk mitigation and cleaning
    description:
      - >-
        Removal of HIPAA Safe Harbor identifiers and geographic detail (state/province);
        retention of country only.
      - Removal of free-speech transcripts.
      - Exclusion of raw audio from v1.0 release.
labeling_strategies:
  - name: Transcription
    description:
      - >-
        Automatic transcription generated with OpenAI Whisper Large during processing;
        transcripts of free-speech content are not distributed.
raw_sources:
  - name: Raw audio handling
    description:
      - >-
        Raw audio waveforms were collected but are not included in v1.0; derived
      - >-
        spectrograms and features are provided instead. Future releases may include
        voice data with additional security precautions.
use_repository:
  - name: Documentation website
    description:
      - https://docs.b2ai-voice.org
other_tasks:
  - name: Additional potential uses
    description:
      - >-
        Methodological research on representation learning, domain adaptation,
        robustness, and fairness in voice-based health AI.
      - >-
        Exploratory analyses of acoustic correlates of disease severity or symptom burden,
        subject to DUA restrictions.
future_use_impacts:
  - name: Considerations for future use
    description:
      - >-
        Initial release excludes raw audio and free-speech transcripts to reduce
        privacy risks; consumers should account for differences between derived
        and raw modalities when interpreting model performance and generalizability.
distribution_formats:
  - name: Access modality
    description:
      - Database, credentialed access via Health Data Nexus
      - Files provided as Parquet (spectrograms) and TSV/JSON (tabular data and dictionaries)
distribution_dates:
  - name: Initial public release
    description:
      - 2024-11-27
license_and_use_terms:
  name: Access and use requirements
  description:
    - License: Bridge2AI Voice Registered Access License
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement
    - Required training: TCPS 2: CORE 2022
    - Access policy: Only credentialed users who sign the DUA can access the files.
maintainers:
  - name: Hosting and support
    description:
      - Health Data Nexus (Temerty Centre for AI Research and Education in Medicine)
updates:
  name: Update plan
  description:
    - >-
      v1.0 is the first release; future releases aim to include voice data (raw
      audio) with additional security precautions and may expand cohort coverage
      (e.g., pediatric).
version_access:
  name: Versioning and DOIs
  description:
    - Version-specific DOI (v1.0): https://doi.org/10.57764/qb6h-em84
    - Latest version DOI: https://doi.org/10.57764/3sg0-7440
is_tabular: mixed
=== YAML Fixing Applied ===
id: bridge2ai-voice-v1-0
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information v1.0"
description: >
  Bridge2AI-Voice is a comprehensive, ethically sourced collection of data derived from voice
  recordings linked to clinical information to enable research on voice as a biomarker of health.
  The initial v1.0 release provides 12,523 recordings for 306 adult participants collected across
  five sites in North America. Participants were selected based on conditions known to manifest in
  voice (voice disorders, neurological disorders, mood disorders, respiratory disorders). This
  low-risk release contains derived data (e.g., spectrograms and engineered features) and detailed
  demographic, clinical, and questionnaire information; original audio waveforms and free-speech
  transcripts are not included.
doi: "doi:10.57764/qb6h-em84"
page: "https://docs.b2ai-voice.org"
issued: 2024-11-27
version: "1.0"
keywords:
  - voice
  - bridge2ai
  - audio
purposes:
  - name: purpose
    response: Enable AI research on voice as a biomarker of health through an ethically sourced, diverse, multi-institutional dataset linked to clinical information.
tasks:
  - name: primary_task
    response: Development and evaluation of AI methods for health-related inference from voice-derived data (e.g., condition screening, phenotyping, biomarker discovery).
addressing_gaps:
  - name: gap_statement
    response: Address the lack of large, high-quality, diverse, and standardized multi-institutional voice datasets linked to health information for AI research.
creators:
  - name: Alistair Johnson
  - name: Jean-Christophe Bélisle-Pipon
  - name: David Dorr
  - name: Satrajit Ghosh
  - name: Philip Payne
  - name: Maria Powell
  - name: Anaïs Rameau
  - name: Vardit Ravitsky
  - name: Alexandros Sigaras
  - name: Olivier Elemento
  - name: Yael Bensoussan
funders:
  - name: NIH funding
    grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
instances:
  - name: recording_derived_data
    representation: Voice recording–derived data (e.g., spectrograms and engineered acoustic/phonetic/prosodic features)
    instance_type: Audio-derived arrays and feature vectors per recording
    data_type: >
      Derived data from raw audio: spectrograms (513 x N STFT magnitude arrays), OpenSMILE acoustic features,
      phonetic/prosodic features (Parselmouth/Praat), additional features (torchaudio).
    counts: 12523
    sampling_strategies:
      - name: instance_sampling
        strategies:
          - Deterministic protocol-based collection across five sites; per-participant multiple sessions possible
    missing_information:
      - name: instance_missing
        missing:
          - Original audio waveform (not included in v1.0)
          - Free-speech transcripts (removed)
        why_missing:
          - Privacy and de-identification; low-risk release policy
  - name: participants
    representation: Participants (adult cohort v1.0)
    instance_type: Individual participants with linked demographics, clinical data, and validated questionnaire responses
    data_type: Tabular phenotype data (one row per participant) with data dictionary
    counts: 306
sampling_strategies:
  - name: cohort_sampling
    is_sample:
      - yes
    source_data:
      - Patients at specialty clinics across five sites in North America, selected into predefined disease cohorts (voice, neurological, mood, respiratory; pediatric cohort planned)
    is_representative:
      - No (not representative of the general population; targeted disease cohorts)
    why_not_representative:
      - Targeted recruitment based on known conditions affecting voice; specialty-clinic sampling
collection_mechanisms:
  - name: collection_protocols
    description:
      - Standardized multi-site protocol; custom tablet application used for data entry and voice tasks; headset used when possible
      - Demographics, health questionnaires, acoustic confounders, disease-specific information, and voice tasks (e.g., sustained vowel)
      - Data exported from REDCap; conversions performed using an open-source library developed by the team
data_collectors:
  - name: data_collection_team
    description:
      - Project investigators at participating specialty clinics screened participants for eligibility, obtained consent, and conducted standardized collection sessions
acquisition_methods:
  - name: acquisition_modalities
    description:
      - Directly observed raw audio recordings; subject-reported questionnaire data; derived/inferred features from audio
    was_directly_observed: yes (voice recordings)
    was_reported_by_subjects: yes (validated questionnaires and clinical data entry)
    was_inferred_derived: yes (spectrograms, acoustic, phonetic, and prosodic features; ASR transcripts generated but not released)
    was_validated_verified: Standardized protocol; multi-site governance and IRB approval
ethical_reviews:
  - name: irb_reb_review
    description:
      - Data collection and sharing approved by the University of South Florida Institutional Review Board
      - Submission to the University of Toronto Research Ethics Board for review
preprocessing_strategies:
  - name: audio_preprocessing_and_feature_extraction
    description:
      - Raw audio converted to monaural, resampled to 16 kHz with Butterworth anti-aliasing filter
      - Spectrograms computed via STFT (25 ms window, 10 ms hop, 512-point FFT)
      - Acoustic features extracted with OpenSMILE
      - Phonetic/prosodic features computed using Parselmouth and Praat
      - Additional audio features using torchaudio
      - Transcriptions generated using OpenAI Whisper Large (not released for free-speech content)
    used_software:
      - name: b2aiprep
        version: "0.21.0"
        url: "https://github.com/sensein/b2aiprep"
      - name: OpenSMILE
      - name: Parselmouth
      - name: Praat
      - name: torchaudio
      - name: OpenAI Whisper Large
cleaning_strategies:
  - name: deidentification_and_release_controls
    description:
      - HIPAA Safe Harbor identifiers removed (e.g., names, fine-grained dates, contact info, IDs, device/account numbers, URLs, biometric identifiers, full-face photos, etc.)
      - State and province removed; country of data collection retained
      - Free-speech transcripts removed
      - Original audio waveforms omitted in v1.0; only derived low-risk data released
labeling_strategies:
  - name: transcription_and_metadata_labels
    description:
      - ASR transcriptions generated using Whisper Large, but free-speech transcripts were removed from the release
      - Phenotype and feature data dictionaries provided (phenotype.json, static_features.json) describing columns and features
raw_sources:
  - name: raw_audio_waveforms
    description:
      - Raw audio waveforms collected but not distributed in v1.0; planned for future releases with additional security precautions
external_resources:
  - name: documentation
    external_resources:
      - https://docs.b2ai-voice.org
    archival:
      - DOI registered; versioned releases indicated
    restrictions:
      - Credentialed access with DUA and required training
  - name: instruments_and_tools
    external_resources:
      - https://doi.org/10.5281/zenodo.14148755
    restrictions:
      - Reference materials and tools; dataset access still governed by Registered Access terms
subpopulations:
  - name: adult_cohort
    identification:
      - Adult participants only in v1.0
      - Disease cohorts: voice disorders, neurological disorders, mood disorders, respiratory disorders (pediatric cohort not included in v1.0)
    distribution:
      - Multi-site collection across five North American sites; per-participant one or more sessions
sensitive_elements:
  - name: health_related_data
    description:
      - Clinical information, demographics, and validated questionnaire responses that may be considered sensitive; de-identified per HIPAA Safe Harbor
is_deidentified:
  name: deidentification_status
  description:
    - HIPAA Safe Harbor de-identification applied; state/province removed; country retained
    - Free-speech transcripts removed; original audio waveforms not included in v1.0
future_use_impacts:
  - name: composition_and_privacy_considerations
    description:
      - Low-risk release (derived data only) reduces privacy risks; exclusion of raw audio limits some research use cases
      - Targeted disease cohort sampling may limit generalizability to the broader population
distribution_formats:
  - name: file_formats
    description:
      - Parquet (.parquet) for spectrogram arrays
      - TSV (.tsv) for phenotype and static feature tables
      - JSON (.json) for data dictionaries
distribution_dates:
  - name: v1_0_release_date
    description:
      - 2024-11-27
license_and_use_terms:
  name: registered_access_terms
  description:
    - License: Bridge2AI Voice Registered Access License
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement
    - Access policy: Only credentialed users who sign the DUA can access the files
    - Required training: TCPS 2: CORE 2022
maintainers:
  - name: Health Data Nexus
    description:
      - Hosting and access management provided by Health Data Nexus (Temerty Centre for AI Research and Education in Medicine; supported by the Temerty Foundation)
updates:
  name: release_plan
  description:
    - v1.0 is the first release (derived data only). Future releases aim to include voice audio data with additional security precautions.
distribution:
  - name: portal_access
    description:
      - Database with credentialed access via Health Data Nexus; files available after meeting access requirements (credentialing, training, DUA)
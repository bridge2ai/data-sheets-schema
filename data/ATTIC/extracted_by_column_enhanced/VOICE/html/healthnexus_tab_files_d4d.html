
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="datasheet-common.css">
    <title>healthnexus tab files d4d - Datasheet for Dataset</title>
</head>
<body>
    <div class="header">
        <h1>healthnexus tab files d4d</h1>
        <p class="subtitle">Datasheet for Dataset - Human Readable Format</p>
    </div>
    
    
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üéØ</span>
                    <div>
                        <h2 class="section-title">Motivation</h2>
                        <p class="section-description">Why was the dataset created?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Funders
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Grantor</th><th>Grant Name</th><th>Grant Number</th></tr></thead><tbody><tr><td>National Institutes of Health</td><td>Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before</td><td>3OT2OD032720-01S1</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Purposes
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Response</dt><dd><div class="long-description">Create an ethically sourced, diverse, multi-institutional dataset of voice linked to clinical and questionnaire data to enable AI research on voice as a biomarker of health and support clinically meaningful insights.</div></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üìä</span>
                    <div>
                        <h2 class="section-title">Composition</h2>
                        <p class="section-description">What do the instances represent?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Instances
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Counts</th><th>Data Type</th><th>Instance Type</th><th>Missing Information</th><th>Representation</th><th>Sampling Strategies</th></tr></thead><tbody><tr><td>12523</td><td>Derived features (spectrograms, acoustic, phonetic/prosodic); no raw audio waveforms in v1.0</td><td>Audio-derived instance</td><td>{'missing': ['Original audio waveforms'], 'why_missing': ['Omitted in initial low-risk release; planned for future releases with additional safeguards']}, {'missing': ['Transcripts of free speech audio'], 'why_missing': ['Removed during de-identification']}</td><td>Voice-derived recordings (spectrograms/features) per recording</td><td>{'is_sample': ['yes'], 'is_random': ['no'], 'source_data': ['Patients presenting at specialty clinics across five North American sites'], 'is_representative': ['no'], 'why_not_representative': ['Participants were selected based on membership in predefined disease cohorts'], 'strategies': ['Targeted enrollment by predefined disease categories']}</td></tr><tr><td>306</td><td>Demographics, clinical, and validated questionnaire responses</td><td>Participant</td><td></td><td>Participant-level phenotype records</td><td>{'is_sample': ['yes'], 'is_random': ['no'], 'source_data': ['Specialty clinics at five North American sites'], 'is_representative': ['no'], 'why_not_representative': ['Cohort-based selection for voice-relevant conditions']}</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subpopulations
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Identification</dt><dd><ul class='formatted-list'><li>Adult cohort (v1.0); disease categories include voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders</li></ul></dd><dt>Distribution</dt><dd><ul class='formatted-list'><li>Participants selected based on membership in predefined disease cohorts</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Formats
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Parquet</li><li>TSV</li><li>JSON</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Distribution Dates
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>2024-11-27</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîç</span>
                    <div>
                        <h2 class="section-title">Collection Process</h2>
                        <p class="section-description">How was the data acquired?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label required-field">
                            ID
                            <span class="required-indicator" title="Required field">*</span>
                        </label>
                        <div class="item-value">bridge2ai-voice-v1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Name
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Title
                            
                        </label>
                        <div class="item-value">Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information v1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Description
                            
                        </label>
                        <div class="item-value"><div class="long-description">Bridge2AI-Voice is a multi-site, ethically sourced dataset of human voice linked to clinical and questionnaire information to enable research on voice as a biomarker of health. Version 1.0 includes 12,523 recordings from 306 participants across five North American sites, focusing on cohorts with known voice-relevant conditions (voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, and respiratory disorders). The initial release contains only low-risk, derived data (e.g., spectrograms and acoustic features) and de-identified phenotype tables; original audio waveforms and free-speech transcripts are not included. Data were collected via a standardized protocol using a custom tablet application, with preprocessing that included resampling to 16 kHz with a Butterworth anti-aliasing filter, STFT-based spectrogram generation, extraction of acoustic and phonetic/prosodic features (OpenSMILE, Parselmouth/Praat), and automatic transcription using OpenAI Whisper Large. Documentation: "https://docs.b2ai-voice.org."</div></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Page
                            
                        </label>
                        <div class="item-value"><a href="https://docs.b2ai-voice.org" target="_blank">https://docs.b2ai-voice.org</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Issued
                            
                        </label>
                        <div class="item-value">2024-11-27</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Keywords
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li>voice</li><li>bridge2ai</li><li>audio</li><li>VOICE</li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Creators
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Name</th></tr></thead><tbody><tr><td>Alistair Johnson</td></tr><tr><td>Jean-Christophe B√©lisle-Pipon</td></tr><tr><td>David Dorr</td></tr><tr><td>Satrajit Ghosh</td></tr><tr><td>Philip Payne</td></tr><tr><td>Maria Powell</td></tr><tr><td>Ana√Øs Rameau</td></tr><tr><td>Vardit Ravitsky</td></tr><tr><td>Alexandros Sigaras</td></tr><tr><td>Olivier Elemento</td></tr><tr><td>Yael Bensoussan</td></tr></tbody></table></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Addressing Gaps
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Response</dt><dd>Addresses the lack of large, high-quality, standardized, and demographically diverse voice datasets linked to clinical and questionnaire data across multiple institutions.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Relationships
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Recordings are linked to participants and sessions via participant_id and session_id; tasks identified by task_name</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Deidentified
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor identifiers removed (e.g., names, contact details, precise dates, etc.)</li><li>State and province removed; country retained</li><li>Free speech transcripts removed; original audio waveforms omitted in v1.0</li></ul></dd></dl></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Sensitive Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Contains de-identified health-related information (demographics, clinical variables, questionnaire responses)</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Confidential Elements
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>De-identified clinical and questionnaire data; identifiable communications removed</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Acquisition Methods
                            
                        </label>
                        <div class="item-value"><ol class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Standardized protocol with voice tasks (e.g., sustained vowel), demographics, health and targeted questionnaires</li><li>Custom tablet application; headset used when possible</li><li>Data exported from REDCap via open-source tooling</li></ul></dd><dt>Was Directly Observed</dt><dd>yes</dd><dt>Was Reported By Subjects</dt><dd>yes</dd><dt>Was Inferred Derived</dt><dd>yes</dd></dl></li></ol></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Collection Mechanisms
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Custom tablet app and headset for data capture; REDCap used for data entry/export</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Data Collectors
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Project investigators at five North American sites; patients presenting at specialty clinics were screened and consented</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Ethical Reviews
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Data collection and sharing approved by the University of South Florida IRB; submitted for review to the University of Toronto Research Ethics Board</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Preprocessing Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter</li><li>Spectrograms computed via short-time FFT (25 ms window, 10 ms hop, 512-point FFT)</li><li>Acoustic features extracted with OpenSMILE</li><li>Phonetic and prosodic features computed with Parselmouth and Praat</li><li>Transcriptions generated with OpenAI Whisper Large model</li></ul></dd><dt>Used Software</dt><dd><table class="data-table"><thead><tr><th>Name</th><th>URL</th></tr></thead><tbody><tr><td>OpenSMILE</td><td></td></tr><tr><td>Parselmouth</td><td></td></tr><tr><td>Praat</td><td></td></tr><tr><td>torchaudio</td><td></td></tr><tr><td>OpenAI Whisper Large</td><td></td></tr><tr><td>b2aiprep</td><td>https://github.com/sensein/b2aiprep</td></tr></tbody></table></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Cleaning Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>HIPAA Safe Harbor de-identification (removal of identifiers and fine-grained dates)</li><li>Removal of free speech transcripts</li><li>Omission of original audio waveforms from initial release</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Labeling Strategies
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Automatic Transcription Using Openai Whisper Large (note</dt><dd>free speech transcripts are not included in v1.0)</dd></dl></li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Raw Sources
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Original audio waveforms collected; not distributed in v1.0. Future releases aim to include voice data with additional precautions.</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Maintainers
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Health Data Nexus</li><li>Temerty Centre for AI Research and Education in Medicine</li></ul></dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Is Tabular
                            
                        </label>
                        <div class="item-value">mixed (Parquet dense arrays and tabular TSV/JSON)</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Subsets
                            
                        </label>
                        <div class="item-value"><table class="data-table"><thead><tr><th>Description</th><th>Format</th><th>ID</th><th>Media Type</th><th>Name</th><th>Path</th><th>Title</th></tr></thead><tbody><tr><td>Parquet dataset containing time-frequency spectrograms derived from voice recordings; includes parti...</td><td></td><td>spectrograms-parquet</td><td>application/x-parquet</td><td>spectrograms.parquet</td><td>spectrograms.parquet</td><td>Spectrograms (derived from voice waveforms)</td></tr><tr><td>Tab-delimited file with one row per participant containing demographics, acoustic confounders, and v...</td><td></td><td>phenotype-tsv</td><td>text/tab-separated-values</td><td>phenotype.tsv</td><td>phenotype.tsv</td><td>Phenotype table</td></tr><tr><td>JSON data dictionary describing columns in phenotype.tsv; includes a one-sentence description for ea...</td><td>JSON</td><td>phenotype-json</td><td>application/json</td><td>phenotype.json</td><td>phenotype.json</td><td>Phenotype data dictionary</td></tr><tr><td>Tab-delimited file with one row per recording containing features derived from OpenSMILE, Praat/Pars...</td><td></td><td>static-features-tsv</td><td>text/tab-separated-values</td><td>static_features.tsv</td><td>static_features.tsv</td><td>Static audio-derived features</td></tr><tr><td>JSON data dictionary describing features in static_features.tsv; includes a description for each fea...</td><td>JSON</td><td>static-features-json</td><td>application/json</td><td>static_features.json</td><td>static_features.json</td><td>Static features data dictionary</td></tr></tbody></table></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üöÄ</span>
                    <div>
                        <h2 class="section-title">Uses</h2>
                        <p class="section-description">What (other) tasks could the dataset be used for?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Tasks
                            
                        </label>
                        <div class="item-value"><ul class='formatted-list'><li><dl class='nested-dict'><dt>Response</dt><dd>Research and development of AI/ML methods for analyzing voice-derived features and their associations with health conditions; exploratory and hypothesis-driven studies on voice as a biomarker.</dd></dl></li></ul></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            License And Use Terms
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Bridge2AI Voice Registered Access License</li><li>Bridge2AI Voice Registered Access Agreement (DUA)</li><li><dl class='nested-dict'><dt>Access Policy</dt><dd>Only credentialed users who sign the DUA can access the files</dd></dl></li><li><dl class='nested-dict'><dt>Required Training</dt><dd>TCPS 2: CORE 2022</dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üì§</span>
                    <div>
                        <h2 class="section-title">Distribution</h2>
                        <p class="section-description">How will the dataset be distributed?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            DOI
                            
                        </label>
                        <div class="item-value"><a href="https://doi.org/10.57764/qb6h-em84" target="_blank">doi:10.57764/qb6h-em84</a></div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version Access
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li><dl class='nested-dict'><dt>Latest Version DOI</dt><dd><a href="https://doi.org/10.57764/3sg0-7440" target="_blank">https://doi.org/10.57764/3sg0-7440</a></dd></dl></li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
            
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">üîÑ</span>
                    <div>
                        <h2 class="section-title">Maintenance</h2>
                        <p class="section-description">How will the dataset be maintained?</p>
                    </div>
                </div>
                <div class="section-content">
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Version
                            
                        </label>
                        <div class="item-value">1.0</div>
                    </div>
                    
                    <div class="data-item">
                        
                        <label class="item-label optional-field">
                            Updates
                            
                        </label>
                        <div class="item-value"><dl class='nested-dict'><dt>Description</dt><dd><ul class='formatted-list'><li>Future releases aim to include voice data with additional precautions to ensure data security</li></ul></dd></dl></div>
                    </div>
                    
                </div>
            </div>
            
        
    
    
    <div class="timestamp">
        Generated on 2025-11-09 10:17:34 using Bridge2AI Data Sheets Schema
    </div>
</body>
</html>
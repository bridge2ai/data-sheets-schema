# === YAML Fixing Applied ===
id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: >
  Bridge2AI-Voice is a comprehensive, ethically sourced dataset linking voice-derived
  data to health information to enable artificial intelligence research on voice as
  a biomarker of health. Version 1.0 provides 12,523 recordings for 306 adult participants
  across five sites in North America. The initial release distributes low-risk derived
  data (e.g., spectrograms and engineered features) along with detailed demographic,
  clinical, and validated questionnaire data. Original audio waveforms and free-speech
  transcripts are not included in v1.0. Participants were selected based on conditions
  known to manifest within the voice waveform, including voice, neurological, mood/psychiatric,
  and respiratory disorders. Data collection followed a standardized multi-site protocol
  using a custom application, and extensive de-identification was performed following
  HIPAA Safe Harbor.
language: en
page: "https://doi.org/10.57764/qb6h-em84"
doi: "doi:10.57764/qb6h-em84"
issued: 2024-11-27
version: "1.0"
keywords:
  - voice
  - bridge2ai
  - audio
  - biomarker
  - spectrogram
  - health
  - clinical
  - de-identification
  - parquet
  - phenotype
  - features
  - North America
creators:
  - name: Alistair Johnson
  - name: Jean-Christophe Bélisle-Pipon
  - name: David Dorr
  - name: Satrajit Ghosh
  - name: Philip Payne
  - name: Maria Powell
  - name: Anaïs Rameau
  - name: Vardit Ravitsky
  - name: Alexandros Sigaras
  - name: Olivier Elemento
  - name: Yael Bensoussan
funders:
  - grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
purposes:
  - response: >
      Create an ethically sourced flagship dataset to enable AI research and provide
      critical insights into using voice as a biomarker of health.
tasks:
  - response: >
      Support development and evaluation of AI methods for analyzing voice-derived
      data linked to health information (e.g., detection, screening, and monitoring
      of conditions impacting voice and speech).
addressing_gaps:
  - response: >
      Address the lack of large, high-quality, diverse, multi-institutional voice datasets
      linked to other health biomarkers, with standardized protocols and ethical oversight.
instances:
  - name: Recording-derived instances
    representation: Voice-derived spectrograms and engineered acoustic/phonetic/prosodic features per recording session
    instance_type: Recording session (per-task)
    data_type: >
      Derived data from standardized audio (spectrograms 513×N via STFT; static features
      from openSMILE, Praat/Parselmouth, torchaudio)
    counts: 12523
  - name: Participant-level instances
    representation: Participants enrolled with demographics, clinical data, and validated questionnaire responses
    instance_type: Participant
    data_type: >
      Tabular phenotype data (one row per participant) including demographics, acoustic confounders,
      and responses to validated questionnaires
    counts: 306
sampling_strategies:
  - is_sample:
      - yes
    is_random:
      - no
    source_data:
      - Patients at specialty clinics across five North American sites
    is_representative:
      - no
    why_not_representative:
      - Participants were selected into predefined disease cohorts (voice, neurological, mood/psychiatric, respiratory; adult cohort only in v1.0)
    strategies:
      - Deterministic selection into five predetermined groups based on inclusion/exclusion criteria and clinic presentation
data_collectors:
  - description:
      - Project investigators at specialty clinics; data collection typically in a single session per participant, with multiple sessions for a subset
collection_mechanisms:
  - description:
      - Standardized multi-site protocol using a custom tablet application and a headset when possible; data exported from REDCap using an open-source library
collection_timeframes:
  - description:
      - Multi-site prospective collection across five North American sites (v1.0 includes adult cohort; specific dates not provided)
ethical_reviews:
  - description:
      - Data collection and sharing approved by the University of South Florida Institutional Review Board; submitted for review to the University of Toronto Research Ethics Board
acquisition_methods:
  - description:
      - Directly observed audio tasks (e.g., sustained phonation) with standardized protocol; participant-reported questionnaires; derived features computed from audio
    was_directly_observed: yes
    was_reported_by_subjects: yes
    was_inferred_derived: yes
    was_validated_verified: >
      Standardized protocol across sites; derived features computed using established tools (openSMILE, Praat/Parselmouth, torchaudio)
preprocessing_strategies:
  - description:
      - Raw audio converted to mono, resampled to 16 kHz with a Butterworth anti-aliasing filter; STFT spectrograms with 25 ms window, 10 ms hop, 512-point FFT; feature extraction using standard toolchains
    used_software:
      - name: openSMILE
      - name: Praat
      - name: Parselmouth
      - name: torchaudio
      - name: librosa
cleaning_strategies:
  - description:
      - HIPAA Safe Harbor de-identification; removal of state/province; retention of country only; removal of free-speech transcripts; omission of original audio waveforms in v1.0
labeling_strategies:
  - description:
      - Automatic transcriptions generated using OpenAI Whisper Large model (free-speech transcripts not distributed in v1.0)
    used_software:
      - name: OpenAI Whisper Large
raw_sources:
  - description:
      - Original audio waveforms collected (not distributed in v1.0); source data managed via REDCap and exported/converted using an open-source library (b2aiprep)
external_resources:
  - external_resources:
      - Project documentation site: "https://docs.b2ai-voice.org"
      - REDCap tooling record: "https://doi.org/10.5281/zenodo.14148755"
    archival:
      - DOI-registered dataset record via Health Data Nexus
subpopulations:
  - identification:
      - Adult cohort only in v1.0
      - Disease cohorts: voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders
    distribution:
      - 306 participants across five North American sites (v1.0)
sensitive_elements:
  - description:
      - Health-related clinical and demographic data; biometric voice-derived features (original audio not released in v1.0)
is_deidentified:
  description:
    - HIPAA Safe Harbor identifiers removed (e.g., names, direct contact info, precise dates, device IDs, account numbers, full-face images, biometric identifiers, etc.)
    - State/province removed; country retained
    - Free-speech transcripts removed
    - Original audio waveforms omitted in v1.0; only derived data released
distribution_formats:
  - description:
      - Parquet (.parquet) for spectrograms
      - TSV (.tsv) for phenotype and static features tables
      - JSON (.json) data dictionaries for phenotype and features
distribution_dates:
  - description:
      - 2024-11-27 (v1.0 initial release)
license_and_use_terms:
  description:
    - License: Bridge2AI Voice Registered Access License
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement (DUA must be signed)
    - Access policy: Only credentialed users who sign the DUA can access the files
    - Required training: "TCPS 2: CORE 2022"
maintainers:
  - description:
      - Health Data Nexus (hosting and access management)
      - Bridge2AI-Voice project team
existing_uses:
  - description:
      - First public release (v1.0); no prior uses listed
updates:
  description:
    - Future releases aim to include original voice recordings with additional security precautions
    - Pediatric cohort data intended for future inclusion
version_access:
  description:
    - Latest version DOI: "https://doi.org/10.57764/3sg0-7440"
    - This record corresponds to version 1.0: "https://doi.org/10.57764/qb6h-em84"

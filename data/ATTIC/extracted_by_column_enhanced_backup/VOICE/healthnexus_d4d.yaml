# === YAML Fixing Applied ===
id: "doi:10.57764/qb6h-em84"
name: Bridge2AI-Voice v1.0
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: "The Bridge2AI-Voice project provides an ethically sourced, diverse dataset enabling research on voice as a biomarker of health. Version 1.0 includes 12,523 derived recordings for 306 adult participants collected across five sites in North America. Participants were selected from cohorts with conditions known to manifest in the voice waveform, including voice, neurological, mood/psychiatric, and respiratory disorders. This initial release contains low-risk derived data (e.g., spectrograms and engineered features) and detailed demographic, clinical, and validated questionnaire data; original audio waveforms and free-speech transcripts are not included. Documentation: https://docs.b2ai-voice.org"
doi: "doi:10.57764/qb6h-em84"
version: "1.0"
issued: "2024-11-27"
page: "https://docs.b2ai-voice.org"
keywords:
  - voice
  - bridge2ai
  - audio
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
purposes:
  - name: Purpose
    response: Create an ethically sourced, diverse, multi-institutional voice dataset linked to clinical information to enable AI research on voice as a biomarker of health.
tasks:
  - name: Task
    response: AI/ML research using derived voice representations (e.g., spectrograms, acoustic/phonetic/prosodic features) to study health-related conditions manifesting in voice.
addressing_gaps:
  - name: Addressing Gap
    response: Addresses the lack of large, high-quality, diverse, standardized, multi-institutional voice datasets linked to health data to support rigorous AI research and clinically relevant questions.
creators:
  - name: Bridge2AI-Voice Consortium
funders:
  - name: Funding
    grantor:
      name: National Institutes of Health (NIH)
    grant:
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
instances:
  - name: Instance
    representation: Voice-derived data linked to clinical, demographic, and questionnaire information.
    instance_type: Participants, sessions, and recordings (multiple sessions for some participants).
    data_type: Derived audio representations (spectrograms), acoustic/phonetic/prosodic features, and phenotypic/clinical data; data dictionaries for tabular files.
    counts: 12523
sampling_strategies:
  - name: Sampling Strategy
    strategies:
      - Purposeful selection of participants from five predefined disease cohorts (respiratory disorders, voice disorders, neurological disorders, mood/psychiatric disorders, pediatric cohort planned; v1.0 includes adults only).
    source_data:
      - Patients presenting at specialty clinics across five sites in North America screened against inclusion/exclusion criteria.
    is_sample:
      - Yes, selected based on membership in predefined disease cohorts.
    is_random:
      - No
    is_representative:
      - Not intended to be representative of the general population; focused on clinical cohorts.
subpopulations:
  - name: Adult cohort (v1.0)
    identification:
      - Adult participants only in v1.0 across five North American sites.
      - Disease cohorts targeted: voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders.
    distribution:
      - 306 participants; 12,523 recordings; multiple sessions for a subset of participants.
acquisition_methods:
  - name: Data acquisition
    description:
      - Directly observed voice tasks (e.g., sustained vowel phonation) collected in clinical/specialty clinic settings under a standardized protocol.
      - Demographic, health questionnaires, confounder questions, and disease-specific information collected via custom tablet application.
    was_directly_observed: Yes
    was_reported_by_subjects: Yes (questionnaires and self-reported information)
    was_inferred_derived: Yes (derived audio features and spectrograms)
    was_validated_verified: Standardized protocol used; derived features computed with established software libraries.
collection_mechanisms:
  - name: Collection mechanisms
    description:
      - Custom tablet application; headset used for data collection when possible.
      - Standardized voice tasks; REDCap used for data management and export via an open-source library.
data_collectors:
  - name: Data collectors
    description:
      - Project investigators at participating specialty clinics and institutions; participants could require multiple sessions to complete protocols.
collection_timeframes: []
ethical_reviews:
  - name: Ethical review
    description:
      - Data collection and sharing approved by the University of South Florida Institutional Review Board; submitted for review to the University of Toronto Research Ethics Board.
data_protection_impacts: []
preprocessing_strategies:
  - name: Audio preprocessing and feature extraction
    description:
      - Raw audio converted to mono and resampled to 16 kHz with a Butterworth anti-aliasing filter.
      - Spectrograms computed via STFT (25 ms window, 10 ms hop, 512-point FFT).
      - Acoustic features extracted with OpenSMILE; phonetic/prosodic features from Parselmouth/Praat.
      - Additional processing using torchaudio; transcription generated with OpenAI Whisper Large.
    used_software:
      - name: OpenSMILE
      - name: Parselmouth
      - name: Praat
      - name: Torchaudio
      - name: OpenAI Whisper Large
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
cleaning_strategies:
  - name: De-identification and content removal
    description:
      - HIPAA Safe Harbor identifiers removed (names; fine-grained dates; contact details; IDs; device/account/license numbers; vehicle identifiers; URLs; full-face photos; biometric identifiers; unique identifiers).
      - State and province removed; country of data collection retained.
      - Transcripts of free speech audio removed.
      - Original audio waveforms omitted from this release; only derived features and spectrograms are included.
labeling_strategies:
  - name: Transcription
    description:
      - Transcriptions generated using OpenAI Whisper Large; free speech transcripts were removed from the released dataset.
    used_software:
      - name: OpenAI Whisper Large
raw_sources:
  - name: Raw data availability
    description:
      - Original audio waveforms are not included in v1.0; future releases aim to include voice data with additional security precautions.
external_resources:
  - name: External resources
    external_resources:
      - Open-source preprocessing library (b2aiprep) used to prepare parquet and merge phenotype data.
    archival:
      - Versioned DOI available for dataset discovery and citation.
    restrictions:
      - Access controlled via registered access license, DUA, and required training.
confidential_elements: []
content_warnings: []
sensitive_elements:
  - name: Sensitive data elements
    description:
      - Clinical and demographic information; responses to validated health questionnaires.
is_deidentified:
  name: De-identification
  description:
    - HIPAA Safe Harbor applied; removal of specified identifiers and geographic detail (state/province); retention of country only.
    - Free-speech transcripts removed; original audio waveforms omitted in v1.0.
distribution_formats:
  - name: Distribution formats
    description:
      - spectrograms.parquet (Parquet; 513 x N spectrogram matrices per recording; includes participant_id, session_id, task_name).
      - phenotype.tsv (tab-delimited; one row per participant; demographics, confounders, validated questionnaires).
      - phenotype.json (data dictionary for phenotype.tsv).
      - static_features.tsv (tab-delimited; one row per recording; acoustic/phonetic/prosodic features).
      - static_features.json (data dictionary for static_features.tsv).
distribution_dates:
  - name: Initial release
    description:
      - 2024-11-27
license_and_use_terms:
  name: License and access terms
  description:
    - Access Policy: Only credentialed users who sign the Data Use Agreement (DUA) can access files.
    - License: Bridge2AI Voice Registered Access License.
    - Data Use Agreement: Bridge2AI Voice Registered Access Agreement.
    - Required training: "TCPS 2: CORE 2022."
    - Files are distributed under registered/credentialed access via Health Data Nexus.
ip_restrictions:
  name: IP restrictions
  description:
    - Not specified beyond registered access license and DUA requirements.
regulatory_restrictions: []
maintainers:
  - name: Maintainer
    description:
      - Health Data Nexus (hosting and access management).
      - Temerty Centre for AI Research and Education in Medicine (support noted).
errata: []
updates:
  name: Update plan
  description:
    - Future releases aim to include original voice waveforms with additional security precautions.
    - Dataset is versioned with distinct DOIs for each release; see latest DOI for current version.
retention_limit: null
version_access:
  name: Version access
  description:
    - Versioned DOIs are provided; v1.0 DOI https: "//doi.org/10.57764/qb6h-em84; latest version DOI https://doi.org/10.57764/3sg0-7440."
extension_mechanism:
  name: Extension mechanism
  description:
    - Preprocessing code (b2aiprep) is open source for reproducibility of derived data preparation; dataset contribution mechanism not specified.
is_tabular: mixed
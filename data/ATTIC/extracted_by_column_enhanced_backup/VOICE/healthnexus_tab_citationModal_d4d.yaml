# === YAML Fixing Applied ===
id: bridge2ai-voice-v1-0
name: Bridge2AI-Voice v1.0
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: >
  Bridge2AI-Voice is a comprehensive, ethically sourced dataset to enable AI
  research on voice as a biomarker of health. Version 1.0 includes 12,523
  recordings from 306 adult participants collected across five sites in North
  America. Participants were selected into five disease cohort categories linked
  to changes in voice and speech: voice disorders, neurological and
  neurodegenerative disorders, mood and psychiatric disorders, respiratory
  disorders, and pediatric voice/speech disorders (adult cohort only in v1.0).
  This initial release contains only low-risk derived data (e.g., spectrograms
  and engineered acoustic/phonetic features) along with detailed demographic,
  clinical, and validated questionnaire data; original audio waveforms and
  transcripts of free speech are not included in v1.0. Data collection followed
  a standardized protocol using a custom tablet application and headset, with
  REDCap-based data capture. Audio preprocessing standardized sampling to 16 kHz
  with a Butterworth anti-aliasing filter, and derived data include
  spectrograms, acoustic features (openSMILE), phonetic/prosodic features
  (Parselmouth/Praat), and ASR transcriptions generated by Whisper (free speech
  transcripts removed prior to release).
version: "1.0"
issued: "2024-11-27"
doi: "doi:10.57764/qb6h-em84"
page: "https://doi.org/10.57764/qb6h-em84"
keywords:
  - voice
  - bridge2ai
  - audio
  - biomarker
  - health
license: Bridge2AI Voice Registered Access License
creators:
  - name: Alistair Johnson
    principal_investigator:
      id: "person:alistair-johnson"
      name: Alistair Johnson
  - name: Jean-Christophe Bélisle-Pipon
    principal_investigator:
      id: "person:jean-christophe-belisle-pipon"
      name: Jean-Christophe Bélisle-Pipon
  - name: David Dorr
    principal_investigator:
      id: "person:david-dorr"
      name: David Dorr
  - name: Satrajit Ghosh
    principal_investigator:
      id: "person:satrajit-ghosh"
      name: Satrajit Ghosh
  - name: Philip Payne
    principal_investigator:
      id: "person:philip-payne"
      name: Philip Payne
  - name: Maria Powell
    principal_investigator:
      id: "person:maria-powell"
      name: Maria Powell
  - name: Anaïs Rameau
    principal_investigator:
      id: "person:anais-rameau"
      name: Anaïs Rameau
  - name: Vardit Ravitsky
    principal_investigator:
      id: "person:vardit-ravitsky"
      name: Vardit Ravitsky
  - name: Alexandros Sigaras
    principal_investigator:
      id: "person:alexandros-sigaras"
      name: Alexandros Sigaras
  - name: Olivier Elemento
    principal_investigator:
      id: "person:olivier-elemento"
      name: Olivier Elemento
  - name: Yael Bensoussan
    principal_investigator:
      id: "person:yael-bensoussan"
      name: Yael Bensoussan
funders:
  - grantor:
      id: "org:nih"
      name: National Institutes of Health (NIH)
    grant:
      id: "grant:3OT2OD032720-01S1"
      name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioaccoustic database to understand disease like never before"
      grant_number: 3OT2OD032720-01S1
purposes:
  - response: >
      Create an ethically sourced, diverse, multi-institutional voice dataset
      linked to health information to enable AI research and support insights
      into voice as a biomarker of health.
tasks:
  - response: >
      AI modeling and analysis of voice-derived representations for health-related
      tasks across cohorts (voice disorders, neurological/neurodegenerative,
      mood/psychiatric, and respiratory disorders), using spectrograms and
      engineered features; adult cohort in v1.0.
addressing_gaps:
  - response: >
      Addresses the lack of large, high-quality, diverse, multi-institutional
      voice datasets linked to clinical and demographic information and collected
      under standardized, ethically reviewed protocols.
subsets:
  - id: "subset:adult-cohort-v1-0"
    name: Adult cohort (v1.0)
    description: Adult participants only in v1.0; pediatric cohort not included in this release.
    is_subpopulation: "true"
instances:
  - representation: >
      Voice-derived data (spectrograms and engineered acoustic/phonetic features)
      at the recording/session level; phenotype and questionnaire data at the
      participant level.
    instance_type: Recordings (session-level) and participants (subject-level)
    data_type: >
      Derived spectrogram tensors (513 x N) from standardized 16 kHz audio;
      static acoustic/phonetic feature vectors per recording; tabular phenotype
      and questionnaire responses per participant.
    counts: 12523
    label: >
      No explicit supervised labels provided in v1.0; cohort membership and
      clinical/phenotypic variables are available.
    missing_information:
      - missing: Free speech transcripts
        why_missing: Removed during de-identification in v1.0
    sampling_strategies:
      - is_sample:
          - "true"
        is_random:
          - "false"
        source_data:
          - Patients at specialty clinics across five sites in North America
        why_not_representative:
          - Clinic-based convenience sampling based on inclusion/exclusion criteria and predefined cohorts
        strategies:
          - Deterministic selection via screening against inclusion/exclusion criteria and cohort membership
collection_mechanisms:
  - description: >
      Standardized protocol using a custom tablet application with a headset for
      audio capture; demographic/clinical/questionnaire data collected in REDCap;
      data export and conversion performed using an open-source library.
    used_software:
      - name: REDCap
        url: "https://www.project-redcap.org/"
      - name: b2aiprep
        url: "https://github.com/sensein/b2aiprep"
instance_acquisition:
  - description: >
      Direct audio recordings captured from participants; clinical and
      questionnaire data reported by participants; multiple derived data types
      generated from raw audio. Standardized data collection protocol applied.
    was_directly_observed: "yes (voice recordings)"
    was_reported_by_subjects: "yes (questionnaires and demographic/clinical information)"
    was_inferred_derived: "yes (spectrograms; acoustic, phonetic, and prosodic features; ASR transcripts were generated but free speech transcripts were removed in v1.0)"
    was_validated_verified: "standardized protocol; site screening per inclusion/exclusion criteria"
collection_timeframes: []
data_collectors:
  - description: Project investigators at five North American clinical sites
ethical_reviews:
  - description: >
      Data collection and sharing approved by University of South Florida IRB;
      submission to the University of Toronto Research Ethics Board for review.
preprocessing_strategies:
  - description: >
      Raw audio converted to mono and resampled to 16 kHz with a Butterworth
      anti-aliasing filter; derived time-frequency spectrograms via STFT
      (25 ms window, 10 ms hop, 512-point FFT); acoustic features via openSMILE;
      phonetic/prosodic measures via Parselmouth/Praat; ASR transcripts
      generated using Whisper Large (free speech transcripts removed prior to
      release).
    used_software:
      - name: openSMILE
        url: "https://audeering.github.io/opensmile/"
      - name: Parselmouth
        url: "https://parselmouth.readthedocs.io/"
      - name: Praat
        url: "https://www.fon.hum.uva.nl/praat/"
      - name: Torchaudio
        version: ">=2.1"
        url: "https://pytorch.org/audio/"
      - name: OpenAI Whisper (Large)
        url: "https://github.com/openai/whisper"
cleaning_strategies:
  - description: >
      Standardization of audio channel and sampling (mono, 16 kHz) with
      anti-aliasing; removal of transcripts of free speech prior to release.
labeling_strategies:
  - description: >
      Automatic speech recognition transcriptions generated using Whisper Large;
      free speech transcripts excluded from the v1.0 release for privacy.
raw_sources:
  - description: >
      Original audio waveforms were used to generate derived data but are not
      included in v1.0; only spectrograms and other derived features are
      released.
content_warnings:
  - warnings:
      - Voice-related clinical content; no raw audio included in v1.0.
subpopulations:
  - identification:
      - Disease cohorts defined at enrollment: voice disorders, neurological/neurodegenerative disorders, mood/psychiatric disorders, respiratory disorders
      - Adult cohort only (v1.0)
    distribution:
      - Participants recruited from five North American sites; detailed demographics provided in phenotype.tsv
sensitive_elements:
  - description:
      - Health-related clinical and demographic data (de-identified)
is_deidentified:
  description:
    - HIPAA Safe Harbor identifiers removed (e.g., names, detailed dates, contact numbers, SSNs, MRNs, device IDs, account numbers, URLs, full-face photos, biometric identifiers)
    - State and province removed; country of data collection retained
    - Transcripts of free speech audio removed
    - Original audio waveforms omitted from v1.0; only derived spectrograms/features released
distribution_formats:
  - description:
      - Parquet (spectrograms.parquet)
      - TSV (phenotype.tsv, static_features.tsv)
      - JSON (phenotype.json, static_features.json)
distribution_dates:
  - description:
      - "Initial public release announced: 2024-11-27"
license_and_use_terms:
  description:
    - Files are distributed under the Bridge2AI Voice Registered Access License
    - Access restricted to credentialed users who sign the Bridge2AI Voice Registered Access Agreement (DUA) and complete required training (TCPS 2: CORE 2022)
    - Access via Health Data Nexus (credentialed access)
updates:
  description:
    - Future releases aim to include original voice recordings with additional security precautions
version_access:
  description:
    - Versioned DOIs available; v1.0 DOI: "https://doi.org/10.57764/qb6h-em84; latest version DOI: https://doi.org/10.57764/3sg0-7440"
external_resources: []
existing_uses: []
use_repository: []
ip_restrictions: []
regulatory_restrictions: []
maintainers: []
errata: []
retention_limit: []
extension_mechanism: []
media_type: ""
created_on: ""
last_updated_on: ""
status: ""
language: ""
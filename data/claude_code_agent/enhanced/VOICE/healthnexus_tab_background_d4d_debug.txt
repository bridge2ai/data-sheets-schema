=== YAML Fixing Applied ===
id: bridge2ai-voice
title: "Bridge2AI-Voice: An ethically-sourced, diverse voice dataset linked to health information"
description: >-
  Bridge2AI-Voice is a comprehensive, ethically sourced dataset linking derived data
  from voice recordings with corresponding clinical information to enable research
  on voice as a biomarker of health. Version 1.0 provides 12,523 recordings for 306
  participants collected across five sites in North America. Participants were
  selected based on conditions known to manifest in the voice waveform, including
  voice disorders, neurological disorders, mood/psychiatric disorders, respiratory
  disorders, and a pediatric cohort (v1.0 includes adult cohort only). This initial
  release contains data considered low risk, including spectrograms and derived
  acoustic/phonetic/prosodic features, plus detailed demographic, clinical, and
  validated questionnaire data. Raw audio waveforms and free-speech transcripts are
  not included in v1.0 to protect privacy; HIPAA Safe Harbor de-identification
  procedures were applied.
language: en
issued: 2024-11-27
page: "https://docs.b2ai-voice.org"
doi: "doi:10.57764/qb6h-em84"
keywords:
  - voice
  - bridge2ai
  - audio
version: "1.0"
created_by:
  - Alistair Johnson
  - Jean-Christophe Bélisle-Pipon
  - David Dorr
  - Satrajit Ghosh
  - Philip Payne
  - Maria Powell
  - Anaïs Rameau
  - Vardit Ravitsky
  - Alexandros Sigaras
  - Olivier Elemento
  - Yael Bensoussan
resources:
  - id: bridge2ai-voice-v1-0
    title: Bridge2AI-Voice v1.0 distribution
    description: >-
      Initial release (v1.0) of the Bridge2AI-Voice dataset: ethically sourced, multi-site
      collection of derived voice data (spectrograms and acoustic/phonetic/prosodic features),
      with participant-level phenotype (demographics, clinical, and validated questionnaires).
      Total of 12,523 recordings for 306 participants. Raw audio waveforms and free-speech
      transcripts are not included in this release.
    page: "https://docs.b2ai-voice.org"
    doi: "doi:10.57764/qb6h-em84"
    issued: 2024-11-27
    keywords:
      - voice
      - bridge2ai
      - audio
    license: Bridge2AI Voice Registered Access License
    version: "1.0"
    is_tabular: mixed (Parquet spectrogram arrays; TSV/JSON tabular metadata and features)
    purposes:
      - name: dataset-purpose
        response: >-
          Create an ethically sourced flagship dataset to enable research in artificial
          intelligence on voice as a biomarker of health and support insights into
          clinical applications.
    tasks:
      - name: intended-tasks
        response: >-
          AI/ML analysis of voice for health-related applications, including detection and
          characterization of voice, neurological/neurodegenerative, mood/psychiatric, and
          respiratory disorders; development of biomarkers from acoustic and prosodic features.
    addressing_gaps:
      - name: addressing-gaps
        response: >-
          Provide a large, multi-institutional, diverse, and ethically sourced voice dataset
          linked to clinical information with standardized protocols, addressing the scarcity
          of high-quality, demographically diverse voice-health datasets.
    funders:
      - name: nih-bridge2ai-voice-grant
        grantor:
          name: National Institutes of Health
        grant:
          name: "Bridge2AI: Voice as a Biomarker of Health - Building an ethically sourced, bioacoustic database to understand disease like never before"
          grant_number: 3OT2OD032720-01S1
    instances:
      - name: dataset-instances
        representation: >-
          Derived data from voice recordings linked to participant-level phenotype (demographics,
          clinical, validated questionnaires).
        instance_type: participants, sessions, and recordings
        data_type: >-
          Spectrograms (513 × N), static acoustic/phonetic/prosodic features, and phenotype
          tabular data; free-speech transcripts were generated but removed from release.
        counts: 12523
        label: Clinical cohort membership and validated questionnaire responses
        sampling_strategies:
          - name: sampling-strategy
            is_sample:
              - yes (enriched clinical cohorts)
            is_random:
              - no
            source_data:
              - Patients presenting at specialty clinics across five North American sites
            is_representative:
              - not guaranteed; cohorts enriched for target conditions
            why_not_representative:
              - Enrichment for specific disorders (voice, neurological, mood/psychiatric, respiratory)
            strategies:
              - Consecutive screening and enrollment per protocol with inclusion/exclusion criteria
    acquisition_methods:
      - name: acquisition
        description:
          - Standardized multi-site protocol with in-clinic recordings and questionnaires
        was_directly_observed: yes (audio recordings)
        was_reported_by_subjects: yes (questionnaires and self-reported items)
        was_inferred_derived: yes (spectrograms and features derived from audio; ASR transcriptions generated)
        was_validated_verified: >-
          Standardized protocol and instrumentation; de-identification and data processing
          followed documented procedures; preprocessing code released as open source.
    collection_mechanisms:
      - name: collection
        description:
          - Custom tablet application; headset used when possible; data exported from REDCap using open-source tooling (b2aiprep).
    data_collectors:
      - name: data-collectors
        description:
          - Project investigators at participating specialty clinics and institutions
    collection_timeframes: []
    ethical_reviews:
      - name: irb-reviews
        description:
          - Data collection and sharing approved by the University of South Florida IRB; submitted for review to the University of Toronto Research Ethics Board.
    is_deidentified:
      name: deidentification
      description:
        - HIPAA Safe Harbor applied; identifiers removed (e.g., names, fine-grained dates, contact info, IDs, etc.)
        - State/province removed; country of collection retained
        - Free-speech transcripts removed
        - Raw audio waveforms not included in v1.0
    confidential_elements:
      - name: confidentiality
        description:
          - Release contains only data considered low risk; raw audio and free-speech transcripts withheld to reduce re-identification risk.
    sensitive_elements:
      - name: sensitive-data
        description:
          - Contains health-related clinical and questionnaire information (de-identified).
    preprocessing_strategies:
      - name: audio-preprocessing
        description:
          - Raw audio converted to mono; resampled to 16 kHz with Butterworth anti-aliasing filter.
          - Spectrograms via STFT (25 ms window, 10 ms hop, 512-point FFT).
          - Acoustic features via OpenSMILE.
          - Phonetic/prosodic features via Parselmouth and Praat.
          - ASR transcriptions via OpenAI Whisper Large (free-speech transcripts not released).
        used_software:
          - name: openSMILE
            url: "https://audeering.github.io/opensmile/"
          - name: Praat
            url: "https://www.praat.org/"
          - name: Parselmouth
            url: "https://parselmouth.readthedocs.io/"
          - name: torchaudio
            version: "2.1"
            url: "https://pytorch.org/audio"
          - name: OpenAI Whisper
            version: Large
            url: "https://github.com/openai/whisper"
          - name: b2aiprep
            url: "https://github.com/sensein/b2aiprep"
    cleaning_strategies:
      - name: de-id-cleaning
        description:
          - HIPAA Safe Harbor de-identification; removal of specified identifiers.
          - Removal of state/province; retention of country.
          - Removal of free-speech transcripts.
          - Exclusion of raw audio from v1.0 release.
    labeling_strategies:
      - name: labeling-annotation
        description:
          - Automatic transcriptions generated with OpenAI Whisper Large; not included in the v1.0 release.
    raw_sources:
      - name: raw-audio
        description:
          - Raw audio was collected but is not distributed in v1.0; only derived spectrograms and features are released.
    other_tasks:
      - name: potential-uses
        description:
          - Development of voice-based biomarkers; screening and monitoring tools for relevant disorders; exploration of acoustic/prosodic correlates of health states.
    future_use_impacts:
      - name: use-impacts
        description:
          - Absence of raw audio and free-speech transcripts in v1.0 limits certain modeling approaches; adult-only cohort in v1.0 may affect generalizability.
    distribution_formats:
      - name: formats
        description:
          - Parquet for spectrogram arrays
          - TSV for tabular phenotype and static features
          - JSON data dictionaries
    distribution_dates:
      - name: v1-0-release-date
        description:
          - 2024-11-27
    license_and_use_terms:
      name: access-and-terms
      description:
        - Access restricted to credentialed users who sign the Bridge2AI Voice Registered Access Agreement (DUA).
        - License: Bridge2AI Voice Registered Access License.
        - Required training: TCPS 2: CORE 2022.
    maintainers:
      - name: maintainers
        description:
          - Bridge2AI-Voice Team; Health Data Nexus
    updates:
      name: update-plan
      description:
        - Future releases aim to include voice audio with additional safeguards and security measures.
    version_access:
      name: versioning
      description:
        - Versioned DOIs provided; latest version DOI: https://doi.org/10.57764/3sg0-7440
    subsets:
      - id: adult-cohort
        title: Adult cohort subset (v1.0)
        description: Adult cohort data only are included in v1.0.
        is_subpopulation: yes
      - id: spectrograms-parquet
        title: spectrograms.parquet
        description: Dense spectrograms (513 × N) derived from raw audio; includes participant_id, session_id, task_name, and spectrogram.
        path: spectrograms.parquet
        media_type: application/x-parquet
      - id: phenotype-tsv
        title: phenotype.tsv
        description: Participant-level phenotype, including demographics, acoustic confounders, and validated questionnaires (one row per participant).
        path: phenotype.tsv
        media_type: text/tab-separated-values
      - id: phenotype-json
        title: phenotype.json
        description: Data dictionary for phenotype.tsv.
        path: phenotype.json
        format: JSON
        media_type: application/json
      - id: static-features-tsv
        title: static_features.tsv
        description: Static acoustic/phonetic/prosodic features (one row per recording).
        path: static_features.tsv
        media_type: text/tab-separated-values
      - id: static-features-json
        title: static_features.json
        description: Data dictionary for static_features.tsv.
        path: static_features.json
        format: JSON
        media_type: application/json
    external_resources:
      - name: documentation
        external_resources:
          - https://docs.b2ai-voice.org
        archival:
          - Versioned via DOI at Health Data Nexus
      - name: references-and-tools
        external_resources:
          - https://doi.org/10.5281/zenodo.14148755
          - https://github.com/sensein/b2aiprep
          - https://audeering.github.io/opensmile/
          - https://www.praat.org/
          - https://parselmouth.readthedocs.io/
          - https://pytorch.org/audio
      - name: citation
        external_resources:
          - https://doi.org/10.57764/qb6h-em84
        restrictions:
          - Cite the dataset as indicated on the landing page.
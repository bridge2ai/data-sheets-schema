<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rubric20-Semantic Evaluation: AI_READI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        h1 {
            color: #1a1a1a;
            margin-bottom: 10px;
            font-size: 2em;
        }

        h2 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid #3498db;
        }

        h3 {
            color: #34495e;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        h4 {
            color: #5a6c7d;
            margin-top: 15px;
            margin-bottom: 8px;
        }

        .metadata {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 6px;
            margin-bottom: 30px;
            border-left: 4px solid #3498db;
        }

        .metadata-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
        }

        .metadata-item {
            display: flex;
            flex-direction: column;
        }

        .metadata-label {
            font-size: 0.85em;
            color: #7f8c8d;
            margin-bottom: 4px;
        }

        .metadata-value {
            font-weight: 500;
            color: #2c3e50;
        }

        .score-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 8px;
            text-align: center;
            margin-bottom: 30px;
        }

        .score-large {
            font-size: 3em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .score-subtitle {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .category-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .category-card {
            background: #fff;
            border: 1px solid #e1e8ed;
            border-radius: 6px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }

        .category-header {
            font-size: 0.85em;
            color: #7f8c8d;
            margin-bottom: 8px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .category-title {
            font-size: 1.1em;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 15px;
        }

        .category-score {
            font-size: 2em;
            font-weight: bold;
            color: #3498db;
            margin-bottom: 5px;
        }

        .category-percentage {
            color: #7f8c8d;
            font-size: 0.95em;
        }

        .question {
            background: #fff;
            border: 1px solid #e1e8ed;
            border-radius: 6px;
            margin-bottom: 20px;
            overflow: hidden;
        }

        .question-header {
            background: #f8f9fa;
            padding: 15px 20px;
            border-bottom: 1px solid #e1e8ed;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .question-title {
            font-weight: 600;
            color: #2c3e50;
        }

        .question-number {
            color: #7f8c8d;
            font-size: 0.9em;
            margin-right: 8px;
        }

        .question-score {
            font-size: 1.1em;
            font-weight: bold;
            padding: 5px 15px;
            border-radius: 20px;
        }

        .score-perfect { background: #2ecc71; color: white; }
        .score-high { background: #27ae60; color: white; }
        .score-good { background: #f39c12; color: white; }
        .score-medium { background: #e67e22; color: white; }
        .score-low { background: #e74c3c; color: white; }

        .question-body {
            padding: 20px;
        }

        .detail {
            margin-bottom: 15px;
        }

        .detail-label {
            font-weight: 600;
            color: #34495e;
            margin-bottom: 5px;
            display: block;
        }

        .detail-content {
            color: #555;
            line-height: 1.5;
        }

        .evidence-list {
            list-style: none;
            padding: 0;
        }

        .evidence-item {
            padding: 8px 12px;
            margin-bottom: 5px;
            background: #f8f9fa;
            border-radius: 4px;
            border-left: 3px solid #3498db;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }

        .semantic-checks {
            background: #fff3cd;
            border: 1px solid #ffc107;
            border-radius: 4px;
            padding: 12px;
            margin-top: 10px;
        }

        .semantic-section {
            background: #e8f4f8;
            border: 1px solid #3498db;
            border-radius: 6px;
            padding: 20px;
            margin-bottom: 20px;
        }

        .semantic-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-top: 15px;
        }

        .semantic-item {
            background: white;
            padding: 12px;
            border-radius: 4px;
            border-left: 3px solid #3498db;
        }

        .semantic-item.passed {
            border-left-color: #2ecc71;
        }

        .semantic-item.failed {
            border-left-color: #e74c3c;
        }

        .semantic-item.warning {
            border-left-color: #f39c12;
        }

        .list-section {
            margin-top: 20px;
        }

        .list-item {
            padding: 10px 15px;
            margin-bottom: 8px;
            background: #f8f9fa;
            border-radius: 4px;
            border-left: 3px solid #3498db;
        }

        .list-item.strength {
            background: #d4edda;
            border-left-color: #28a745;
        }

        .list-item.weakness {
            background: #f8d7da;
            border-left-color: #dc3545;
        }

        .list-item.recommendation {
            background: #e7f3ff;
            border-left-color: #2196f3;
        }

        .timestamp {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e8ed;
            color: #7f8c8d;
            font-size: 0.9em;
        }

        .badge {
            display: inline-block;
            padding: 3px 8px;
            border-radius: 3px;
            font-size: 0.8em;
            font-weight: 600;
            margin-left: 8px;
        }

        .badge-success { background: #d4edda; color: #155724; }
        .badge-warning { background: #fff3cd; color: #856404; }
        .badge-danger { background: #f8d7da; color: #721c24; }

        .category-section {
            margin-bottom: 40px;
        }

        .issue-item {
            background: #fff;
            border: 1px solid #e1e8ed;
            border-radius: 4px;
            padding: 15px;
            margin-bottom: 10px;
        }

        .issue-type {
            font-weight: 600;
            color: #e74c3c;
            margin-bottom: 5px;
        }

        .issue-severity {
            display: inline-block;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 0.85em;
            margin-left: 10px;
        }

        .severity-high { background: #e74c3c; color: white; }
        .severity-medium { background: #f39c12; color: white; }
        .severity-low { background: #95a5a6; color: white; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Rubric20-Semantic Evaluation Report</h1>
        <div class="metadata">
            <div class="metadata-grid">
                <div class="metadata-item">
                    <div class="metadata-label">Project</div>
                    <div class="metadata-value">AI_READI</div>
                </div>
                <div class="metadata-item">
                    <div class="metadata-label">D4D File</div>
                    <div class="metadata-value">AI_READI_d4d.yaml</div>
                </div>
                <div class="metadata-item">
                    <div class="metadata-label">Evaluator Model</div>
                    <div class="metadata-value">claude-sonnet-4-5-20250929</div>
                </div>
                <div class="metadata-item">
                    <div class="metadata-label">Rubric Type</div>
                    <div class="metadata-value">rubric20-semantic</div>
                </div>
                <div class="metadata-item">
                    <div class="metadata-label">Temperature</div>
                    <div class="metadata-value">0.0</div>
                </div>
                <div class="metadata-item">
                    <div class="metadata-label">Evaluation Date</div>
                    <div class="metadata-value">2025-12-20T00:00:00Z</div>
                </div>
            </div>
        </div>

        <div class="score-card">
            <div class="score-large">82.0/84.0</div>
            <div class="score-subtitle">97.6% Overall Score · Grade: A+</div>
        </div>

        <h2>Category Performance</h2>
        <div class="category-grid">

            <div class="category-card">
                <div class="category-header">Category</div>
                <div class="category-title">Structural Completeness</div>
                <div class="category-score">21/21</div>
                <div class="category-percentage">100.0%</div>
            </div>

            <div class="category-card">
                <div class="category-header">Category</div>
                <div class="category-title">Metadata Quality & Content</div>
                <div class="category-score">21/21</div>
                <div class="category-percentage">100.0%</div>
            </div>

            <div class="category-card">
                <div class="category-header">Category</div>
                <div class="category-title">Technical Documentation</div>
                <div class="category-score">24/25</div>
                <div class="category-percentage">96.0%</div>
            </div>

            <div class="category-card">
                <div class="category-header">Category</div>
                <div class="category-title">FAIRness & Accessibility</div>
                <div class="category-score">16/17</div>
                <div class="category-percentage">94.1%</div>
            </div>

        </div>

        <h2>Question-Level Assessment</h2>

        <div class="category-section">
            <h3>Structural Completeness</h3>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q1.</span>
                        Field Completeness
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">All mandatory fields present with exceptional content quality. Title is descriptive and includes full acronym expansion. Description is comprehensive at 571 characters covering dataset design, scope, domains, and FAIR compliance.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">id: https://fairhub.io/datasets/2, title: 'Artificial Intelligence Ready and Equitable Atlas for Diabetes Insights (AI-READI)', description: 400+ chars, keywords: 19 keywords, license_and_use_terms: comprehensive CC BY-NC 4.0 with detailed terms</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q2.</span>
                        Entry Length Adequacy
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Exceptional narrative depth. Description provides specific details (4,000 participants, 3 sites, triple-balanced design, 10+ data domains). Each purpose statement exceeds 200 chars with actionable research objectives.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">description: 571 chars with detailed multimodal data description, purposes: 3 purposes averaging 287 chars each with specific research objectives</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q3.</span>
                        Keyword Diversity
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent keyword diversity covering disease (T2DM), methodology (machine learning, multimodal), study design (cross-sectional, multi-site), data types (retinal imaging, wearables), and key concepts (salutogenesis, health equity, FAIR). Keywords span technical, clinical, and ethical domains.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">keywords: [Type 2 Diabetes Mellitus, T2DM, AI-READI, Machine Learning, Artificial Intelligence, multimodal dataset, harmonized data, multi-site study, salutogenesis, FAIR principles, retinal imaging, continuous glucose monitoring, wearable devices, biorepository, biospecimens, triple-balanced sampling, health equity, Bridge2AI, cross-sectional study]</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q4.</span>
                        File Enumeration and Type Variety
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Strong format diversity reflecting multimodal nature: DICOM (imaging), CSV (clinical/sensor), mHealth (wearables), REDCap (metadata). Covers both raw data and metadata formats. XML for ECG mentioned in acquisition but not explicitly in distribution_formats.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">distribution_formats: DICOM for retinal imaging, CSV for tabular/time-series data, mHealth standard for wearables, REDCap data dictionary; acquisition methods mention XML for ECG</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q5.</span>
                        Data File Size Availability
                        <span class="badge badge-success">pass_fail</span>
                    </div>
                    <div class="question-score score-perfect">1/1</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Clear instance count metadata with target N=4,000 participants. Subpopulations quantified with ~1,000 per group (8 subgroups defined). No byte size information for files, but instance counts are comprehensive.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">instances.description: 'Target enrollment is 4,000 people' with specific subpopulation targets of ~1,000 per race/ethnicity group and diabetes severity level</div>
                    </div>

                </div>
            </div>

        </div>

        <div class="category-section">
            <h3>Metadata Quality & Content</h3>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q6.</span>
                        Dataset Identification Metadata
                        <span class="badge badge-success">pass_fail</span>
                    </div>
                    <div class="question-score score-perfect">1/1</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Multiple persistent identifiers across platforms. FAIRhub URL serves as primary ID. Zenodo DOI 10.5281/zenodo.10642459 for archived documentation. Publication DOIs link to protocol and commentary. No RRID present but not critical for clinical dataset.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">id: https://fairhub.io/datasets/2, page: https://fairhub.io/datasets/2, external_resources: DOI 10.5281/zenodo.10642459 (Zenodo archive), DOI 10.1136/bmjopen-2024-097449 (protocol), DOI 10.1038/s42255-024-01165-x (commentary)</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q7.</span>
                        Funding and Acknowledgements Completeness
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Exceptional funding documentation including primary NIH grant OT2OD032644, supplementary grants, opportunity number OTA-21-008, project dates (Sept 2022 - Aug 2025), and 2022 funding amount ($5,026,499). All 20 creators listed with institutions and roles (Contact PI, Co-Investigators). Research to Prevent Blindness support mentioned.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">funders: NIH Common Fund Bridge2AI Program with grant OT2OD032644, additional grants P30DK035816, UL1TR003096; creators: 20 investigators with names, roles, and institutional affiliations (UW, UAB, UCSD)</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q8.</span>
                        Ethical and Privacy Declarations
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Comprehensive ethical documentation exceeding standard requirements. IRB approval from UW (STUDY00016228) with reliance agreements from UAB and UCSD. Written informed consent mentioned. Community Advisory Board (11 diverse members) provides ethical oversight. Sensitive data clearly categorized (genetic, geographic, medical) with access controls. Tribal consultation planned for Native American cohort. Bioethics guidance integrated throughout.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">human_subject_research.involves_human_subjects: true, irb_approval: UW STUDY00016228 with UAB and UCSD reliance agreements, ethics_review_board: 3 IRBs + Community Advisory Board, special_populations: racial/ethnic minorities, tribal consultation planned, sensitive_elements: 3 categories (genetic, geographic, medical records) with controlled access</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q9.</span>
                        Access Requirements and Governance Documentation
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent governance framework. Public data uses CC BY-NC 4.0 with explicit terms (attribution required, non-commercial, derivatives permitted, changes indicated). Controlled access requires separate DUA. Two-tier access model clearly defined: public dataset (general health info) vs controlled dataset (genetic, zip codes, medical records). Data Access Committee developing policies. IP and regulatory restrictions implicit through access tiers.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">license: CC BY-NC 4.0, license_and_use_terms: detailed terms with attribution, non-commercial use, derivative work permissions; subsets: public access vs controlled access clearly distinguished with DUA requirement; sensitive_elements: genetic, geographic, medical data categorized</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q10.</span>
                        Interoperability and Standardization
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Outstanding interoperability through multiple data standards: OMOP CDM (clinical data), DICOM (imaging), mHealth (wearables), RxNorm (medications), ICD-10 (diagnoses). Data stored as 'AI-ready' enabling immediate use without reformatting. Standards appropriately matched to modalities: imaging→DICOM, clinical→OMOP, wearables→mHealth. Standardization across 3 sites ensures harmonization.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">preprocessing_strategies mention OMOP Common Data Model for clinical data, DICOM for imaging, mHealth standard for wearables, RxNorm codes for medications, ICD-10 codes for diabetes classification; formats: DICOM, CSV, mHealth</div>
                    </div>

                </div>
            </div>

        </div>

        <div class="category-section">
            <h3>Technical Documentation</h3>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q11.</span>
                        Tool and Software Transparency
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-high">4/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Strong documentation of preprocessing (5 strategies) and cleaning (1 strategy) with detailed procedures. Equipment/software mentioned: REDCap, imaging devices (Heidelberg Spectralis, Topcon Triton, Zeiss Cirrus, etc.), wearables (Dexcom G6, Garmin VivoSmart 5), lab instruments (Philips Pagewriter TC30). However, lacks version numbers for software tools and URLs/repositories. No labeling_strategies documented (not applicable for clinical study). Preprocessing details include specific protocols (DICOM conversion, mHealth conversion, PBMC processing).</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">preprocessing_strategies: 5 strategies (standardization, image conversion, biospecimen processing, QC, data mapping); cleaning_strategies: 1 strategy (multi-site harmonization); software tools mentioned: REDCap (data management), various imaging devices with manufacturers, Dexcom G6, Garmin VivoSmart 5, specific lab equipment</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q12.</span>
                        Collection Protocol Clarity
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Exceptional collection protocol documentation. 5 collection mechanisms described: in-person visits (2.5-4 hours), EHR screening (ICD-10 codes), wave-based recruitment, home monitoring (10 days), biospecimen banking. 12 acquisition methods covering all domains: surveys (REDCap), vitals, retinal imaging (7 devices), visual function, lab tests, ECG, cognitive function (MoCA), neuropathy (monofilament), CGM (Dexcom), activity (Garmin), environment, biospecimens. Data collectors: study coordinators at 3 sites (UW, UAB, UCSD) with standardized training and certification. Timeframes: enrollment period, pilot phase, home monitoring duration all specified.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">collection_mechanisms: 5 mechanisms (in-person visits, EHR screening, wave-based recruitment, home monitoring, biospecimen collection); acquisition_methods: 12 detailed acquisition methods across all data domains; collection_timeframes: enrollment July 18, 2023 to November 30, 2026, pilot period July-Nov 2023, 10-day home monitoring</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q13.</span>
                        Version History Documentation
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent versioning infrastructure. Version access via docs.aireadi.org with version-specific guides. Multiple releases documented: pilot (May 2024), v1.0.0 (Nov 2024, data through July 31, 2024), v2.0.0 and v3.0.0 mentioned, final release planned late 2026. Update frequency defined: periodic releases during enrollment. Version-specific documentation maintained. No explicit errata section but updates section covers maintenance plan. Dataset versioning implemented systematically.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">updates: periodic releases with enrollment progression, pilot data May 2024, v1.0.0 through July 31 2024 released Nov 2024, v2.0.0 and v3.0.0 mentioned, final dataset expected after 4,000 participant completion Nov 2026, version-specific documentation at https://docs.aireadi.org/</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q14.</span>
                        Associated Publications
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Strong publication record. Two formal peer-reviewed publications: (1) BMJ Open protocol paper (DOI 10.1136/bmjopen-2024-097449) describing study design, (2) Nature Metabolism commentary (DOI 10.1038/s42255-024-01165-x) on AI-READI significance. Zenodo archive (DOI 10.5281/zenodo.10642459) for documentation. 9 external resources total spanning publications, websites, repositories, and program affiliations. NIH RePORTER link provides grant transparency.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">external_resources: BMJ Open protocol DOI 10.1136/bmjopen-2024-097449, Nature Metabolism commentary DOI 10.1038/s42255-024-01165-x, Zenodo archive DOI 10.5281/zenodo.10642459, additional resources: project website, docs site, FAIRhub, Bridge2AI program, NIH RePORTER</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q15.</span>
                        Human Subject Representation
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Outstanding human subjects documentation. Target N=4,000 with precise demographic balancing: 4 racial/ethnic groups × 4 diabetes levels × 2 sexes = 32 cells. Subpopulations explicitly defined with targets (~1,000 per racial group, ~1,000 per diabetes level). Inclusion criteria: age 40+, English-speaking, T2DM spectrum. Exclusion: pregnancy, type 1 diabetes, cognitive impairment (implied by MoCA). Recruitment sources specified (UAB, UCSD, UW health systems). Special populations explicitly targeted for health equity (racial/ethnic minorities disproportionately affected by T2DM).</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">instances: detailed description of 4,000 participants with triple-balanced design across race/ethnicity (Asian, Black, Hispanic, White), diabetes severity (4 levels), and biological sex (male, female); subpopulations: 8 subgroups defined with ~1,000 target per group; inclusion: age 40+, English-speaking; exclusion: pregnancy, type 1 diabetes</div>
                    </div>

                </div>
            </div>

        </div>

        <div class="category-section">
            <h3>FAIRness & Accessibility</h3>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q16.</span>
                        Findability (Persistent Links)
                        <span class="badge badge-success">pass_fail</span>
                    </div>
                    <div class="question-score score-perfect">1/1</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent findability with multiple persistent entry points. Primary landing page: FAIRhub (https://fairhub.io/datasets/2). Documentation: docs.aireadi.org. Project site: aireadi.org. Data sharing policy: aireadi.org/goals/data-sharing. Federal transparency: NIH RePORTER. DOIs for publications and archived documentation. Bridge2AI program link provides programmatic context. All URLs use HTTPS.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">page: https://fairhub.io/datasets/2, external_resources: 9 URLs including FAIRhub, docs.aireadi.org, aireadi.org, bridge2ai.org, NIH RePORTER, DOIs for Zenodo, BMJ Open, Nature Metabolism</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q17.</span>
                        Accessibility (Access Mechanism)
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Comprehensive access mechanism documentation. Two-tier access model: (1) Public dataset available via FAIRhub with CC BY-NC 4.0 license agreement (no registration beyond agreement), (2) Controlled dataset requires Data Use Agreement (DUA) for sensitive data (genetic, zip codes, medical records). Platform: FAIRhub with direct download. Access policy: being developed by Data Access Committee. Formats clearly specified for each data type. Biorepository access procedures under development.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">distribution_formats: 4 formats (DICOM, CSV, mHealth, REDCap) with access_urls pointing to FAIRhub; subsets: public access (license agreement) vs controlled access (DUA required); license_and_use_terms: CC BY-NC 4.0 with specific terms; Data Access Committee developing policies</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q18.</span>
                        Reusability (License Clarity)
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-perfect">5/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent license clarity. CC BY-NC 4.0 explicitly permits: distribution, remix, adaptation, derivative works (even with different licenses), non-commercial building upon work. Requirements clearly stated: proper citation, appropriate credit, indicate changes, non-commercial use. Controlled data has separate DUA (mentioned but terms under development). Link to canonical license text provided. Reuse cases clearly identifiable: AI/ML model development, multi-modal research, health equity studies, biomarker discovery.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">license: CC BY-NC 4.0, license_and_use_terms: detailed description with explicit permissions (distribute, remix, adapt, build upon non-commercially, derivative works on different terms), requirements (attribution, indicate changes), and URL to full license (http://creativecommons.org/licenses/by-nc/4.0/)</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q19.</span>
                        Data Integrity and Provenance
                        <span class="badge badge-success">numeric</span>
                    </div>
                    <div class="question-score score-high">4/5</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Good integrity and provenance documentation. Version progression clearly documented with dates and scope (v1.0.0 includes data through July 31, 2024). Update frequency defined (periodic with enrollment progression). Version-specific documentation provides provenance context. Dataset versioning infrastructure established. However, lacks file-level checksums, detailed change logs between versions, or automated provenance tracking. Biospecimen provenance tracked through UAB CCTS but details not in D4D. No mention of data lineage or transformation logs.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">updates: periodic releases documented (pilot May 2024, v1.0.0 Nov 2024, v2.0.0, v3.0.0, final late 2026) with version-specific documentation at docs.aireadi.org; update_details list version progression; no explicit checksums or file-level provenance metadata</div>
                    </div>

                </div>
            </div>

            <div class="question">
                <div class="question-header">
                    <div class="question-title">
                        <span class="question-number">Q20.</span>
                        Interlinking Across Platforms
                        <span class="badge badge-success">pass_fail</span>
                    </div>
                    <div class="question-score score-perfect">1/1</div>
                </div>
                <div class="question-body">
                    <div class="detail">
                        <span class="detail-label">Assessment</span>
                        <div class="detail-content">Excellent cross-platform interlinking. Data repository (FAIRhub) links to documentation (docs.aireadi.org), project site (aireadi.org), funder (NIH RePORTER), program (Bridge2AI), archival repository (Zenodo), and publications (BMJ Open, Nature Metabolism). Cross-references span data repositories, documentation platforms, funding agencies, academic publishers, and program consortia. Comprehensive ecosystem of linked resources enables discovery from multiple entry points.</div>
                    </div>

                    <div class="detail">
                        <span class="detail-label">Evidence Found</span>
                        <div class="detail-content">external_resources: 9 cross-platform links including FAIRhub (data repository), docs.aireadi.org (documentation), aireadi.org (project), Zenodo (archive), NIH RePORTER (grant), Bridge2AI (program), BMJ Open (protocol), Nature Metabolism (publication)</div>
                    </div>

                </div>
            </div>

        </div>

        <h2>Semantic Analysis Summary</h2>

        <div class="semantic-section">
            <h3>Consistency Checks</h3>

            <div class="semantic-grid">

                <div class="semantic-item">
                    <strong>Passed:</strong> 24
                </div>

                <div class="semantic-item">
                    <strong>Failed:</strong> 0
                </div>

                <div class="semantic-item">
                    <strong>Warnings:</strong> 3
                </div>

            </div>

        </div>

        <h3>Issues Detected</h3>

        <div class="issue-item">
            <div class="issue-type">
                correctness
                <span class="issue-severity severity-low">LOW</span>
            </div>
            <div><strong>Fields:</strong> external_resources, id</div>
            <div><strong>Recommendation:</strong> </div>
        </div>

        <div class="issue-item">
            <div class="issue-type">
                consistency
                <span class="issue-severity severity-low">LOW</span>
            </div>
            <div><strong>Fields:</strong> id, external_resources</div>
            <div><strong>Recommendation:</strong> </div>
        </div>

        <div class="issue-item">
            <div class="issue-type">
                semantic_understanding
                <span class="issue-severity severity-low">LOW</span>
            </div>
            <div><strong>Fields:</strong> distribution_formats, acquisition_methods</div>
            <div><strong>Recommendation:</strong> </div>
        </div>

        <div class="timestamp">
            Generated on 2025-12-23 13:21:35 using Bridge2AI Data Sheets Schema
        </div>
    </div>
</body>
</html>
